{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0efba513",
   "metadata": {
    "id": "HU48Dzb4iuhP"
   },
   "source": [
    "# xAGäºˆæ¸¬ã‚³ãƒ³ãƒšã€€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆãã®2ï¼‰\n",
    "\n",
    "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆhost_baseline_001.ipynbï¼‰ã«ã¤ã„ã¦ã€ç‰¹å¾´é‡ã®è¿½åŠ ä½œæˆã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’è¡Œã£ãŸæ”¹å–„ç‰ˆã‚³ãƒ¼ãƒ‰ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a57b0d9",
   "metadata": {
    "id": "4N4IPuA_J7sw"
   },
   "outputs": [],
   "source": [
    "#ç¬¬ä¸€å›ã¯ã“ã¡ã‚‰\n",
    "#https://www.kaggle.com/competitions/dsdojo_1/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55e515",
   "metadata": {
    "id": "cdc2NNOJiuhU"
   },
   "source": [
    "---\n",
    "## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8529b3a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZJyn-MciuhU",
    "outputId": "eb7079dd-b265-4b57-fda9-ff61cec466b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: japanize_matplotlib in /usr/local/lib/python3.11/site-packages (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (from japanize_matplotlib) (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->japanize_matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: catboost in /usr/local/lib/python3.11/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (from catboost) (3.10.6)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from catboost) (1.16.2)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.11/site-packages (from catboost) (6.3.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.11/site-packages (from plotly->catboost) (2.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# å¿…è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§Colabç’°å¢ƒã«ãªã„ã‚‚ã®ã¯install\n",
    "!pip install japanize_matplotlib\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b3b3db",
   "metadata": {
    "id": "km_jW_2YiuhU",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# å¿…è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’import\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "import networkx as nx\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’ä¼´ã†å‡¦ç†ã‚’è¡Œã†ãŸã‚ã€çµæœã®å†ç¾æ€§ã‚’ä¿ã¤ã«ã¯ã‚·ãƒ¼ãƒ‰å€¤ã‚’å›ºå®šã—ã¦ãŠãå¿…è¦ãŒã‚ã‚Šã¾ã™\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c13b46",
   "metadata": {
    "id": "ah17yN7bu-Mu",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ã‚³ãƒ³ãƒšã®è©•ä¾¡æŒ‡æ¨™ã«åˆã‚ã›ãŸç›®çš„é–¢æ•°/è©•ä¾¡é–¢æ•°ã®å®šç¾©\n",
    "WEIGHTED_TARGET_THRESHOLD = 0.1\n",
    "WEIGHTED_POSITIVE_WEIGHT = 5.0\n",
    "\n",
    "def make_sample_weight(y_true):\n",
    "    \"\"\"\n",
    "    ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«å¿œã˜ãŸé‡ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ\n",
    "    \"\"\"\n",
    "    y_array = np.asarray(y_true, dtype=float)\n",
    "    return np.where(y_array >= WEIGHTED_TARGET_THRESHOLD, WEIGHTED_POSITIVE_WEIGHT, 1.0)\n",
    "\n",
    "def weighted_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    é‡ã¿ä»˜ãRMSEè©•ä¾¡é–¢æ•°\n",
    "    ã‚³ãƒ³ãƒšã®è©•ä¾¡æŒ‡æ¨™ã«åˆã‚ã›ã¦å®Ÿè£…\n",
    "    \"\"\"\n",
    "    weights = make_sample_weight(y_true)\n",
    "    squared_errors = (y_true - y_pred) ** 2\n",
    "    weighted_squared_errors = weights * squared_errors\n",
    "    pw_rmse = np.sqrt(np.mean(weighted_squared_errors) + 1e-9)\n",
    "    return float(pw_rmse)\n",
    "\n",
    "def weighted_rmse_feval(y_pred, dtrain):\n",
    "    \"\"\"\n",
    "    LightGBMç”¨ã®é‡ã¿ä»˜ãRMSEè©•ä¾¡é–¢æ•°\n",
    "    \"\"\"\n",
    "    y_true = dtrain.get_label()\n",
    "    weighted_rmse_value = weighted_rmse(y_true, y_pred)\n",
    "    return \"weighted_rmse\", weighted_rmse_value, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df386a04",
   "metadata": {
    "id": "v0L9gXW5iuhU"
   },
   "outputs": [],
   "source": [
    "# è¡¨ç¤ºã§ãã‚‹dfã®è¡Œã€åˆ—æ•°ã‚’å¢—ã‚„ã™\n",
    "pd.set_option(\"display.max_rows\", 100)    # æœ€å¤§100è¡Œã¾ã§è¡¨ç¤º\n",
    "pd.set_option(\"display.max_columns\", 100) # æœ€å¤§100åˆ—ã¾ã§è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b86531",
   "metadata": {
    "id": "29WdPR8riuhV"
   },
   "source": [
    "## ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5cbd03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 804
    },
    "id": "e6eZzzhRiuhV",
    "lines_to_next_cell": 2,
    "outputId": "b494a902-ca3a-4cde-d9e9-52c00f7f2c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å…ƒãƒ‘ã‚¹: ../../data\n",
      "trainãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (27870, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Round</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Result</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>xAG</th>\n",
       "      <th>player_name</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>URL</th>\n",
       "      <th>player_id</th>\n",
       "      <th>match_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-09</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 4</td>\n",
       "      <td>Away</td>\n",
       "      <td>W 2â€“1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Leicester City</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-17</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 5</td>\n",
       "      <td>Home</td>\n",
       "      <td>D 0â€“0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-23</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 6</td>\n",
       "      <td>Away</td>\n",
       "      <td>W 4â€“0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Stoke City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day            Comp        Round Venue Result    Squad  \\\n",
       "0  2017-09-09  Sat  Premier League  Matchweek 4  Away  W 2â€“1  Chelsea   \n",
       "1  2017-09-17  Sun  Premier League  Matchweek 5  Home  D 0â€“0  Chelsea   \n",
       "2  2017-09-23  Sat  Premier League  Matchweek 6  Away  W 4â€“0  Chelsea   \n",
       "\n",
       "         Opponent  xAG  player_name  birth_date  \\\n",
       "0  Leicester City  0.1  Eden Hazard  1991-01-07   \n",
       "1         Arsenal  0.0  Eden Hazard  1991-01-07   \n",
       "2      Stoke City  0.0  Eden Hazard  1991-01-07   \n",
       "\n",
       "                                                 URL player_id match_id  \n",
       "0  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499753  \n",
       "1  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499760  \n",
       "2  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499776  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (12798, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Round</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Result</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>player_name</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>URL</th>\n",
       "      <th>player_id</th>\n",
       "      <th>match_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 27</td>\n",
       "      <td>Home</td>\n",
       "      <td>W 3â€“0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 28</td>\n",
       "      <td>Away</td>\n",
       "      <td>L 1â€“2</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Manchester Utd</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 29</td>\n",
       "      <td>Away</td>\n",
       "      <td>L 0â€“1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2500004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day            Comp         Round Venue Result    Squad  \\\n",
       "0  2018-02-12  Mon  Premier League  Matchweek 27  Home  W 3â€“0  Chelsea   \n",
       "1  2018-02-25  Sun  Premier League  Matchweek 28  Away  L 1â€“2  Chelsea   \n",
       "2  2018-03-04  Sun  Premier League  Matchweek 29  Away  L 0â€“1  Chelsea   \n",
       "\n",
       "          Opponent  player_name  birth_date  \\\n",
       "0        West Brom  Eden Hazard  1991-01-07   \n",
       "1   Manchester Utd  Eden Hazard  1991-01-07   \n",
       "2  Manchester City  Eden Hazard  1991-01-07   \n",
       "\n",
       "                                                 URL player_id match_id  \n",
       "0  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499979  \n",
       "1  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499996  \n",
       "2  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2500004  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2303958, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>match_date</th>\n",
       "      <th>match_venue</th>\n",
       "      <th>match_status</th>\n",
       "      <th>home_team_name</th>\n",
       "      <th>away_team_name</th>\n",
       "      <th>match_winner</th>\n",
       "      <th>period_id</th>\n",
       "      <th>time_seconds</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>player_id</th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "      <th>type_name</th>\n",
       "      <th>result_name</th>\n",
       "      <th>bodypart_name</th>\n",
       "      <th>team_name_short</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>player_name</th>\n",
       "      <th>jersey_number</th>\n",
       "      <th>minutes_played</th>\n",
       "      <th>is_starter</th>\n",
       "      <th>competition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2576335</td>\n",
       "      <td>May 20, 2018 at 8:45:00 PM GMT+2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Played</td>\n",
       "      <td>SS Lazio</td>\n",
       "      <td>FC Internazionale Milano</td>\n",
       "      <td>3161</td>\n",
       "      <td>1</td>\n",
       "      <td>2.417590</td>\n",
       "      <td>3161</td>\n",
       "      <td>False</td>\n",
       "      <td>3344</td>\n",
       "      <td>53.55</td>\n",
       "      <td>34.00</td>\n",
       "      <td>65.10</td>\n",
       "      <td>39.44</td>\n",
       "      <td>pass</td>\n",
       "      <td>success</td>\n",
       "      <td>foot</td>\n",
       "      <td>Internazionale</td>\n",
       "      <td>1993-02-12</td>\n",
       "      <td>Rafael AlcÃ¢ntara do Nascimento</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "      <td>Italian first division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576335</td>\n",
       "      <td>May 20, 2018 at 8:45:00 PM GMT+2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Played</td>\n",
       "      <td>SS Lazio</td>\n",
       "      <td>FC Internazionale Milano</td>\n",
       "      <td>3161</td>\n",
       "      <td>1</td>\n",
       "      <td>3.904412</td>\n",
       "      <td>3161</td>\n",
       "      <td>False</td>\n",
       "      <td>116349</td>\n",
       "      <td>65.10</td>\n",
       "      <td>39.44</td>\n",
       "      <td>66.15</td>\n",
       "      <td>61.88</td>\n",
       "      <td>pass</td>\n",
       "      <td>success</td>\n",
       "      <td>foot</td>\n",
       "      <td>Internazionale</td>\n",
       "      <td>1991-08-24</td>\n",
       "      <td>MatÃ­as Vecino Falero</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>True</td>\n",
       "      <td>Italian first division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2576335</td>\n",
       "      <td>May 20, 2018 at 8:45:00 PM GMT+2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Played</td>\n",
       "      <td>SS Lazio</td>\n",
       "      <td>FC Internazionale Milano</td>\n",
       "      <td>3161</td>\n",
       "      <td>1</td>\n",
       "      <td>6.484211</td>\n",
       "      <td>3161</td>\n",
       "      <td>False</td>\n",
       "      <td>135903</td>\n",
       "      <td>66.15</td>\n",
       "      <td>61.88</td>\n",
       "      <td>69.30</td>\n",
       "      <td>48.96</td>\n",
       "      <td>pass</td>\n",
       "      <td>success</td>\n",
       "      <td>foot</td>\n",
       "      <td>Internazionale</td>\n",
       "      <td>1994-05-27</td>\n",
       "      <td>JoÃ£o Pedro Cavaco Cancelo</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>True</td>\n",
       "      <td>Italian first division</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id                        match_date match_venue match_status  \\\n",
       "0  2576335  May 20, 2018 at 8:45:00 PM GMT+2         NaN       Played   \n",
       "1  2576335  May 20, 2018 at 8:45:00 PM GMT+2         NaN       Played   \n",
       "2  2576335  May 20, 2018 at 8:45:00 PM GMT+2         NaN       Played   \n",
       "\n",
       "  home_team_name            away_team_name  match_winner  period_id  \\\n",
       "0       SS Lazio  FC Internazionale Milano          3161          1   \n",
       "1       SS Lazio  FC Internazionale Milano          3161          1   \n",
       "2       SS Lazio  FC Internazionale Milano          3161          1   \n",
       "\n",
       "   time_seconds  team_id  is_home player_id  start_x  start_y  end_x  end_y  \\\n",
       "0      2.417590     3161    False      3344    53.55    34.00  65.10  39.44   \n",
       "1      3.904412     3161    False    116349    65.10    39.44  66.15  61.88   \n",
       "2      6.484211     3161    False    135903    66.15    61.88  69.30  48.96   \n",
       "\n",
       "  type_name result_name bodypart_name team_name_short  birth_date  \\\n",
       "0      pass     success          foot  Internazionale  1993-02-12   \n",
       "1      pass     success          foot  Internazionale  1991-08-24   \n",
       "2      pass     success          foot  Internazionale  1994-05-27   \n",
       "\n",
       "                      player_name  jersey_number  minutes_played  is_starter  \\\n",
       "0  Rafael AlcÃ¢ntara do Nascimento              0              69        True   \n",
       "1            MatÃ­as Vecino Falero              0              96        True   \n",
       "2       JoÃ£o Pedro Cavaco Cancelo              0              96        True   \n",
       "\n",
       "              competition  \n",
       "0  Italian first division  \n",
       "1  Italian first division  \n",
       "2  Italian first division  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨ã®ãƒ‘ã‚¹è¨­å®š\n",
    "base_path = '../../data'\n",
    "print(f\"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å…ƒãƒ‘ã‚¹: {base_path}\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "# player_idã‚„match_idã®æ•°å€¤çš„å¤§å°ã«æ„å‘³ã¯ãªã„ã®ã§stringå½¢å¼ã§èª­ã¿è¾¼ã¿\n",
    "train_df = pd.read_csv(f\"{base_path}/match_train_data.csv\", dtype={\"player_id\": \"string\", \"match_id\": \"string\"})\n",
    "test_df = pd.read_csv(f\"{base_path}/match_test_data.csv\", dtype={\"player_id\": \"string\", \"match_id\": \"string\"})\n",
    "actions_df = pd.read_csv(f\"{base_path}/action_data.csv\", dtype={\"player_id\": \"string\", \"match_id\": \"string\"})\n",
    "submission_df = pd.read_csv(f\"{base_path}/sample_submission.csv\")\n",
    "\n",
    "print(f\"trainãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {train_df.shape}\")\n",
    "display(train_df.head(3))\n",
    "\n",
    "print(f\"\\ntestãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {test_df.shape}\")\n",
    "display(test_df.head(3))\n",
    "\n",
    "print(f\"\\nã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {actions_df.shape}\")\n",
    "display(actions_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e550dd29",
   "metadata": {
    "id": "a4Pt7U5biuhV"
   },
   "source": [
    "## ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° - åŸºæœ¬ç‰¹å¾´é‡\n",
    "\n",
    "ã¾ãšã€001ã¨åŒã˜åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7623bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3d_UMBliuhV",
    "outputId": "3eec7699-ba5f-4497-855d-8c6c40c55b20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ãƒãƒ¼ã‚¸å¾Œã®trainãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (27870, 15)\n",
      "\n",
      "ãƒãƒ¼ã‚¸å¾Œã®testãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (12798, 14)\n"
     ]
    }
   ],
   "source": [
    "# æ‰€ä¸ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç°¡å˜ã«è¨ˆç®—ã§ãã‚‹å¹´é½¢ç‰¹å¾´é‡ã‚’è¿½åŠ ã™ã‚‹\n",
    "\n",
    "# 2017/18ã‚·ãƒ¼ã‚ºãƒ³çµ‚äº†æ™‚ç‚¹ã§ã®å¹´é½¢ã‚’è¨ˆç®—\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "train_df['birth_date'] = pd.to_datetime(train_df['birth_date'])\n",
    "train_df['age'] = (train_df['Date'] - train_df['birth_date']).dt.days / 365.25\n",
    "\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "test_df['birth_date'] = pd.to_datetime(test_df['birth_date'])\n",
    "test_df['age'] = (test_df['Date'] - test_df['birth_date']).dt.days / 365.25\n",
    "\n",
    "print(f\"\\nãƒãƒ¼ã‚¸å¾Œã®trainãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {train_df.shape}\")\n",
    "print(f\"\\nãƒãƒ¼ã‚¸å¾Œã®testãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8e12ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_urDy8riuhV",
    "outputId": "ef6080ba-2f4d-42ed-aea8-35cffd58e420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ†æå¯¾è±¡ã¨ãªã‚‹è©¦åˆÃ—é¸æ‰‹: 40505çµ„\n",
      "æŠ½å‡ºã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: 1867094ä»¶\n"
     ]
    }
   ],
   "source": [
    "# ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©¦åˆÃ—é¸æ‰‹ãƒ¬ãƒ™ãƒ«ã®ç‰¹å¾´é‡ã‚’ä½œæˆ\n",
    "\n",
    "# train/testã«å«ã¾ã‚Œã‚‹è©¦åˆÃ—é¸æ‰‹ã®çµ„ã¿åˆã‚ã›ã‚’ä½œæˆã™ã‚‹\n",
    "target_match_players_train = train_df[['match_id', 'player_id']].drop_duplicates()\n",
    "target_match_players_test = test_df[['match_id', 'player_id']].drop_duplicates()\n",
    "target_match_players = pd.concat([target_match_players_train, target_match_players_test]).drop_duplicates()\n",
    "\n",
    "print(f\"åˆ†æå¯¾è±¡ã¨ãªã‚‹è©¦åˆÃ—é¸æ‰‹: {len(target_match_players)}çµ„\")\n",
    "\n",
    "# ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ã€train/testãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹è©¦åˆÃ—é¸æ‰‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿ã‚’æŠ½å‡º\n",
    "relevant_actions = actions_df.merge(\n",
    "    target_match_players,\n",
    "    on=['match_id', 'player_id'],\n",
    "    how='inner'\n",
    ")\n",
    "print(f\"æŠ½å‡ºã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(relevant_actions)}ä»¶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafb9b9a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced_features imported and reloaded (early cell).\n"
     ]
    }
   ],
   "source": [
    "# è¿½åŠ ï¼ˆæ—©ã„æ®µéšã«æŒ¿å…¥ï¼‰: é«˜åº¦ç‰¹å¾´é‡ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®èª­ã¿è¾¼ã¿\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "try:\n",
    "    ROOT = Path.cwd().resolve().parents[1]\n",
    "    if str(ROOT) not in sys.path:\n",
    "        sys.path.append(str(ROOT))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆä¿®æ­£ã‚’åæ˜ ã•ã›ã‚‹ï¼‰\n",
    "from scripts import advanced_features\n",
    "importlib.reload(advanced_features)\n",
    "\n",
    "from scripts.advanced_features import (\n",
    "    build_nstep_chain_features,\n",
    "    build_second_assist_sca_gca,\n",
    "    build_pass_geometry_and_timing,\n",
    "    build_xpass_risk_features,\n",
    "    add_player_trend,\n",
    "    # ğŸ†• æ–°ç‰¹å¾´é‡é–¢æ•°\n",
    "    build_time_based_features,\n",
    "    build_zone_based_features,\n",
    "    build_pass_network_centrality,\n",
    "    build_extended_chain_features,\n",
    "    build_dynamic_positioning_features,\n",
    ")\n",
    "print(\"advanced_features imported and reloaded (early cell).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ff206d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "hXudsW7vjuBf",
    "outputId": "5dcd2476-bef4-4b52-a970-22614a3b7fd9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_home</th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>False</td>\n",
       "      <td>1.05</td>\n",
       "      <td>34.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>True</td>\n",
       "      <td>87.15</td>\n",
       "      <td>33.32</td>\n",
       "      <td>105.0</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>False</td>\n",
       "      <td>8.40</td>\n",
       "      <td>40.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>True</td>\n",
       "      <td>100.80</td>\n",
       "      <td>29.92</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>True</td>\n",
       "      <td>95.55</td>\n",
       "      <td>34.68</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_home  start_x  start_y  end_x  end_y\n",
       "328     False     1.05    34.68    0.0   37.4\n",
       "448      True    87.15    33.32  105.0   37.4\n",
       "905     False     8.40    40.12    0.0   30.6\n",
       "3296     True   100.80    29.92  105.0   30.6\n",
       "4080     True    95.55    34.68  105.0   34.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_home</th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>False</td>\n",
       "      <td>103.95</td>\n",
       "      <td>33.32</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>True</td>\n",
       "      <td>87.15</td>\n",
       "      <td>33.32</td>\n",
       "      <td>105.0</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>False</td>\n",
       "      <td>96.60</td>\n",
       "      <td>27.88</td>\n",
       "      <td>105.0</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>True</td>\n",
       "      <td>100.80</td>\n",
       "      <td>29.92</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>True</td>\n",
       "      <td>95.55</td>\n",
       "      <td>34.68</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_home  start_x  start_y  end_x  end_y\n",
       "328     False   103.95    33.32  105.0   30.6\n",
       "448      True    87.15    33.32  105.0   37.4\n",
       "905     False    96.60    27.88  105.0   37.4\n",
       "3296     True   100.80    29.92  105.0   30.6\n",
       "4080     True    95.55    34.68  105.0   34.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½ç½®ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã¯ã€homeã¨awayã§åŸºæº–ãŒç•°ãªã‚‹\n",
    "# homeã®å ´åˆã¯ã€x=0ãŒè‡ªé™£ã‚´ãƒ¼ãƒ«ãƒ©ã‚¤ãƒ³ã€x=105ãŒæ•µé™£ã‚´ãƒ¼ãƒ«ãƒ©ã‚¤ãƒ³ã€y=0ãŒå³ã‚µã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€y=68ãŒå·¦ã‚µã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«å¯¾å¿œã™ã‚‹\n",
    "# awayã§ã¯é€†ã«ãªã‚‹ãŸã‚ã€homeã®é¸æ‰‹ã¨awayã®é¸æ‰‹ã§å¹³å‡çš„ãªx,yã®å€¤ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ãŒã§ããªã„\n",
    "display(relevant_actions[(relevant_actions[\"type_name\"] == \"shot\") & (relevant_actions[\"result_name\"] == \"success\")][[\"is_home\", \"start_x\", \"start_y\", \"end_x\", \"end_y\"]].head())\n",
    "\n",
    "# ãã“ã§ã€ä½ç½®ã‚’æ¨™æº–åŒ–ã™ã‚‹ãŸã‚ã€awayãƒãƒ¼ãƒ ã®å ´åˆã¯ã€x' = 105-x, y' = 68-yã«ä¿®æ­£ã™ã‚‹\n",
    "relevant_actions.loc[relevant_actions['is_home'] == False, 'start_x'] = 105 - relevant_actions.loc[relevant_actions['is_home'] == False, 'start_x']\n",
    "relevant_actions.loc[relevant_actions['is_home'] == False, 'end_x'] = 105 - relevant_actions.loc[relevant_actions['is_home'] == False, 'end_x']\n",
    "relevant_actions.loc[relevant_actions['is_home'] == False, 'start_y'] = 68 - relevant_actions.loc[relevant_actions['is_home'] == False, 'start_y']\n",
    "relevant_actions.loc[relevant_actions['is_home'] == False, 'end_y'] = 68 - relevant_actions.loc[relevant_actions['is_home'] == False, 'end_y']\n",
    "\n",
    "relevant_actions[(relevant_actions[\"type_name\"] == \"shot\") & (relevant_actions[\"result_name\"] == \"success\")][[\"is_home\", \"start_x\", \"start_y\", \"end_x\", \"end_y\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86955e67",
   "metadata": {
    "id": "sQOHu5iUnWLA"
   },
   "source": [
    "is_homeã®å€¤ã«é–¢ä¿‚ãªãã€ã‚´ãƒ¼ãƒ«ã—ãŸå ´åˆend_x=105ã¨ãªã£ã¦ãŠã‚Šã€ä½ç½®ãŒæ¨™æº–åŒ–ã•ã‚Œã¦ã„ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baa26226",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "5LCBi5A3joBl",
    "outputId": "935dbfa8-dd0f-44c5-e3f9-c2e8d4b26b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (40041, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>action_count</th>\n",
       "      <th>avg_x</th>\n",
       "      <th>avg_y</th>\n",
       "      <th>minutes_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>80</td>\n",
       "      <td>53.84</td>\n",
       "      <td>30.40</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>16</td>\n",
       "      <td>77.44</td>\n",
       "      <td>43.05</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>30</td>\n",
       "      <td>67.24</td>\n",
       "      <td>35.36</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  action_count  avg_x  avg_y  minutes_played\n",
       "0  2499719    120339            80  53.84  30.40              70\n",
       "1  2499719     12829            16  77.44  43.05              98\n",
       "2  2499719     14763            30  67.24  35.36              75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# åŸºæœ¬çš„ãªçµ±è¨ˆç‰¹å¾´é‡ã®ä½œæˆ\n",
    "# groupby()ã¨agg()ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€åˆ—ã”ã¨ã«ä»»æ„ã®é›†è¨ˆæ–¹æ³•ã‚’æŒ‡å®šã§ãã‚‹ã€‚\n",
    "match_player_stats = (\n",
    "    relevant_actions\n",
    "    .groupby(['match_id', 'player_id'])\n",
    "    .agg(\n",
    "        action_count   = ('type_name', 'size'), # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°åˆè¨ˆ\n",
    "        avg_x          = ('start_x', 'mean'), # å¹³å‡ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆå‰å¾Œæ–¹å‘ï¼‰\n",
    "        avg_y          = ('start_y', 'mean'), # å¹³å‡ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆå·¦å³æ–¹å‘ï¼‰\n",
    "        minutes_played = ('minutes_played', 'first')  # å‡ºå ´æ™‚é–“\n",
    "    )\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(f\"ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {match_player_stats.shape}\")\n",
    "display(match_player_stats.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea35255",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing advanced features from relevant_actions (early) ...\n",
      "Advanced feature blocks created (early).\n"
     ]
    }
   ],
   "source": [
    "# è¿½åŠ ï¼ˆrelevant_actionsç›´å¾Œï¼‰: é«˜åº¦ç‰¹å¾´é‡è¨ˆç®—\n",
    "print(\"Computing advanced features from relevant_actions (early) ...\")\n",
    "\n",
    "nstep_block = build_nstep_chain_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    team_col=\"team_id\",\n",
    "    type_col=\"type_name\",\n",
    "    n_steps=3,\n",
    "    gamma=0.7,\n",
    ")\n",
    "\n",
    "second_assist, sca1, sca2, gca1, gca2 = build_second_assist_sca_gca(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    team_col=\"team_id\",\n",
    "    type_col=\"type_name\",\n",
    "    result_col=\"result_name\",\n",
    ")\n",
    "\n",
    "pass_geom, pass_latency = build_pass_geometry_and_timing(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    type_col=\"type_name\",\n",
    ")\n",
    "\n",
    "xpass_risk = build_xpass_risk_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    type_col=\"type_name\",\n",
    "    result_col=\"result_name\",\n",
    ")\n",
    "\n",
    "print(\"Advanced feature blocks created (early).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ec0719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¨ˆç®—ä¸­: æ–°ç‰¹å¾´é‡ (æ™‚é–“å¸¯åˆ¥/ã‚¾ãƒ¼ãƒ³åˆ¥/ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯/æ‹¡å¼µé€£é–/å‹•çš„ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°)...\n",
      "æ–°ç‰¹å¾´é‡ãƒ–ãƒ­ãƒƒã‚¯ä½œæˆå®Œäº†\n",
      "  - æ™‚é–“å¸¯åˆ¥: 40041è¡Œ\n",
      "  - ã‚¾ãƒ¼ãƒ³åˆ¥: 40041è¡Œ\n",
      "  - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­å¿ƒæ€§: 39831è¡Œ\n",
      "  - æ‹¡å¼µé€£é–: 40041è¡Œ\n",
      "  - å‹•çš„ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°: 40041è¡Œ\n"
     ]
    }
   ],
   "source": [
    "# ğŸ†• æ–°ç‰¹å¾´é‡ã®è¨ˆç®— (EXP0025è¿½åŠ )\n",
    "print(\"è¨ˆç®—ä¸­: æ–°ç‰¹å¾´é‡ (æ™‚é–“å¸¯åˆ¥/ã‚¾ãƒ¼ãƒ³åˆ¥/ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯/æ‹¡å¼µé€£é–/å‹•çš„ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°)...\")\n",
    "\n",
    "# 1. æ™‚é–“å¸¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹\n",
    "time_based_features = build_time_based_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    time_col=\"time_seconds\",\n",
    "    period_col=\"period_id\"\n",
    ")\n",
    "\n",
    "# 2. ã‚¾ãƒ¼ãƒ³åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å¯†åº¦\n",
    "zone_based_features = build_zone_based_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\"\n",
    ")\n",
    "\n",
    "# 3. ãƒ‘ã‚¹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­å¿ƒæ€§\n",
    "network_centrality_features = build_pass_network_centrality(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    team_col=\"team_id\",\n",
    "    type_col=\"type_name\",\n",
    "    time_col=\"time_seconds\"\n",
    ")\n",
    "\n",
    "# 4. æ‹¡å¼µã‚·ãƒ¼ã‚±ãƒ³ã‚¹é€£é– (7æ‰‹å…ˆ)\n",
    "extended_chain_features = build_extended_chain_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    team_col=\"team_id\",\n",
    "    type_col=\"type_name\",\n",
    "    n_steps=7,\n",
    "    gamma=0.6\n",
    ")\n",
    "\n",
    "# 5. å‹•çš„ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°\n",
    "dynamic_positioning_features = build_dynamic_positioning_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\"\n",
    ")\n",
    "\n",
    "print(\"æ–°ç‰¹å¾´é‡ãƒ–ãƒ­ãƒƒã‚¯ä½œæˆå®Œäº†\")\n",
    "print(f\"  - æ™‚é–“å¸¯åˆ¥: {len(time_based_features)}è¡Œ\")\n",
    "print(f\"  - ã‚¾ãƒ¼ãƒ³åˆ¥: {len(zone_based_features)}è¡Œ\")\n",
    "print(f\"  - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­å¿ƒæ€§: {len(network_centrality_features)}è¡Œ\")\n",
    "print(f\"  - æ‹¡å¼µé€£é–: {len(extended_chain_features)}è¡Œ\")\n",
    "print(f\"  - å‹•çš„ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°: {len(dynamic_positioning_features)}è¡Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1abe8e04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "RAZHAVEanr4A",
    "outputId": "a989b03e-8c48-472d-9aaf-03b24fac09bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (40041, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>goal_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  goal_count\n",
       "0  2499719    120339           0\n",
       "1  2499719     12829           2\n",
       "2  2499719     14763           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ã‚´ãƒ¼ãƒ«æ•°ã®é›†è¨ˆ\n",
    "# type_nameã«shotãŒå«ã¾ã‚Œã¦ã€æˆåŠŸã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚´ãƒ¼ãƒ«ã«ãªã‚‹\n",
    "is_shot  = relevant_actions['type_name'].isin(['shot', 'shot_freekick', 'shot_penalty'])\n",
    "is_success = relevant_actions['result_name'].eq('success')\n",
    "is_goal = (is_shot & is_success).astype(int)\n",
    "\n",
    "match_player_goals = (\n",
    "    relevant_actions\n",
    "    .assign(is_goal=is_goal) # is_goalåˆ—ã‚’è¿½åŠ \n",
    "    .groupby(['match_id', 'player_id'], as_index=False)['is_goal']\n",
    "    .sum() # ã‚´ãƒ¼ãƒ«ã§ã‚ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆè¨ˆ\n",
    "    .rename(columns={'is_goal': 'goal_count'})\n",
    ")\n",
    "\n",
    "print(f\"ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {match_player_goals.shape}\")\n",
    "display(match_player_goals.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b94f8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "ZHhHF5_tiuhV",
    "outputId": "dfa2bb40-8395-43e4-c7c8-afe51f28a8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (40041, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>type_bad_touch_count</th>\n",
       "      <th>type_clearance_count</th>\n",
       "      <th>type_corner_crossed_count</th>\n",
       "      <th>type_corner_short_count</th>\n",
       "      <th>type_cross_count</th>\n",
       "      <th>type_dribble_count</th>\n",
       "      <th>type_foul_count</th>\n",
       "      <th>type_freekick_crossed_count</th>\n",
       "      <th>type_freekick_short_count</th>\n",
       "      <th>type_goalkick_count</th>\n",
       "      <th>type_interception_count</th>\n",
       "      <th>type_keeper_save_count</th>\n",
       "      <th>type_pass_count</th>\n",
       "      <th>type_shot_count</th>\n",
       "      <th>type_shot_freekick_count</th>\n",
       "      <th>type_shot_penalty_count</th>\n",
       "      <th>type_tackle_count</th>\n",
       "      <th>type_take_on_count</th>\n",
       "      <th>type_throw_in_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  type_bad_touch_count  type_clearance_count  \\\n",
       "0  2499719    120339                     0                     2   \n",
       "1  2499719     12829                     0                     0   \n",
       "2  2499719     14763                     0                     0   \n",
       "\n",
       "   type_corner_crossed_count  type_corner_short_count  type_cross_count  \\\n",
       "0                          0                        0                 2   \n",
       "1                          0                        0                 1   \n",
       "2                          0                        0                 1   \n",
       "\n",
       "   type_dribble_count  type_foul_count  type_freekick_crossed_count  \\\n",
       "0                   4                0                            0   \n",
       "1                   2                0                            0   \n",
       "2                   5                3                            0   \n",
       "\n",
       "   type_freekick_short_count  type_goalkick_count  type_interception_count  \\\n",
       "0                          0                    0                        5   \n",
       "1                          0                    0                        0   \n",
       "2                          0                    0                        0   \n",
       "\n",
       "   type_keeper_save_count  type_pass_count  type_shot_count  \\\n",
       "0                       0               66                1   \n",
       "1                       0               11                2   \n",
       "2                       0               17                2   \n",
       "\n",
       "   type_shot_freekick_count  type_shot_penalty_count  type_tackle_count  \\\n",
       "0                         0                        0                  0   \n",
       "1                         0                        0                  0   \n",
       "2                         0                        0                  1   \n",
       "\n",
       "   type_take_on_count  type_throw_in_count  \n",
       "0                   0                    0  \n",
       "1                   0                    0  \n",
       "2                   1                    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—æ•°ã®é›†è¨ˆ\n",
    "# type_nameåˆ—ã®å€¤ã”ã¨ã«æ•°ã‚’é›†è¨ˆã™ã‚‹\n",
    "action_type_stats = (\n",
    "    relevant_actions\n",
    "    .groupby(['match_id', 'player_id', 'type_name'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)  # type_name ã‚’åˆ—ã«å±•é–‹ã€æ¬ æã¯0ã§åŸ‹ã‚ã‚‹\n",
    "    .rename_axis(None, axis=1)\n",
    "    .add_prefix('type_').add_suffix('_count') # åˆ—åã«æ¥é ­è¾ã¨æ¥å°¾è¾ã‚’è¿½åŠ ã™ã‚‹ï¼ˆtype_nameãŒshotãªã‚‰ã€Œtype_shot_countã€ã«ãªã‚‹ï¼‰\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(f\"ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {action_type_stats.shape}\")\n",
    "display(action_type_stats.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "401b8c4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMpQ9RL1n1h8",
    "lines_to_next_cell": 2,
    "outputId": "e3a47fbf-85f2-44ee-d77c-2acb13ee8c48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ãƒãƒ¼ã‚¸å¾Œã®trainãƒ‡ãƒ¼ã‚¿shape: (27870, 39)\n",
      "ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ãƒãƒ¼ã‚¸å¾Œã®testãƒ‡ãƒ¼ã‚¿shape: (12798, 38)\n"
     ]
    }
   ],
   "source": [
    "# ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã‚’train/testã¸ãƒãƒ¼ã‚¸\n",
    "train_df = (\n",
    "    train_df\n",
    "    .merge(match_player_stats, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(match_player_goals, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(action_type_stats, on=['match_id', 'player_id'], how='left')\n",
    ")\n",
    "\n",
    "\n",
    "test_df = (\n",
    "    test_df\n",
    "    .merge(match_player_stats, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(match_player_goals, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(action_type_stats, on=['match_id', 'player_id'], how='left')\n",
    ")\n",
    "\n",
    "\n",
    "action_type_cols = [col for col in train_df.columns if col.startswith('type_')]\n",
    "stats_count_cols = ['action_count', 'minutes_played', 'goal_count']\n",
    "\n",
    "for col in action_type_cols + stats_count_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0)\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(0)\n",
    "\n",
    "print(f\"ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ãƒãƒ¼ã‚¸å¾Œã®trainãƒ‡ãƒ¼ã‚¿shape: {train_df.shape}\")\n",
    "print(f\"ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ãƒãƒ¼ã‚¸å¾Œã®testãƒ‡ãƒ¼ã‚¿shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755da67",
   "metadata": {
    "id": "vGTCBG_BiuhV"
   },
   "source": [
    "## ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° - å¿œç”¨ç‰¹å¾´é‡\n",
    "\n",
    "ã“ã“ã‹ã‚‰ã€ã‚ˆã‚Šé«˜åº¦ãªç‰¹å¾´é‡ã‚’ä½œæˆã—ã¦ã„ãã¾ã™ã€‚å„ç‰¹å¾´é‡ã®æ„å›³ã¨è¨ˆç®—æ–¹æ³•ã‚’è©³ã—ãèª¬æ˜ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e83c8d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "09a43976bef243599b2e9b64cffb91b4",
      "d3e34a9bb0d24577acc83d7ae4b2486d",
      "dcffd72448ea44bf9ec8aec5b31762f6",
      "3a83f4956d7d41938ef54f146a5cc541",
      "69216dc0f0f4422e8166c4a8f8abe666",
      "79fcd266aa524e9b9d656b2eab1a8cd3",
      "09a7b0f32ef942afb2963f355e80a8bc",
      "dc043a4a5ed74b1c9b6cc8e027e5b2b6",
      "5e50717143ae4771b600c2a5f73488e2",
      "5b6ef11c003d4a79b3924bc396c0ff56",
      "78773c5f4ebc47fea4077d687ab0ea0c"
     ]
    },
    "id": "maM2mFbTiuhV",
    "lines_to_next_cell": 1,
    "outputId": "6c028ca4-a3f4-41f8-b6f5-79d096d17f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æˆåŠŸç‡ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a510d3ed5b144b83a584091a12a86973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating success rates:   0%|          | 0/40041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (40041, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>pass_success_rate</th>\n",
       "      <th>shot_success_rate</th>\n",
       "      <th>take_on_success_rate</th>\n",
       "      <th>cross_success_rate</th>\n",
       "      <th>corner_crossed_success_rate</th>\n",
       "      <th>freekick_crossed_success_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  pass_success_rate  shot_success_rate  \\\n",
       "0  2499719    120339           0.924242                0.0   \n",
       "1  2499719     12829           0.636364                1.0   \n",
       "2  2499719     14763           0.647059                0.5   \n",
       "\n",
       "   take_on_success_rate  cross_success_rate  corner_crossed_success_rate  \\\n",
       "0                   0.0                 1.0                          0.0   \n",
       "1                   0.0                 0.0                          0.0   \n",
       "2                   1.0                 0.0                          0.0   \n",
       "\n",
       "   freekick_crossed_success_rate  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æˆåŠŸç‡ç‰¹å¾´é‡\n",
    "# ã‚¢ã‚·ã‚¹ãƒˆã«ç¹‹ãŒã‚‹å¯èƒ½æ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã€å„ç¨®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æˆåŠŸç‡ã‚’è¨ˆç®—ã™ã‚‹\n",
    "\n",
    "# æˆåŠŸç‡ã‚’è¨ˆç®—ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—\n",
    "action_types_with_result = ['pass', 'shot', 'take_on', 'cross', 'corner_crossed', 'freekick_crossed']  # take_onã¯ãƒ‰ãƒªãƒ–ãƒ«ã§ã®ä»•æ›ã‘\n",
    "\n",
    "success_rates_list = []\n",
    "print(\"ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æˆåŠŸç‡ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "for (match_id, player_id), group in tqdm(relevant_actions.groupby(['match_id', 'player_id']), desc=\"Calculating success rates\"):\n",
    "    row_data = {'match_id': match_id, 'player_id': player_id}\n",
    "\n",
    "    for action_type in action_types_with_result:\n",
    "        type_actions = group[group['type_name'] == action_type] # å¯¾è±¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º\n",
    "\n",
    "        if len(type_actions) > 0:\n",
    "            success_count = len(type_actions[type_actions['result_name'] == 'success'])\n",
    "            total_count = len(type_actions)\n",
    "\n",
    "            # æˆåŠŸç‡ã‚’è¨ˆç®—\n",
    "            success_rate = success_count / total_count\n",
    "            row_data[f'{action_type}_success_rate'] = success_rate\n",
    "        else:\n",
    "            # è©²å½“ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã¯0\n",
    "            row_data[f'{action_type}_success_rate'] = 0\n",
    "\n",
    "    success_rates_list.append(row_data)\n",
    "\n",
    "success_rates = pd.DataFrame(success_rates_list)\n",
    "\n",
    "print(f\"ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {success_rates.shape}\")\n",
    "display(success_rates.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b0bff5f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced features merged (early).\n",
      "ğŸ†• æ–°ç‰¹å¾´é‡ 25å€‹ã‚’è¿½åŠ ã—ã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "# è¿½åŠ ï¼ˆãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ãƒãƒ¼ã‚¸ã®ç›´å‰ï¼‰: é«˜åº¦ç‰¹å¾´é‡ã®ãƒãƒ¼ã‚¸\n",
    "def _merge_many(df, parts):\n",
    "    for part in parts:\n",
    "        if part is None or (hasattr(part, \"empty\") and part.empty):\n",
    "            continue\n",
    "        df = df.merge(part, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "    return df\n",
    "\n",
    "train_df = _merge_many(\n",
    "    train_df,\n",
    "    [\n",
    "        nstep_block,\n",
    "        second_assist,\n",
    "        sca1,\n",
    "        sca2,\n",
    "        gca1,\n",
    "        gca2,\n",
    "        pass_geom,\n",
    "        pass_latency,\n",
    "        xpass_risk,\n",
    "        # ğŸ†• æ–°ç‰¹å¾´é‡\n",
    "        time_based_features,\n",
    "        zone_based_features,\n",
    "        network_centrality_features,\n",
    "        extended_chain_features,\n",
    "        dynamic_positioning_features,\n",
    "    ],\n",
    ")\n",
    "\n",
    "test_df = _merge_many(\n",
    "    test_df,\n",
    "    [\n",
    "        nstep_block,\n",
    "        second_assist,\n",
    "        sca1,\n",
    "        sca2,\n",
    "        gca1,\n",
    "        gca2,\n",
    "        pass_geom,\n",
    "        pass_latency,\n",
    "        xpass_risk,\n",
    "        # ğŸ†• æ–°ç‰¹å¾´é‡\n",
    "        time_based_features,\n",
    "        zone_based_features,\n",
    "        network_centrality_features,\n",
    "        extended_chain_features,\n",
    "        dynamic_positioning_features,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Fill NA and typesï¼ˆã“ã“ã§æ¬ æã‚’æ½°ã™ï¼‰\n",
    "count_cols = [\"second_assist_count\", \"SCA_1\", \"SCA_2\", \"GCA_1\", \"GCA_2\"]\n",
    "for col in count_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0).astype(int)\n",
    "        test_df[col] = test_df[col].fillna(0).astype(int)\n",
    "\n",
    "num_cols = [\n",
    "    \"nstep_to_shot\",\n",
    "    \"nstep_xt_delta\",\n",
    "    \"pass_dist_mean\",\n",
    "    \"pass_dist_max\",\n",
    "    \"to_goal_angle_abs_mean\",\n",
    "    \"to_goal_dist_mean\",\n",
    "    \"pass_to_shot_latency_mean\",\n",
    "    \"pass_to_shot_latency_min\",\n",
    "    \"risk_creativity_sum\",\n",
    "    \"xpass_mean\",\n",
    "    \"xpass_min\",\n",
    "    \"pass_success_minus_xpass\",\n",
    "    \"xpass_deep_mean\",\n",
    "    \"xpass_box_mean\",\n",
    "]\n",
    "for col in num_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0.0)\n",
    "        test_df[col] = test_df[col].fillna(0.0)\n",
    "\n",
    "# ğŸ†• æ–°ç‰¹å¾´é‡ã®æ¬ æå€¤å‡¦ç†\n",
    "new_feature_cols = [\n",
    "    # æ™‚é–“å¸¯åˆ¥\n",
    "    \"first_half_actions\", \"second_half_actions\", \"final_15min_actions\",\n",
    "    \"early_10min_actions\", \"time_weighted_intensity\",\n",
    "    # ã‚¾ãƒ¼ãƒ³åˆ¥\n",
    "    \"defensive_zone_actions\", \"middle_zone_actions\", \"attacking_zone_actions\",\n",
    "    \"halfspace_left_actions\", \"halfspace_right_actions\", \"central_corridor_actions\",\n",
    "    \"final_third_penetrations\", \"box_entries\",\n",
    "    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­å¿ƒæ€§\n",
    "    \"betweenness_centrality\", \"closeness_centrality\", \"degree_centrality\",\n",
    "    \"pass_receiver_diversity\", \"unique_pass_partners\",\n",
    "    # æ‹¡å¼µé€£é–\n",
    "    \"longchain_to_shot\", \"longchain_xt_delta\",\n",
    "    # å‹•çš„ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°\n",
    "    \"position_variance_x\", \"position_variance_y\", \"position_range_x\",\n",
    "    \"position_range_y\", \"avg_action_distance\",\n",
    "]\n",
    "for col in new_feature_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0.0)\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(0.0)\n",
    "\n",
    "print(\"Advanced features merged (early).\")\n",
    "print(f\"ğŸ†• æ–°ç‰¹å¾´é‡ {len(new_feature_cols)}å€‹ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef22e643",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿½åŠ ã•ã‚ŒãŸé«˜åº¦ç‰¹å¾´é‡: 38å€‹ (ğŸ†•æ–°ç‰¹å¾´é‡å«ã‚€)\n"
     ]
    }
   ],
   "source": [
    "# è¿½åŠ ï¼ˆall_featureså®šç¾©ã‚»ãƒ«ã®ç›´å¾Œã‚’æƒ³å®šï¼‰: all_features ã«é«˜åº¦ç‰¹å¾´é‡ã‚’å«ã‚ã‚‹\n",
    "advanced_candidates = [\n",
    "    \"second_assist_count\",\n",
    "    \"SCA_1\",\n",
    "    \"SCA_2\",\n",
    "    \"GCA_1\",\n",
    "    \"GCA_2\",\n",
    "    \"nstep_to_shot\",\n",
    "    \"nstep_xt_delta\",\n",
    "    \"pass_dist_mean\",\n",
    "    \"pass_dist_max\",\n",
    "    \"to_goal_angle_abs_mean\",\n",
    "    \"to_goal_dist_mean\",\n",
    "    \"pass_to_shot_latency_mean\",\n",
    "    \"pass_to_shot_latency_min\",\n",
    "    \"risk_creativity_sum\",\n",
    "    \"xpass_mean\",\n",
    "    \"xpass_min\",\n",
    "    \"pass_success_minus_xpass\",\n",
    "    \"xpass_deep_mean\",\n",
    "    \"xpass_box_mean\",\n",
    "    # æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰\n",
    "    \"xAG_expanding_mean\",\n",
    "    \"xAG_rolling3_mean\",\n",
    "    \"xAG_diff_prev\",\n",
    "    # ğŸ†• æ–°ç‰¹å¾´é‡\n",
    "    \"first_half_actions\", \"second_half_actions\", \"final_15min_actions\",\n",
    "    \"early_10min_actions\", \"time_weighted_intensity\",\n",
    "    \"defensive_zone_actions\", \"middle_zone_actions\", \"attacking_zone_actions\",\n",
    "    \"halfspace_left_actions\", \"halfspace_right_actions\", \"central_corridor_actions\",\n",
    "    \"final_third_penetrations\", \"box_entries\",\n",
    "    \"betweenness_centrality\", \"closeness_centrality\", \"degree_centrality\",\n",
    "    \"pass_receiver_diversity\", \"unique_pass_partners\",\n",
    "    \"longchain_to_shot\", \"longchain_xt_delta\",\n",
    "    \"position_variance_x\", \"position_variance_y\", \"position_range_x\",\n",
    "    \"position_range_y\", \"avg_action_distance\",\n",
    "]\n",
    "advanced_features = [c for c in advanced_candidates if c in train_df.columns]\n",
    "try:\n",
    "    all_features = list(dict.fromkeys(all_features + advanced_features))\n",
    "except NameError:\n",
    "    _advanced_features_pending = advanced_features\n",
    "print(f\"è¿½åŠ ã•ã‚ŒãŸé«˜åº¦ç‰¹å¾´é‡: {len(advanced_features)}å€‹ (ğŸ†•æ–°ç‰¹å¾´é‡å«ã‚€)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13635c99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "yjC2SnrIiuhW",
    "outputId": "ac96bf5f-28cf-4e2f-a395-3c52f5b32736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ç½®ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\n",
      "\n",
      "ã‚¾ãƒ¼ãƒ³åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³çµ±è¨ˆ:\n",
      "  defensive ã‚¨ãƒªã‚¢: å¹³å‡ 13.5 ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n",
      "  midfield  ã‚¨ãƒªã‚¢: å¹³å‡ 20.8 ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n",
      "  attacking ã‚¨ãƒªã‚¢: å¹³å‡ 12.3 ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n",
      "\n",
      "ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (40041, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>start_zone</th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>zone_attacking_actions</th>\n",
       "      <th>zone_defensive_actions</th>\n",
       "      <th>zone_midfield_actions</th>\n",
       "      <th>zone_attacking_actions_ratio</th>\n",
       "      <th>zone_midfield_actions_ratio</th>\n",
       "      <th>zone_defensive_actions_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "start_zone match_id player_id  zone_attacking_actions  zone_defensive_actions  \\\n",
       "0           2499719    120339                      19                      16   \n",
       "1           2499719     12829                      12                       0   \n",
       "2           2499719     14763                      15                       5   \n",
       "\n",
       "start_zone  zone_midfield_actions  zone_attacking_actions_ratio  \\\n",
       "0                              45                        0.2375   \n",
       "1                               4                        0.7500   \n",
       "2                              10                        0.5000   \n",
       "\n",
       "start_zone  zone_midfield_actions_ratio  zone_defensive_actions_ratio  \n",
       "0                              0.562500                      0.200000  \n",
       "1                              0.250000                      0.000000  \n",
       "2                              0.333333                      0.166667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ä½ç½®ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡\n",
    "# ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸Šã§ã®æ´»å‹•ã‚¨ãƒªã‚¢ã‚’åˆ†æã—ã€æ”»æ’ƒçš„ãªé¸æ‰‹ã‚’è­˜åˆ¥\n",
    "\n",
    "print(\"ä½ç½®ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "# ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’3ã¤ã®ã‚¨ãƒªã‚¢ã«åˆ†å‰²ï¼ˆxåº§æ¨™ãƒ™ãƒ¼ã‚¹ï¼‰\n",
    "def categorize_position(x):\n",
    "    \"\"\"xåº§æ¨™ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚¨ãƒªã‚¢ã‚’åˆ¤å®š\"\"\"\n",
    "    if x < 35:\n",
    "        return 'defensive'  # å®ˆå‚™çš„ã‚¨ãƒªã‚¢\n",
    "    elif x < 70:\n",
    "        return 'midfield'   # ä¸­ç›¤ã‚¨ãƒªã‚¢\n",
    "    else:\n",
    "        return 'attacking'  # æ”»æ’ƒçš„ã‚¨ãƒªã‚¢\n",
    "\n",
    "# å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¨ãƒªã‚¢ã‚’åˆ¤å®š\n",
    "relevant_actions['start_zone'] = relevant_actions['start_x'].apply(categorize_position)\n",
    "\n",
    "# ã‚¾ãƒ¼ãƒ³åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°ã‚’é›†è¨ˆ\n",
    "zone_actions = (\n",
    "    relevant_actions\n",
    "    .pivot_table(\n",
    "        index=['match_id', 'player_id'],\n",
    "        columns='start_zone',\n",
    "        values='period_id',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "    .add_prefix('zone_')\n",
    "    .add_suffix('_actions')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# å„ã‚¾ãƒ¼ãƒ³ã§ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¯”ç‡ã‚’è¨ˆç®—\n",
    "zone_actions['total_actions'] = (\n",
    "    zone_actions.get('zone_defensive_actions', 0) +\n",
    "    zone_actions.get('zone_midfield_actions', 0) +\n",
    "    zone_actions.get('zone_attacking_actions', 0)\n",
    ")\n",
    "\n",
    "zone_actions['zone_attacking_actions_ratio'] = np.where(\n",
    "    zone_actions['total_actions'] > 0,\n",
    "    zone_actions.get('zone_attacking_actions', 0) / zone_actions['total_actions'],\n",
    "    0\n",
    ")\n",
    "\n",
    "zone_actions['zone_midfield_actions_ratio'] = np.where(\n",
    "    zone_actions['total_actions'] > 0,\n",
    "    zone_actions.get('zone_midfield_actions', 0) / zone_actions['total_actions'],\n",
    "    0\n",
    ")\n",
    "\n",
    "zone_actions['zone_defensive_actions_ratio'] = np.where(\n",
    "    zone_actions['total_actions'] > 0,\n",
    "    zone_actions.get('zone_defensive_actions', 0) / zone_actions['total_actions'],\n",
    "    0\n",
    ")\n",
    "zone_actions = zone_actions.drop(columns=['total_actions'])\n",
    "\n",
    "print(f\"\\nã‚¾ãƒ¼ãƒ³åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³çµ±è¨ˆ:\")\n",
    "for zone in ['defensive', 'midfield', 'attacking']:\n",
    "    col_name = f'zone_{zone}_actions'\n",
    "    if col_name in zone_actions.columns:\n",
    "        mean_val = zone_actions[col_name].mean()\n",
    "        print(f\"  {zone:10s}ã‚¨ãƒªã‚¢: å¹³å‡ {mean_val:.1f} ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\")\n",
    "\n",
    "print(f\"\\nä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {zone_actions.shape}\")\n",
    "display(zone_actions.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64cc03e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "W2m7WIjGiuhW",
    "outputId": "87b1e9c5-034e-4850-89e4-65e627031806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ™‚é–“æ­£è¦åŒ–ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\n",
      "\n",
      "ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (40041, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>action_count_per_minute</th>\n",
       "      <th>goal_count_per_minute</th>\n",
       "      <th>type_bad_touch_count_per_minute</th>\n",
       "      <th>type_clearance_count_per_minute</th>\n",
       "      <th>type_corner_crossed_count_per_minute</th>\n",
       "      <th>type_corner_short_count_per_minute</th>\n",
       "      <th>type_cross_count_per_minute</th>\n",
       "      <th>type_dribble_count_per_minute</th>\n",
       "      <th>type_foul_count_per_minute</th>\n",
       "      <th>type_freekick_crossed_count_per_minute</th>\n",
       "      <th>type_freekick_short_count_per_minute</th>\n",
       "      <th>type_goalkick_count_per_minute</th>\n",
       "      <th>type_interception_count_per_minute</th>\n",
       "      <th>type_keeper_save_count_per_minute</th>\n",
       "      <th>type_pass_count_per_minute</th>\n",
       "      <th>type_shot_count_per_minute</th>\n",
       "      <th>type_shot_freekick_count_per_minute</th>\n",
       "      <th>type_shot_penalty_count_per_minute</th>\n",
       "      <th>type_tackle_count_per_minute</th>\n",
       "      <th>type_take_on_count_per_minute</th>\n",
       "      <th>type_throw_in_count_per_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  action_count_per_minute  goal_count_per_minute  \\\n",
       "0  2499719    120339                 1.142857               0.000000   \n",
       "1  2499719     12829                 0.163265               0.020408   \n",
       "2  2499719     14763                 0.400000               0.013333   \n",
       "\n",
       "   type_bad_touch_count_per_minute  type_clearance_count_per_minute  \\\n",
       "0                              0.0                         0.028571   \n",
       "1                              0.0                         0.000000   \n",
       "2                              0.0                         0.000000   \n",
       "\n",
       "   type_corner_crossed_count_per_minute  type_corner_short_count_per_minute  \\\n",
       "0                                   0.0                                 0.0   \n",
       "1                                   0.0                                 0.0   \n",
       "2                                   0.0                                 0.0   \n",
       "\n",
       "   type_cross_count_per_minute  type_dribble_count_per_minute  \\\n",
       "0                     0.028571                       0.057143   \n",
       "1                     0.010204                       0.020408   \n",
       "2                     0.013333                       0.066667   \n",
       "\n",
       "   type_foul_count_per_minute  type_freekick_crossed_count_per_minute  \\\n",
       "0                        0.00                                     0.0   \n",
       "1                        0.00                                     0.0   \n",
       "2                        0.04                                     0.0   \n",
       "\n",
       "   type_freekick_short_count_per_minute  type_goalkick_count_per_minute  \\\n",
       "0                                   0.0                             0.0   \n",
       "1                                   0.0                             0.0   \n",
       "2                                   0.0                             0.0   \n",
       "\n",
       "   type_interception_count_per_minute  type_keeper_save_count_per_minute  \\\n",
       "0                            0.071429                                0.0   \n",
       "1                            0.000000                                0.0   \n",
       "2                            0.000000                                0.0   \n",
       "\n",
       "   type_pass_count_per_minute  type_shot_count_per_minute  \\\n",
       "0                    0.942857                    0.014286   \n",
       "1                    0.112245                    0.020408   \n",
       "2                    0.226667                    0.026667   \n",
       "\n",
       "   type_shot_freekick_count_per_minute  type_shot_penalty_count_per_minute  \\\n",
       "0                                  0.0                                 0.0   \n",
       "1                                  0.0                                 0.0   \n",
       "2                                  0.0                                 0.0   \n",
       "\n",
       "   type_tackle_count_per_minute  type_take_on_count_per_minute  \\\n",
       "0                      0.000000                       0.000000   \n",
       "1                      0.000000                       0.000000   \n",
       "2                      0.013333                       0.013333   \n",
       "\n",
       "   type_throw_in_count_per_minute  \n",
       "0                             0.0  \n",
       "1                             0.0  \n",
       "2                             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# æ™‚é–“æ­£è¦åŒ–ç‰¹å¾´é‡\n",
    "# å‡ºå ´æ™‚é–“ã«ã‚ˆã‚‹å½±éŸ¿ã‚’æ’é™¤ã—ã€å…¬å¹³ãªæ¯”è¼ƒã‚’å¯èƒ½ã«ã™ã‚‹\n",
    "\n",
    "print(\"æ™‚é–“æ­£è¦åŒ–ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "per_minute_features = match_player_stats.copy()\n",
    "\n",
    "# å…¨ä½“ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°ã®æ­£è¦åŒ–\n",
    "per_minute_features['action_count_per_minute'] = np.where(\n",
    "    per_minute_features['minutes_played'] > 0,\n",
    "    per_minute_features['action_count'] / per_minute_features['minutes_played'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# ã‚´ãƒ¼ãƒ«æ•°ã‚’ãƒãƒ¼ã‚¸ãƒ»ã‚¼ãƒ­åŸ‹ã‚\n",
    "per_minute_features = per_minute_features.merge(\n",
    "    match_player_goals,\n",
    "    on=['match_id', 'player_id'],\n",
    "    how='left'\n",
    ")\n",
    "per_minute_features['goal_count'] = per_minute_features['goal_count'].fillna(0)\n",
    "\n",
    "# ã‚´ãƒ¼ãƒ«æ•°ã®æ­£è¦åŒ–\n",
    "per_minute_features['goal_count_per_minute'] = np.where(\n",
    "    per_minute_features['minutes_played'] > 0,\n",
    "    per_minute_features['goal_count'] / per_minute_features['minutes_played'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°ã‚’ãƒãƒ¼ã‚¸ãƒ»ã‚¼ãƒ­åŸ‹ã‚\n",
    "per_minute_features = per_minute_features.merge(\n",
    "    action_type_stats,\n",
    "    on=['match_id', 'player_id'],\n",
    "    how='left'\n",
    ")\n",
    "action_type_cols = [col for col in per_minute_features.columns if col.startswith('type_') and col.endswith('_count')] # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°ã®åˆ—\n",
    "for col in action_type_cols:\n",
    "    per_minute_features[col] = per_minute_features[col].fillna(0)\n",
    "\n",
    "# ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°ã®æ­£è¦åŒ–\n",
    "for col in action_type_cols:\n",
    "    new_col_name = col.replace('_count', '_count_per_minute')\n",
    "    per_minute_features[new_col_name] = np.where(\n",
    "        per_minute_features['minutes_played'] > 0,\n",
    "        per_minute_features[col] / per_minute_features['minutes_played'],\n",
    "        0\n",
    "    )\n",
    "\n",
    "# æ–°è¦ä½œæˆã—ãŸåˆ—ã®ã¿ã«çµã‚Šè¾¼ã¿\n",
    "per_minute_cols = [col for col in per_minute_features.columns if col.endswith('_per_minute')]\n",
    "per_minute_features = per_minute_features[['match_id', 'player_id'] + per_minute_cols]\n",
    "\n",
    "print(f\"\\nä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {per_minute_features.shape}\")\n",
    "display(per_minute_features.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a302cfed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "5m47SqPMiuhW",
    "outputId": "5ceb8fa8-cc5a-478a-bb4b-7be3075b35f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ”»æ’ƒ/å®ˆå‚™ãƒãƒ©ãƒ³ã‚¹ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\n",
      "\n",
      "ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (40010, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>action_type</th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>type_defensive_actions</th>\n",
       "      <th>type_offensive_actions</th>\n",
       "      <th>type_offensive_action_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "action_type match_id player_id  type_defensive_actions  \\\n",
       "0            2499719    120339                       7   \n",
       "1            2499719     12829                       0   \n",
       "2            2499719     14763                       1   \n",
       "\n",
       "action_type  type_offensive_actions  type_offensive_action_ratio  \n",
       "0                                73                     0.912500  \n",
       "1                                16                     1.000000  \n",
       "2                                26                     0.962963  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# æ”»æ’ƒ/å®ˆå‚™ãƒãƒ©ãƒ³ã‚¹ç‰¹å¾´é‡\n",
    "# é¸æ‰‹ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å®šé‡åŒ–ã—ã€æ”»æ’ƒçš„ãªé¸æ‰‹ã‚’è­˜åˆ¥\n",
    "\n",
    "print(\"æ”»æ’ƒ/å®ˆå‚™ãƒãƒ©ãƒ³ã‚¹ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "# æ”»æ’ƒ/å®ˆå‚™ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å®šç¾©\n",
    "offensive_actions = ['shot', 'pass', 'cross', 'take_on', 'dribble']\n",
    "defensive_actions = ['tackle', 'interception', 'clearance']\n",
    "\n",
    "# å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®åˆ†é¡ã‚’ä»˜ä¸\n",
    "def categorize_ad(action):\n",
    "    if action in offensive_actions:\n",
    "        return 'offensive'\n",
    "    elif action in defensive_actions:\n",
    "        return 'defensive'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "relevant_actions['action_type'] = relevant_actions['type_name'].apply(categorize_ad)\n",
    "\n",
    "# æ”»å®ˆåˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°ã‚’é›†è¨ˆ\n",
    "offense_defense_balance = (\n",
    "    relevant_actions\n",
    "    .pivot_table(\n",
    "        index=['match_id', 'player_id'],\n",
    "        columns='action_type',\n",
    "        values='period_id',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "    .add_prefix('type_')\n",
    "    .add_suffix('_actions')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# æ”»å®ˆãƒãƒ©ãƒ³ã‚¹æŒ‡æ¨™ã‚’è¨ˆç®—\n",
    "offense_defense_balance['total_actions'] = (\n",
    "    offense_defense_balance.get('type_offensive_actions', 0) +\n",
    "    offense_defense_balance.get('type_defensive_actions', 0)\n",
    ")\n",
    "\n",
    "offense_defense_balance['type_offensive_action_ratio'] = np.where(\n",
    "    offense_defense_balance['total_actions'] > 0,\n",
    "    offense_defense_balance['type_offensive_actions'] / offense_defense_balance['total_actions'],\n",
    "    0\n",
    ")\n",
    "\n",
    "offense_defense_balance = offense_defense_balance.drop(columns=['total_actions'])\n",
    "\n",
    "print(f\"\\nä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {offense_defense_balance.shape}\")\n",
    "display(offense_defense_balance.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a599156",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "sLKXukn5pIUx",
    "outputId": "3c3f0531-8bd0-4e66-9c7e-dacfa3a0b86a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚·ãƒ¥ãƒ¼ãƒˆã®ãƒ‘ã‚¹æ•°ã‚’è¨ˆç®—ä¸­...\n"
     ]
    }
   ],
   "source": [
    "# æ™‚ç³»åˆ—è¦ç´ ã‚’åŠ å‘³ã—ãŸç‰¹å¾´é‡\n",
    "# xAGã®å®šç¾©ã‚’è€ƒãˆã‚‹ã¨ã€ãƒ‘ã‚¹ã—ãŸå‘³æ–¹ã®ã‚·ãƒ¥ãƒ¼ãƒˆãŒå¤šã„ã»ã©xAGã¯é«˜ããªã‚‹\n",
    "# ãã“ã§ã€æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚·ãƒ¥ãƒ¼ãƒˆã§ã‚ã‚‹ãƒ‘ã‚¹ã®æ•°ã‚’é¸æ‰‹-è©¦åˆã”ã¨ã«é›†è¨ˆã™ã‚‹\n",
    "\n",
    "print(\"æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚·ãƒ¥ãƒ¼ãƒˆã®ãƒ‘ã‚¹æ•°ã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "# ç›´å¾Œã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã‚’ã‚·ãƒ•ãƒˆã§ä»˜ä¸\n",
    "relevant_actions = relevant_actions.sort_values(['match_id', 'period_id', 'time_seconds'])  # å¿µã®ç‚ºã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ™‚é–“ã§ã‚½ãƒ¼ãƒˆ\n",
    "relevant_actions[\"next_type\"] = relevant_actions.groupby(\"match_id\")[\"type_name\"].shift(-1)\n",
    "\n",
    "# pass â†’ shot ã¨ãªã£ã¦ã„ã‚‹è¡Œã‚’æŠ½å‡º\n",
    "pass_to_shot = relevant_actions[\n",
    "    (relevant_actions[\"type_name\"] == \"pass\") &\n",
    "    (relevant_actions[\"next_type\"] == \"shot\")\n",
    "]\n",
    "\n",
    "# match_id, player_idã”ã¨ã«ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "pass_leads_to_shot = (\n",
    "    pass_to_shot.groupby([\"match_id\", \"player_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"pass_leads_to_shot\")\n",
    ")\n",
    "\n",
    "print(f\"\\nä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {pass_leads_to_shot.shape}\")\n",
    "display(pass_leads_to_shot.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12a383",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–/ãƒ‡ã‚£ãƒ¼ãƒ—ç³»ã®ç‰¹å¾´é‡\n",
    "print(\"ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–/ãƒ‡ã‚£ãƒ¼ãƒ—ç³»ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "PASS_PROGRESSIVE_TYPES = {\"pass\", \"cross\", \"freekick_crossed\", \"corner_crossed\"}\n",
    "CARRY_PROGRESSIVE_TYPES = {\"carry\", \"dribble\", \"take_on\"}\n",
    "\n",
    "progressive_pass_actions = relevant_actions[\n",
    "    relevant_actions[\"type_name\"].isin(PASS_PROGRESSIVE_TYPES)\n",
    "].copy()\n",
    "\n",
    "if not progressive_pass_actions.empty:\n",
    "    dx = (progressive_pass_actions[\"end_x\"] - progressive_pass_actions[\"start_x\"]).fillna(0.0)\n",
    "    dy = (progressive_pass_actions[\"end_y\"] - progressive_pass_actions[\"start_y\"]).fillna(0.0)\n",
    "else:\n",
    "    dx = pd.Series(dtype=float)\n",
    "    dy = pd.Series(dtype=float)\n",
    "\n",
    "progressive_pass_actions[\"delta_x\"] = dx\n",
    "progressive_pass_actions[\"delta_total\"] = np.hypot(dx, dy)\n",
    "progressive_pass_actions[\"is_completed\"] = progressive_pass_actions[\"result_name\"] == \"success\"\n",
    "\n",
    "FINAL_THIRD_X = 70.0\n",
    "DEEP_COMPLETION_X = 85.0\n",
    "PENALTY_AREA_X = 88.0\n",
    "PROGRESS_ADVANCE_MIN = 10.0\n",
    "\n",
    "progressive_pass_actions[\"is_progressive\"] = (\n",
    "    (progressive_pass_actions[\"delta_x\"] >= PROGRESS_ADVANCE_MIN)\n",
    "    | (\n",
    "        (progressive_pass_actions[\"start_x\"] < FINAL_THIRD_X)\n",
    "        & (progressive_pass_actions[\"end_x\"] >= FINAL_THIRD_X)\n",
    "    )\n",
    "    | (progressive_pass_actions[\"end_x\"] >= DEEP_COMPLETION_X)\n",
    ")\n",
    "\n",
    "progressive_pass_actions[\"progressive_attempt\"] = progressive_pass_actions[\"is_progressive\"].astype(int)\n",
    "progressive_pass_actions[\"progressive_success\"] = (\n",
    "    progressive_pass_actions[\"is_progressive\"] & progressive_pass_actions[\"is_completed\"]\n",
    ").astype(int)\n",
    "progressive_pass_actions[\"progressive_distance\"] = np.where(\n",
    "    progressive_pass_actions[\"is_progressive\"],\n",
    "    progressive_pass_actions[\"delta_total\"],\n",
    "    0.0,\n",
    ")\n",
    "\n",
    "progressive_pass_actions[\"is_final_third_entry\"] = (\n",
    "    progressive_pass_actions[\"is_completed\"]\n",
    "    & (progressive_pass_actions[\"start_x\"] < FINAL_THIRD_X)\n",
    "    & (progressive_pass_actions[\"end_x\"] >= FINAL_THIRD_X)\n",
    ")\n",
    "progressive_pass_actions[\"is_deep_completion\"] = (\n",
    "    progressive_pass_actions[\"is_completed\"]\n",
    "    & (progressive_pass_actions[\"end_x\"] >= DEEP_COMPLETION_X)\n",
    ")\n",
    "progressive_pass_actions[\"is_penalty_area_entry\"] = (\n",
    "    progressive_pass_actions[\"is_completed\"]\n",
    "    & (progressive_pass_actions[\"end_x\"] >= PENALTY_AREA_X)\n",
    ")\n",
    "\n",
    "pass_progressive_features = (\n",
    "    progressive_pass_actions.groupby([\"match_id\", \"player_id\"]).agg(\n",
    "        progressive_pass_count=(\"progressive_attempt\", \"sum\"),\n",
    "        progressive_pass_success=(\"progressive_success\", \"sum\"),\n",
    "        progressive_pass_distance_total=(\"progressive_distance\", \"sum\"),\n",
    "        final_third_entry_count=(\"is_final_third_entry\", \"sum\"),\n",
    "        deep_completion_count=(\"is_deep_completion\", \"sum\"),\n",
    "        penalty_area_entry_count=(\"is_penalty_area_entry\", \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "if \"progressive_pass_count\" in pass_progressive_features:\n",
    "    pass_progressive_features[\"progressive_pass_success_rate\"] = np.where(\n",
    "        pass_progressive_features[\"progressive_pass_count\"] > 0,\n",
    "        pass_progressive_features[\"progressive_pass_success\"]\n",
    "        / pass_progressive_features[\"progressive_pass_count\"],\n",
    "        0.0,\n",
    "    )\n",
    "    pass_progressive_features[\"progressive_pass_distance_mean\"] = np.where(\n",
    "        pass_progressive_features[\"progressive_pass_count\"] > 0,\n",
    "        pass_progressive_features[\"progressive_pass_distance_total\"]\n",
    "        / pass_progressive_features[\"progressive_pass_count\"],\n",
    "        0.0,\n",
    "    )\n",
    "else:\n",
    "    pass_progressive_features[\"progressive_pass_success_rate\"] = []\n",
    "    pass_progressive_features[\"progressive_pass_distance_mean\"] = []\n",
    "\n",
    "carry_actions = relevant_actions[\n",
    "    relevant_actions[\"type_name\"].isin(CARRY_PROGRESSIVE_TYPES)\n",
    "].copy()\n",
    "\n",
    "if not carry_actions.empty:\n",
    "    carry_actions[\"end_x\"] = carry_actions[\"end_x\"].fillna(carry_actions[\"start_x\"])\n",
    "    carry_actions[\"end_y\"] = carry_actions[\"end_y\"].fillna(carry_actions[\"start_y\"])\n",
    "    carry_dx = (carry_actions[\"end_x\"] - carry_actions[\"start_x\"]).fillna(0.0)\n",
    "    carry_dy = (carry_actions[\"end_y\"] - carry_actions[\"start_y\"]).fillna(0.0)\n",
    "    carry_actions[\"delta_total\"] = np.hypot(carry_dx, carry_dy)\n",
    "    carry_actions[\"delta_x\"] = carry_dx\n",
    "    carry_actions[\"is_success\"] = carry_actions[\"result_name\"] == \"success\"\n",
    "    carry_actions[\"is_progressive\"] = (\n",
    "        (carry_actions[\"delta_x\"] >= 5.0)\n",
    "        | (\n",
    "            (carry_actions[\"start_x\"] < FINAL_THIRD_X)\n",
    "            & (carry_actions[\"end_x\"] >= FINAL_THIRD_X)\n",
    "        )\n",
    "    )\n",
    "    carry_actions[\"progressive_carry_attempt\"] = carry_actions[\"is_progressive\"].astype(int)\n",
    "    carry_actions[\"progressive_carry_success\"] = (\n",
    "        carry_actions[\"is_progressive\"] & carry_actions[\"is_success\"]\n",
    "    ).astype(int)\n",
    "    carry_actions[\"progressive_carry_distance\"] = np.where(\n",
    "        carry_actions[\"is_progressive\"], carry_actions[\"delta_total\"], 0.0\n",
    "    )\n",
    "\n",
    "    carry_progressive_features = (\n",
    "        carry_actions.groupby([\"match_id\", \"player_id\"]).agg(\n",
    "            progressive_carry_count=(\"progressive_carry_attempt\", \"sum\"),\n",
    "            progressive_carry_success=(\"progressive_carry_success\", \"sum\"),\n",
    "            progressive_carry_distance_total=(\"progressive_carry_distance\", \"sum\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    carry_progressive_features[\"progressive_carry_success_rate\"] = np.where(\n",
    "        carry_progressive_features[\"progressive_carry_count\"] > 0,\n",
    "        carry_progressive_features[\"progressive_carry_success\"]\n",
    "        / carry_progressive_features[\"progressive_carry_count\"],\n",
    "        0.0,\n",
    "    )\n",
    "    carry_progressive_features[\"progressive_carry_distance_mean\"] = np.where(\n",
    "        carry_progressive_features[\"progressive_carry_count\"] > 0,\n",
    "        carry_progressive_features[\"progressive_carry_distance_total\"]\n",
    "        / carry_progressive_features[\"progressive_carry_count\"],\n",
    "        0.0,\n",
    "    )\n",
    "else:\n",
    "    carry_progressive_features = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"match_id\",\n",
    "            \"player_id\",\n",
    "            \"progressive_carry_count\",\n",
    "            \"progressive_carry_success\",\n",
    "            \"progressive_carry_distance_total\",\n",
    "            \"progressive_carry_success_rate\",\n",
    "            \"progressive_carry_distance_mean\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "progressive_features = pass_progressive_features.merge(\n",
    "    carry_progressive_features,\n",
    "    on=[\"match_id\", \"player_id\"],\n",
    "    how=\"outer\",\n",
    ").fillna(0.0)\n",
    "\n",
    "print(f\"ä½œæˆã—ãŸãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ç³»ç‰¹å¾´é‡: {progressive_features.shape}\")\n",
    "display(progressive_features.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’å‹ xT (Expected Threat) ç‰¹å¾´é‡\n",
    "print(\"å­¦ç¿’å‹xT (value iteration) ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "# ã‚°ãƒªãƒƒãƒ‰å®šç¾© (16x12)\n",
    "GRID_X_EDGES = np.linspace(0, 105, 17)\n",
    "GRID_Y_EDGES = np.linspace(0, 68, 13)\n",
    "NUM_X = len(GRID_X_EDGES) - 1\n",
    "NUM_Y = len(GRID_Y_EDGES) - 1\n",
    "NUM_ZONES = NUM_X * NUM_Y\n",
    "\n",
    "def map_to_zone(x_array: np.ndarray, y_array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Map coordinates to xT grid zone indices (0-191).\"\"\"\n",
    "    x_idx = np.clip(np.digitize(x_array, GRID_X_EDGES) - 1, 0, NUM_X - 1)\n",
    "    y_idx = np.clip(np.digitize(y_array, GRID_Y_EDGES) - 1, 0, NUM_Y - 1)\n",
    "    return (y_idx * NUM_X + x_idx).astype(int)\n",
    "\n",
    "# åˆ©ç”¨ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç¨®åˆ¥\n",
    "distribution_actions = {\n",
    "    \"pass\", \"cross\", \"throw_in\", \"corner_crossed\", \"freekick_crossed\",\n",
    "    \"carry\", \"take_on\", \"dribble\", \"goal_kick\", \"clearance\"\n",
    "}\n",
    "shot_actions = {\"shot\", \"shot_penalty\", \"shot_freekick\"}\n",
    "\n",
    "# å­¦ç¿’ç”¨xTã¯trainã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿ã‚’ä½¿ç”¨ï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰\n",
    "train_match_ids_xt = set(train_df[\"match_id\"])\n",
    "train_actions = relevant_actions[relevant_actions[\"match_id\"].isin(train_match_ids_xt)].copy()\n",
    "\n",
    "# åº§æ¨™æ¬ æã‚’ã‚¼ãƒ­åŸ‹ã‚ã—ã¦ã‚¾ãƒ¼ãƒ³ç®—å‡ºç”¨ã«æº–å‚™ï¼ˆtrainã®ã¿ï¼‰\n",
    "start_x_train = train_actions[\"start_x\"].fillna(0).to_numpy()\n",
    "start_y_train = train_actions[\"start_y\"].fillna(0).to_numpy()\n",
    "start_zones_train = map_to_zone(start_x_train, start_y_train)\n",
    "\n",
    "transition_counts = np.zeros((NUM_ZONES, NUM_ZONES), dtype=np.float64)\n",
    "shot_counts = np.zeros(NUM_ZONES, dtype=np.float64)\n",
    "goal_counts = np.zeros(NUM_ZONES, dtype=np.float64)\n",
    "ball_loss_counts = np.zeros(NUM_ZONES, dtype=np.float64)\n",
    "\n",
    "# ã‚·ãƒ§ãƒƒãƒˆé–¢é€£çµ±è¨ˆï¼ˆtrainã®ã¿ï¼‰\n",
    "shot_mask_train = train_actions[\"type_name\"].isin(shot_actions)\n",
    "if shot_mask_train.any():\n",
    "    shot_zones_train = start_zones_train[shot_mask_train.to_numpy()]\n",
    "    shot_counts += np.bincount(shot_zones_train, minlength=NUM_ZONES)\n",
    "    goal_flags_train = train_actions.loc[shot_mask_train, \"result_name\"].eq(\"success\").to_numpy(dtype=np.float64)\n",
    "    goal_counts += np.bincount(shot_zones_train, weights=goal_flags_train, minlength=NUM_ZONES)\n",
    "\n",
    "# ãƒ‘ã‚¹ãƒ»ã‚­ãƒ£ãƒªãƒ¼ç­‰ã®ãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³é·ç§»çµ±è¨ˆï¼ˆtrainã®ã¿ï¼‰\n",
    "move_mask_train = train_actions[\"type_name\"].isin(distribution_actions)\n",
    "if move_mask_train.any():\n",
    "    move_actions_train = train_actions.loc[move_mask_train].copy()\n",
    "    move_start_zones_train = map_to_zone(\n",
    "        move_actions_train[\"start_x\"].fillna(0).to_numpy(),\n",
    "        move_actions_train[\"start_y\"].fillna(0).to_numpy(),\n",
    "    )\n",
    "    move_success_train = move_actions_train[\"result_name\"].eq(\"success\").to_numpy()\n",
    "\n",
    "    if (~move_success_train).any():\n",
    "        ball_loss_counts += np.bincount(move_start_zones_train[~move_success_train], minlength=NUM_ZONES)\n",
    "\n",
    "    valid_success_idx_train = move_success_train & move_actions_train[\"end_x\"].notna().to_numpy() & move_actions_train[\"end_y\"].notna().to_numpy()\n",
    "    if valid_success_idx_train.any():\n",
    "        success_start_zones_train = move_start_zones_train[valid_success_idx_train]\n",
    "        success_end_zones_train = map_to_zone(\n",
    "            move_actions_train.loc[valid_success_idx_train, \"end_x\"].to_numpy(),\n",
    "            move_actions_train.loc[valid_success_idx_train, \"end_y\"].to_numpy(),\n",
    "        )\n",
    "        np.add.at(transition_counts, (success_start_zones_train, success_end_zones_train), 1.0)\n",
    "\n",
    "# xTä¾¡å€¤åå¾©ï¼ˆtrainçµ±è¨ˆã§æ¨å®šï¼‰\n",
    "transition_totals = transition_counts.sum(axis=1)\n",
    "total_counts = transition_totals + shot_counts + ball_loss_counts\n",
    "safe_totals = np.where(total_counts == 0, 1.0, total_counts)\n",
    "\n",
    "transition_probs = np.divide(\n",
    "    transition_counts,\n",
    "    safe_totals[:, None],\n",
    "    out=np.zeros_like(transition_counts),\n",
    "    where=safe_totals[:, None] > 0,\n",
    ")\n",
    "shot_prob = shot_counts / safe_totals\n",
    "goal_given_shot = np.divide(\n",
    "    goal_counts,\n",
    "    shot_counts,\n",
    "    out=np.zeros_like(goal_counts),\n",
    "    where=shot_counts > 0,\n",
    ")\n",
    "immediate_reward = shot_prob * goal_given_shot\n",
    "\n",
    "gamma = 0.95\n",
    "xt_values = immediate_reward.copy()\n",
    "max_iterations = 500\n",
    "for iteration in range(max_iterations):\n",
    "    updated = immediate_reward + gamma * transition_probs.dot(xt_values)\n",
    "    max_delta = np.max(np.abs(updated - xt_values))\n",
    "    xt_values = updated\n",
    "    if max_delta < 1e-6:\n",
    "        break\n",
    "else:\n",
    "    iteration += 1  # åæŸã—ãªã‹ã£ãŸå ´åˆã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿\n",
    "\n",
    "print(f\"å­¦ç¿’å‹xT value iteration: {iteration + 1} step(s), max_delta={max_delta:.2e}\")\n",
    "print(f\"xTå€¤ã®ç¯„å›²: min={xt_values.min():.5f}, max={xt_values.max():.5f}\")\n",
    "\n",
    "# ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®xTç‰¹å¾´é‡ä»˜ä¸ï¼ˆtrainã§å­¦ç¿’ã—ãŸxt_valuesã‚’å…¨è¡Œã¸é©ç”¨ï¼‰\n",
    "# å…¨è¡Œï¼ˆtrain+testï¼‰ã®é–‹å§‹ã‚¾ãƒ¼ãƒ³ã‚’ç®—å‡º\n",
    "start_x_all = relevant_actions[\"start_x\"].fillna(0).to_numpy()\n",
    "start_y_all = relevant_actions[\"start_y\"].fillna(0).to_numpy()\n",
    "start_zones_all = map_to_zone(start_x_all, start_y_all)\n",
    "\n",
    "end_x = relevant_actions[\"end_x\"].to_numpy()\n",
    "end_y = relevant_actions[\"end_y\"].to_numpy()\n",
    "has_end_coords = np.isfinite(end_x) & np.isfinite(end_y)\n",
    "end_zones_all = np.zeros(len(relevant_actions), dtype=int)\n",
    "if has_end_coords.any():\n",
    "    end_zones_all[has_end_coords] = map_to_zone(end_x[has_end_coords], end_y[has_end_coords])\n",
    "\n",
    "start_values = xt_values[start_zones_all]\n",
    "end_values = np.zeros(len(relevant_actions), dtype=np.float64)\n",
    "end_values[has_end_coords] = xt_values[end_zones_all[has_end_coords]]\n",
    "\n",
    "success_flag = relevant_actions[\"result_name\"].eq(\"success\").astype(int).to_numpy()\n",
    "end_values_on_success = np.where(success_flag == 1, end_values, 0.0)\n",
    "\n",
    "relevant_actions[\"xt_learned_start\"] = start_values\n",
    "relevant_actions[\"xt_learned_end\"] = end_values\n",
    "relevant_actions[\"xt_learned_delta\"] = end_values_on_success - start_values\n",
    "relevant_actions[\"xt_learned_positive_delta\"] = np.clip(relevant_actions[\"xt_learned_delta\"], 0.0, None)\n",
    "relevant_actions[\"xt_learned_success\"] = success_flag\n",
    "relevant_actions[\"xt_learned_end_on_success\"] = np.where(success_flag == 1, end_values, np.nan)\n",
    "relevant_actions[\"xt_learned_delta_on_success\"] = np.where(success_flag == 1, relevant_actions[\"xt_learned_delta\"], np.nan)\n",
    "\n",
    "xt_learned_features = (\n",
    "    relevant_actions.groupby([\"match_id\", \"player_id\"])\n",
    "    .agg(\n",
    "        xt_learned_start_mean=(\"xt_learned_start\", \"mean\"),\n",
    "        xt_learned_start_max=(\"xt_learned_start\", \"max\"),\n",
    "        xt_learned_delta_sum=(\"xt_learned_delta\", \"sum\"),\n",
    "        xt_learned_delta_mean=(\"xt_learned_delta\", \"mean\"),\n",
    "        xt_learned_positive_delta_sum=(\"xt_learned_positive_delta\", \"sum\"),\n",
    "        xt_learned_positive_delta_mean=(\"xt_learned_positive_delta\", \"mean\"),\n",
    "        xt_learned_success_rate=(\"xt_learned_success\", \"mean\"),\n",
    "        xt_learned_action_count=(\"xt_learned_success\", \"count\"),\n",
    "        xt_learned_end_success_mean=(\"xt_learned_end_on_success\", \"mean\"),\n",
    "        xt_learned_delta_success_mean=(\"xt_learned_delta_on_success\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "xt_learned_feature_cols = [col for col in xt_learned_features.columns if col not in {\"match_id\", \"player_id\"}]\n",
    "\n",
    "train_df = train_df.merge(xt_learned_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "test_df = test_df.merge(xt_learned_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "\n",
    "train_df[xt_learned_feature_cols] = train_df[xt_learned_feature_cols].fillna(0.0)\n",
    "test_df[xt_learned_feature_cols] = test_df[xt_learned_feature_cols].fillna(0.0)\n",
    "\n",
    "train_df[\"xt_learned_action_count\"] = train_df[\"xt_learned_action_count\"].astype(int)\n",
    "test_df[\"xt_learned_action_count\"] = test_df[\"xt_learned_action_count\"].astype(int)\n",
    "\n",
    "print(\"å­¦ç¿’å‹xTç‰¹å¾´é‡ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰:\")\n",
    "display(xt_learned_features.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321279ba",
   "metadata": {
    "id": "hHxhgz7ypDWn"
   },
   "source": [
    "## Possession-Level Progression Features\n",
    "\n",
    "Learned xT highlights forward threat, so we aggregate possession speed and directness as complementary signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2f6d8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Calculating possession progression features...\")\n",
    "\n",
    "pos_actions = (\n",
    "    relevant_actions\n",
    "    .reset_index(drop=False)\n",
    "    .sort_values([\"match_id\", \"period_id\", \"time_seconds\", \"index\"], kind=\"mergesort\")\n",
    "    .rename(columns={\"index\": \"action_index\"})\n",
    "    .copy()\n",
    ")\n",
    "pos_actions[\"time_seconds\"] = pos_actions[\"time_seconds\"].fillna(0.0)\n",
    "pos_actions[\"team_id\"] = pos_actions[\"team_id\"].fillna(\"unknown_team\")\n",
    "pos_actions[\"new_match\"] = pos_actions[\"match_id\"].ne(pos_actions[\"match_id\"].shift())\n",
    "pos_actions[\"same_team_prev\"] = pos_actions[\"team_id\"].eq(pos_actions[\"team_id\"].shift())\n",
    "pos_actions[\"prev_success\"] = pos_actions[\"result_name\"].shift().eq(\"success\")\n",
    "pos_actions[\"time_diff\"] = pos_actions.groupby(\"match_id\")[\"time_seconds\"].diff().fillna(0.0)\n",
    "pos_actions[\"new_possession\"] = (\n",
    "    pos_actions[\"new_match\"]\n",
    "    | (~pos_actions[\"same_team_prev\"].fillna(False))\n",
    "    | (~pos_actions[\"prev_success\"].fillna(True))\n",
    "    | (pos_actions[\"time_diff\"] > 15.0)\n",
    ")\n",
    "pos_actions.loc[pos_actions.index[0], \"new_possession\"] = True\n",
    "pos_actions[\"possession_id\"] = pos_actions[\"new_possession\"].cumsum().astype(int)\n",
    "pos_actions[\"possession_event_index\"] = pos_actions.groupby(\"possession_id\").cumcount() + 1\n",
    "\n",
    "pos_group = pos_actions.groupby(\"possession_id\").agg(\n",
    "    match_id=(\"match_id\", \"first\"),\n",
    "    team_id=(\"team_id\", \"first\"),\n",
    "    start_x=(\"start_x\", \"first\"),\n",
    "    start_y=(\"start_y\", \"first\"),\n",
    "    end_x=(\"end_x\", \"last\"),\n",
    "    end_y=(\"end_y\", \"last\"),\n",
    "    start_time=(\"time_seconds\", \"first\"),\n",
    "    end_time=(\"time_seconds\", \"last\"),\n",
    "    action_count=(\"player_id\", \"count\"),\n",
    "    unique_players=(\"player_id\", \"nunique\"),\n",
    "    xt_positive_sum=(\"xt_learned_positive_delta\", \"sum\"),\n",
    "    xt_delta_sum=(\"xt_learned_delta\", \"sum\"),\n",
    ").reset_index()\n",
    "\n",
    "pos_group[\"duration\"] = (pos_group[\"end_time\"] - pos_group[\"start_time\"]).clip(lower=1.0)\n",
    "pos_group[\"delta_x\"] = pos_group[\"end_x\"] - pos_group[\"start_x\"]\n",
    "pos_group[\"delta_y\"] = pos_group[\"end_y\"] - pos_group[\"start_y\"]\n",
    "pos_group[\"ground_distance\"] = np.sqrt(np.square(pos_group[\"delta_x\"]) + np.square(pos_group[\"delta_y\"]))\n",
    "pos_group[\"directness\"] = np.divide(\n",
    "    pos_group[\"delta_x\"],\n",
    "    pos_group[\"ground_distance\"],\n",
    "    out=np.zeros_like(pos_group[\"delta_x\"]),\n",
    "    where=pos_group[\"ground_distance\"] > 0,\n",
    ")\n",
    "pos_group[\"speed_x\"] = pos_group[\"delta_x\"] / pos_group[\"duration\"]\n",
    "pos_group[\"speed_ground\"] = pos_group[\"ground_distance\"] / pos_group[\"duration\"]\n",
    "pos_group[\"xt_positive_per_second\"] = np.divide(\n",
    "    pos_group[\"xt_positive_sum\"],\n",
    "    pos_group[\"duration\"],\n",
    "    out=np.zeros_like(pos_group[\"xt_positive_sum\"]),\n",
    "    where=pos_group[\"duration\"] > 0,\n",
    ")\n",
    "\n",
    "final_third_threshold = 70.0\n",
    "final_third_steps = (\n",
    "    pos_actions[pos_actions[\"end_x\"].ge(final_third_threshold)]\n",
    "    .groupby(\"possession_id\")[\"possession_event_index\"]\n",
    "    .min()\n",
    ")\n",
    "final_third_times = (\n",
    "    pos_actions[pos_actions[\"end_x\"].ge(final_third_threshold)]\n",
    "    .groupby(\"possession_id\")[\"time_seconds\"]\n",
    "    .min()\n",
    ")\n",
    "pos_group[\"final_third_entry_step\"] = pos_group[\"possession_id\"].map(final_third_steps)\n",
    "pos_group[\"final_third_entry_flag\"] = pos_group[\"final_third_entry_step\"].notna().astype(float)\n",
    "pos_group[\"final_third_entry_time\"] = pos_group[\"possession_id\"].map(final_third_times)\n",
    "pos_group[\"time_to_final_third\"] = (\n",
    "    pos_group[\"final_third_entry_time\"] - pos_group[\"start_time\"]\n",
    ").where(pos_group[\"final_third_entry_flag\"] > 0)\n",
    "\n",
    "pos_player = (\n",
    "    pos_actions[[\"match_id\", \"player_id\", \"possession_id\"]]\n",
    "    .drop_duplicates()\n",
    "    .merge(\n",
    "        pos_group[[\n",
    "            \"possession_id\",\n",
    "            \"duration\",\n",
    "            \"ground_distance\",\n",
    "            \"directness\",\n",
    "            \"speed_x\",\n",
    "            \"speed_ground\",\n",
    "            \"xt_positive_per_second\",\n",
    "            \"xt_positive_sum\",\n",
    "            \"xt_delta_sum\",\n",
    "            \"action_count\",\n",
    "            \"final_third_entry_flag\",\n",
    "            \"final_third_entry_step\",\n",
    "            \"time_to_final_third\",\n",
    "        ]],\n",
    "        on=\"possession_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n",
    "\n",
    "player_pos_features = pos_player.groupby([\"match_id\", \"player_id\"]).agg(\n",
    "    possession_count=(\"possession_id\", \"nunique\"),\n",
    "    possession_duration_mean=(\"duration\", \"mean\"),\n",
    "    possession_ground_distance_mean=(\"ground_distance\", \"mean\"),\n",
    "    possession_directness_mean=(\"directness\", \"mean\"),\n",
    "    possession_speed_x_mean=(\"speed_x\", \"mean\"),\n",
    "    possession_speed_ground_mean=(\"speed_ground\", \"mean\"),\n",
    "    possession_xt_positive_per_second_mean=(\"xt_positive_per_second\", \"mean\"),\n",
    "    possession_xt_positive_sum=(\"xt_positive_sum\", \"sum\"),\n",
    "    possession_xt_delta_sum=(\"xt_delta_sum\", \"sum\"),\n",
    "    possession_actions_per_pos_mean=(\"action_count\", \"mean\"),\n",
    "    possession_final_third_rate=(\"final_third_entry_flag\", \"mean\"),\n",
    "    possession_final_third_step_mean=(\"final_third_entry_step\", \"mean\"),\n",
    "    possession_time_to_final_third_mean=(\"time_to_final_third\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "possession_feature_cols = [\n",
    "    col for col in player_pos_features.columns if col not in {\"match_id\", \"player_id\"}\n",
    "]\n",
    "numeric_possession_cols = [col for col in possession_feature_cols if col != \"possession_count\"]\n",
    "\n",
    "train_df = train_df.merge(player_pos_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "test_df = test_df.merge(player_pos_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "\n",
    "train_df[\"possession_count\"] = train_df[\"possession_count\"].fillna(0).astype(int)\n",
    "test_df[\"possession_count\"] = test_df[\"possession_count\"].fillna(0).astype(int)\n",
    "\n",
    "if numeric_possession_cols:\n",
    "    train_df[numeric_possession_cols] = train_df[numeric_possession_cols].fillna(0.0)\n",
    "    test_df[numeric_possession_cols] = test_df[numeric_possession_cols].fillna(0.0)\n",
    "\n",
    "print(\"Possession progression features added:\", len(possession_feature_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1329ad",
   "metadata": {},
   "source": [
    "## Pass Network Features\n",
    "\n",
    "Network-centric statistics to capture player roles within possession flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5600a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Calculating pass network features...\")\n",
    "\n",
    "sorted_actions = (\n",
    "    relevant_actions\n",
    "    .reset_index(drop=False)\n",
    "    .sort_values([\"match_id\", \"period_id\", \"time_seconds\", \"index\"], kind=\"mergesort\")\n",
    "    .rename(columns={\"index\": \"action_index\"})\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "sorted_actions[\"next_player_id\"] = sorted_actions.groupby(\"match_id\")[\"player_id\"].shift(-1)\n",
    "sorted_actions[\"next_team_id\"] = sorted_actions.groupby(\"match_id\")[\"team_id\"].shift(-1)\n",
    "\n",
    "success_pass_mask = (\n",
    "    (sorted_actions[\"type_name\"] == \"pass\")\n",
    "    & sorted_actions[\"result_name\"].eq(\"success\")\n",
    "    & sorted_actions[\"next_team_id\"].notna()\n",
    "    & sorted_actions[\"next_team_id\"].eq(sorted_actions[\"team_id\"])\n",
    ")\n",
    "\n",
    "pass_edges = sorted_actions.loc[success_pass_mask, [\n",
    "    \"match_id\",\n",
    "    \"team_id\",\n",
    "    \"player_id\",\n",
    "    \"next_player_id\",\n",
    "    \"start_x\",\n",
    "    \"start_y\",\n",
    "    \"end_x\",\n",
    "    \"end_y\"\n",
    "]].copy()\n",
    "\n",
    "pass_edges = pass_edges.dropna(subset=[\"player_id\", \"next_player_id\"])\n",
    "pass_edges[\"player_id\"] = pass_edges[\"player_id\"].astype(str)\n",
    "pass_edges[\"next_player_id\"] = pass_edges[\"next_player_id\"].astype(str)\n",
    "\n",
    "pass_edges[\"pass_distance\"] = np.sqrt(\n",
    "    (pass_edges[\"end_x\"] - pass_edges[\"start_x\"]) ** 2 +\n",
    "    (pass_edges[\"end_y\"] - pass_edges[\"start_y\"]) ** 2\n",
    ")\n",
    "pass_edges[\"lateral_shift\"] = pass_edges[\"end_y\"] - pass_edges[\"start_y\"]\n",
    "pass_edges[\"switch_flag\"] = pass_edges[\"lateral_shift\"].abs() >= 20.0\n",
    "\n",
    "player_edge_stats = (\n",
    "    pass_edges.groupby([\"match_id\", \"player_id\"])\n",
    "    .agg(\n",
    "        pass_net_attempts=(\"next_player_id\", \"count\"),\n",
    "        pass_net_avg_distance=(\"pass_distance\", \"mean\"),\n",
    "        pass_net_switch_rate=(\"switch_flag\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "receiver_stats = (\n",
    "    pass_edges.groupby([\"match_id\", \"next_player_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"pass_net_receive_count\")\n",
    "    .rename(columns={\"next_player_id\": \"player_id\"})\n",
    ")\n",
    "\n",
    "centrality_records = []\n",
    "for (match_id, team_id), group in pass_edges.groupby([\"match_id\", \"team_id\"]):\n",
    "    players = set(group[\"player_id\"]) | set(group[\"next_player_id\"])\n",
    "    if not players:\n",
    "        continue\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    for src, tgt in group[[\"player_id\", \"next_player_id\"]].itertuples(index=False):\n",
    "        if G.has_edge(src, tgt):\n",
    "            G[src][tgt][\"weight\"] += 1.0\n",
    "        else:\n",
    "            G.add_edge(src, tgt, weight=1.0)\n",
    "\n",
    "    for node in players:\n",
    "        if node not in G:\n",
    "            G.add_node(node)\n",
    "\n",
    "    out_degree = dict(G.out_degree(weight=\"weight\"))\n",
    "    in_degree = dict(G.in_degree(weight=\"weight\"))\n",
    "    try:\n",
    "        betweenness = nx.betweenness_centrality(G, weight=\"weight\", normalized=True)\n",
    "    except Exception:\n",
    "        betweenness = {node: 0.0 for node in players}\n",
    "\n",
    "    undirected = G.to_undirected()\n",
    "    if undirected.number_of_edges() > 0:\n",
    "        clustering = nx.clustering(undirected, weight=\"weight\")\n",
    "    else:\n",
    "        clustering = {node: 0.0 for node in players}\n",
    "\n",
    "    for node in players:\n",
    "        centrality_records.append({\n",
    "            \"match_id\": match_id,\n",
    "            \"player_id\": node,\n",
    "            \"pass_net_out_degree\": out_degree.get(node, 0.0),\n",
    "            \"pass_net_in_degree\": in_degree.get(node, 0.0),\n",
    "            \"pass_net_betweenness\": betweenness.get(node, 0.0),\n",
    "            \"pass_net_clustering\": clustering.get(node, 0.0),\n",
    "        })\n",
    "\n",
    "centrality_df = pd.DataFrame(centrality_records)\n",
    "if centrality_df.empty:\n",
    "    centrality_df = pd.DataFrame(columns=[\n",
    "        \"match_id\",\n",
    "        \"player_id\",\n",
    "        \"pass_net_out_degree\",\n",
    "        \"pass_net_in_degree\",\n",
    "        \"pass_net_betweenness\",\n",
    "        \"pass_net_clustering\",\n",
    "    ])\n",
    "\n",
    "if player_edge_stats.empty:\n",
    "    player_edge_stats = pd.DataFrame(columns=[\n",
    "        \"match_id\",\n",
    "        \"player_id\",\n",
    "        \"pass_net_attempts\",\n",
    "        \"pass_net_avg_distance\",\n",
    "        \"pass_net_switch_rate\",\n",
    "    ])\n",
    "\n",
    "if receiver_stats.empty:\n",
    "    receiver_stats = pd.DataFrame(columns=[\n",
    "        \"match_id\",\n",
    "        \"player_id\",\n",
    "        \"pass_net_receive_count\",\n",
    "    ])\n",
    "\n",
    "pass_network_features = (\n",
    "    centrality_df\n",
    "    .merge(player_edge_stats, on=[\"match_id\", \"player_id\"], how=\"outer\")\n",
    "    .merge(receiver_stats, on=[\"match_id\", \"player_id\"], how=\"outer\")\n",
    ")\n",
    "\n",
    "if not pass_network_features.empty:\n",
    "    numeric_cols = [\n",
    "        col for col in pass_network_features.columns\n",
    "        if col not in {\"match_id\", \"player_id\"}\n",
    "    ]\n",
    "    pass_network_features[numeric_cols] = pass_network_features[numeric_cols].fillna(0.0)\n",
    "\n",
    "pass_network_feature_cols = [\n",
    "    col for col in pass_network_features.columns if col not in {\"match_id\", \"player_id\"}\n",
    "]\n",
    "\n",
    "train_df = train_df.merge(pass_network_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "test_df = test_df.merge(pass_network_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "\n",
    "if pass_network_feature_cols:\n",
    "    train_df[pass_network_feature_cols] = train_df[pass_network_feature_cols].fillna(0.0)\n",
    "    test_df[pass_network_feature_cols] = test_df[pass_network_feature_cols].fillna(0.0)\n",
    "\n",
    "print(\"Pass network features added:\", len(pass_network_feature_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767dd03",
   "metadata": {},
   "source": [
    "\n",
    "## è¡Œç‚ºã‚¿ã‚¤ãƒ—åˆ¥ eÎ”xT ç‰¹å¾´é‡\n",
    "\n",
    "å­¦ç¿’æ¸ˆã¿xTã«åŸºã¥ãç©ºé–“ä¾¡å€¤ã¨è¡Œç‚ºã‚¿ã‚¤ãƒ—åˆ¥ã®æˆåŠŸç¢ºç‡ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã€ãƒªã‚¹ã‚¯èª¿æ•´ã•ã‚ŒãŸæœŸå¾…xTå¢—åˆ† (eÎ”xT) ã‚’ç®—å‡ºã—ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0712a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"è¡Œç‚ºã‚¿ã‚¤ãƒ—åˆ¥ xPass ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™...\")\n",
    "\n",
    "xpass_action_groups = {\n",
    "    \"pass\": [\"pass\"],\n",
    "    \"cross\": [\"cross\"],\n",
    "    \"carry\": [\"carry\"],\n",
    "    \"dribble\": [\"dribble\", \"take_on\"],\n",
    "    \"free_kick\": [\"freekick_crossed\"],\n",
    "    \"corner\": [\"corner_crossed\"],\n",
    "}\n",
    "\n",
    "train_match_ids = set(train_df[\"match_id\"])\n",
    "\n",
    "if \"action_index\" not in relevant_actions.columns:\n",
    "    relevant_actions = relevant_actions.copy()\n",
    "    relevant_actions[\"action_index\"] = np.arange(len(relevant_actions))\n",
    "\n",
    "if \"xpass_prob\" not in relevant_actions.columns:\n",
    "    relevant_actions[\"xpass_prob\"] = np.nan\n",
    "if \"xpass_action_group\" not in relevant_actions.columns:\n",
    "    relevant_actions[\"xpass_action_group\"] = pd.NA\n",
    "\n",
    "relevant_actions[\"is_train_action\"] = relevant_actions[\"match_id\"].isin(train_match_ids)\n",
    "\n",
    "relevant_actions[\"end_x_filled\"] = relevant_actions[\"end_x\"].fillna(relevant_actions[\"start_x\"])\n",
    "relevant_actions[\"end_y_filled\"] = relevant_actions[\"end_y\"].fillna(relevant_actions[\"start_y\"])\n",
    "relevant_actions[\"delta_x\"] = (relevant_actions[\"end_x_filled\"] - relevant_actions[\"start_x\"]).fillna(0.0)\n",
    "relevant_actions[\"delta_y\"] = (relevant_actions[\"end_y_filled\"] - relevant_actions[\"start_y\"]).fillna(0.0)\n",
    "relevant_actions[\"distance\"] = np.hypot(relevant_actions[\"delta_x\"], relevant_actions[\"delta_y\"])\n",
    "relevant_actions[\"abs_delta_y\"] = relevant_actions[\"delta_y\"].abs()\n",
    "\n",
    "for col in [\"xt_learned_start\", \"xt_learned_delta\", \"xt_learned_positive_delta\"]:\n",
    "    if col in relevant_actions.columns:\n",
    "        relevant_actions[col] = relevant_actions[col].fillna(0.0)\n",
    "\n",
    "xpass_predictions = []\n",
    "xpass_training_summary = []\n",
    "xpass_calibration_records = []\n",
    "\n",
    "xpass_numeric_candidates = [\n",
    "    \"start_x\",\n",
    "    \"start_y\",\n",
    "    \"end_x_filled\",\n",
    "    \"end_y_filled\",\n",
    "    \"delta_x\",\n",
    "    \"delta_y\",\n",
    "    \"distance\",\n",
    "    \"abs_delta_y\",\n",
    "    \"time_seconds\",\n",
    "    \"minutes_played\",\n",
    "    \"period_id\",\n",
    "    \"is_home\",\n",
    "    \"xt_learned_start\",\n",
    "    \"xt_learned_delta\",\n",
    "    \"xt_learned_positive_delta\",\n",
    "]\n",
    "\n",
    "xpass_categorical_candidates = [\n",
    "    \"team_name_short\",\n",
    "    \"bodypart_name\",\n",
    "    \"competition\",\n",
    "    \"match_venue\",\n",
    "]\n",
    "\n",
    "for action_group, action_names in xpass_action_groups.items():\n",
    "    subset_idx = relevant_actions[\"type_name\"].isin(action_names)\n",
    "    action_subset = relevant_actions.loc[subset_idx].copy()\n",
    "\n",
    "    if action_subset.empty:\n",
    "        continue\n",
    "\n",
    "    action_subset[\"is_success\"] = action_subset[\"result_name\"].eq(\"success\").astype(int)\n",
    "    action_subset[\"is_home\"] = action_subset[\"is_home\"].fillna(False).astype(int)\n",
    "\n",
    "    numeric_candidates_local = list(xpass_numeric_candidates)\n",
    "    if \"is_starter\" in action_subset.columns:\n",
    "        action_subset[\"is_starter\"] = action_subset[\"is_starter\"].fillna(False).astype(int)\n",
    "        numeric_candidates_local.append(\"is_starter\")\n",
    "\n",
    "    if \"minutes_played\" in action_subset.columns:\n",
    "        action_subset[\"minutes_played\"] = action_subset[\"minutes_played\"].fillna(0.0)\n",
    "\n",
    "    categorical_features = [col for col in xpass_categorical_candidates if col in action_subset.columns]\n",
    "    for col in categorical_features:\n",
    "        action_subset[col] = action_subset[col].fillna(\"missing\").astype(\"category\")\n",
    "\n",
    "    numeric_features = [col for col in numeric_candidates_local if col in action_subset.columns]\n",
    "    used_features = numeric_features + categorical_features\n",
    "\n",
    "    train_subset = action_subset[action_subset[\"is_train_action\"]].copy()\n",
    "    test_subset = action_subset[~action_subset[\"is_train_action\"]].copy()\n",
    "\n",
    "    if train_subset.empty or train_subset[\"match_id\"].nunique() < 2:\n",
    "        fallback = float(train_subset[\"is_success\"].mean()) if len(train_subset) else 0.5\n",
    "        fallback = float(np.clip(fallback, 1e-4, 1 - 1e-4))\n",
    "        action_subset.loc[train_subset.index, \"xpass_prob\"] = fallback\n",
    "        action_subset.loc[test_subset.index, \"xpass_prob\"] = fallback\n",
    "        action_subset[\"xpass_action_group\"] = action_group\n",
    "        relevant_actions.loc[action_subset.index, \"xpass_prob\"] = action_subset[\"xpass_prob\"]\n",
    "        relevant_actions.loc[action_subset.index, \"xpass_action_group\"] = action_subset[\"xpass_action_group\"]\n",
    "        xpass_predictions.append(\n",
    "            action_subset[\n",
    "                [\n",
    "                    \"match_id\",\n",
    "                    \"player_id\",\n",
    "                    \"action_index\",\n",
    "                    \"xpass_action_group\",\n",
    "                    \"xpass_prob\",\n",
    "                    \"xt_learned_delta\",\n",
    "                    \"xt_learned_start\",\n",
    "                    \"is_train_action\",\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "        xpass_training_summary.append(\n",
    "            {\n",
    "                \"action_type\": action_group,\n",
    "                \"train_actions\": len(train_subset),\n",
    "                \"test_actions\": len(test_subset),\n",
    "                \"success_rate\": float(train_subset[\"is_success\"].mean()) if len(train_subset) else np.nan,\n",
    "            }\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    n_splits = min(5, max(2, train_subset[\"match_id\"].nunique()))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"num_leaves\": 25,\n",
    "        \"feature_fraction\": 0.7,\n",
    "        \"bagging_fraction\": 0.7,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"min_data_in_leaf\": 64,\n",
    "        \"min_gain_to_split\": 0.01,\n",
    "        \"lambda_l1\": 0.1,\n",
    "        \"lambda_l2\": 0.1,\n",
    "        \"seed\": SEED,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    oof_preds = np.zeros(len(train_subset), dtype=float)\n",
    "    test_preds = np.zeros(len(test_subset), dtype=float) if len(test_subset) else None\n",
    "    models = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(gkf.split(train_subset, groups=train_subset[\"match_id\"])):\n",
    "        X_tr = train_subset.iloc[tr_idx][used_features]\n",
    "        y_tr = train_subset.iloc[tr_idx][\"is_success\"]\n",
    "        X_val = train_subset.iloc[val_idx][used_features]\n",
    "        y_val = train_subset.iloc[val_idx][\"is_success\"]\n",
    "\n",
    "        train_ds = lgb.Dataset(\n",
    "            X_tr,\n",
    "            label=y_tr,\n",
    "            categorical_feature=categorical_features or None,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "        val_ds = lgb.Dataset(\n",
    "            X_val,\n",
    "            label=y_val,\n",
    "            reference=train_ds,\n",
    "            categorical_feature=categorical_features or None,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_ds,\n",
    "            valid_sets=[val_ds],\n",
    "            num_boost_round=800,\n",
    "            callbacks=[lgb.early_stopping(80), lgb.log_evaluation(0)],\n",
    "        )\n",
    "        models.append(model)\n",
    "        fold_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        oof_preds[val_idx] = fold_pred\n",
    "        if len(test_subset):\n",
    "            test_preds += model.predict(test_subset[used_features], num_iteration=model.best_iteration)\n",
    "\n",
    "    if len(test_subset):\n",
    "        test_preds = test_preds / len(models)\n",
    "\n",
    "    # Plattã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆfold-aware to prevent leakageï¼‰\n",
    "    if len(np.unique(train_subset[\"is_success\"])) > 1:\n",
    "        try:\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "            # Fold-aware calibration for OOF predictions to prevent data leakage\n",
    "            calibrated_oof_preds = np.zeros(len(train_subset), dtype=float)\n",
    "            \n",
    "            for fold_idx, (tr_idx, val_idx) in enumerate(gkf.split(train_subset, groups=train_subset[\"match_id\"])):\n",
    "                # Fit calibration model on TRAINING fold only (exclude validation fold)\n",
    "                calib_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "                calib_model.fit(\n",
    "                    oof_preds[tr_idx].reshape(-1, 1),\n",
    "                    train_subset.iloc[tr_idx][\"is_success\"].to_numpy()\n",
    "                )\n",
    "                \n",
    "                # Apply calibration to VALIDATION fold\n",
    "                calibrated_oof_preds[val_idx] = calib_model.predict_proba(\n",
    "                    oof_preds[val_idx].reshape(-1, 1)\n",
    "                )[:, 1]\n",
    "            \n",
    "            oof_preds = calibrated_oof_preds\n",
    "            \n",
    "            # For test predictions: use ALL training data (this is correct)\n",
    "            if test_preds is not None:\n",
    "                final_calib = LogisticRegression(max_iter=1000, random_state=42)\n",
    "                final_calib.fit(oof_preds.reshape(-1, 1), train_subset[\"is_success\"].to_numpy())\n",
    "                test_preds = final_calib.predict_proba(test_preds.reshape(-1, 1))[:, 1]\n",
    "                \n",
    "        except Exception as exc:\n",
    "            print(f\"Calibration failed for {action_group}: {exc}\")\n",
    "\n",
    "    oof_preds = np.clip(oof_preds, 1e-4, 1 - 1e-4)\n",
    "    if len(test_subset):\n",
    "        test_preds = np.clip(test_preds, 1e-4, 1 - 1e-4)\n",
    "\n",
    "    train_mean = float(train_subset[\"is_success\"].mean()) if len(train_subset) else 0.5\n",
    "    fallback = float(np.clip(train_mean, 1e-4, 1 - 1e-4))\n",
    "\n",
    "    action_subset.loc[train_subset.index, \"xpass_prob\"] = oof_preds\n",
    "    if len(test_subset):\n",
    "        action_subset.loc[test_subset.index, \"xpass_prob\"] = test_preds\n",
    "    else:\n",
    "        action_subset.loc[test_subset.index, \"xpass_prob\"] = fallback\n",
    "\n",
    "    action_subset[\"xpass_action_group\"] = action_group\n",
    "\n",
    "    relevant_actions.loc[action_subset.index, \"xpass_prob\"] = action_subset[\"xpass_prob\"]\n",
    "    relevant_actions.loc[action_subset.index, \"xpass_action_group\"] = action_subset[\"xpass_action_group\"]\n",
    "\n",
    "    xpass_predictions.append(\n",
    "        action_subset[\n",
    "            [\n",
    "                \"match_id\",\n",
    "                \"player_id\",\n",
    "                \"action_index\",\n",
    "                \"xpass_action_group\",\n",
    "                \"xpass_prob\",\n",
    "                \"xt_learned_delta\",\n",
    "                \"xt_learned_start\",\n",
    "                \"is_train_action\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    xpass_training_summary.append(\n",
    "        {\n",
    "            \"action_type\": action_group,\n",
    "            \"train_actions\": len(train_subset),\n",
    "            \"test_actions\": len(test_subset),\n",
    "            \"success_rate\": float(train_subset[\"is_success\"].mean()) if len(train_subset) else np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    cal_df = train_subset[[\"is_success\"]].copy()\n",
    "    cal_df[\"pred\"] = oof_preds\n",
    "    cal_df[\"action_type\"] = action_group\n",
    "    try:\n",
    "        unique_pred = np.unique(np.round(cal_df[\"pred\"], 6))\n",
    "        n_bins = min(10, max(4, len(unique_pred)))\n",
    "        cal_df[\"bucket\"] = pd.qcut(cal_df[\"pred\"], q=n_bins, duplicates=\"drop\")\n",
    "        agg = cal_df.groupby([\"action_type\", \"bucket\"], observed=True).agg(\n",
    "            pred_mean=(\"pred\", \"mean\"),\n",
    "            success_rate=(\"is_success\", \"mean\"),\n",
    "            count=(\"is_success\", \"size\"),\n",
    "        ).reset_index()\n",
    "        xpass_calibration_records.append(agg)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "if xpass_predictions:\n",
    "    xpass_predictions_df = pd.concat(xpass_predictions, ignore_index=True)\n",
    "else:\n",
    "    xpass_predictions_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"match_id\",\n",
    "            \"player_id\",\n",
    "            \"action_index\",\n",
    "            \"xpass_action_group\",\n",
    "            \"xpass_prob\",\n",
    "            \"xt_learned_delta\",\n",
    "            \"xt_learned_start\",\n",
    "            \"is_train_action\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "xpass_training_summary_df = pd.DataFrame(xpass_training_summary)\n",
    "if not xpass_training_summary_df.empty:\n",
    "    display(xpass_training_summary_df.sort_values(\"action_type\"))\n",
    "\n",
    "if xpass_calibration_records:\n",
    "    calibration_df = pd.concat(xpass_calibration_records, ignore_index=True)\n",
    "    display(calibration_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122cff23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "nzaeWhMpbDlr",
    "outputId": "f99d35a4-fc96-4bcc-f176-50c7235075ef"
   },
   "outputs": [],
   "source": [
    "# 5åˆ†å‰²ã®GroupKFoldã‚’è¨­å®šï¼ˆmatch_idã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "train_df[\"fold\"] = 0  # 0ã§åˆæœŸåŒ–\n",
    "\n",
    "# xAGè»¸ã®ã‚¹ã‚±ãƒ¼ãƒ«ã¯å…±é€šåŒ–ã—ã¦è¦‹ã‚„ã™ãã™ã‚‹\n",
    "x_min, x_max = train_df[\"xAG\"].min(), train_df[\"xAG\"].max()\n",
    "xAG_vals = np.arange(x_min, x_max + 0.1, 0.1).round(1)\n",
    "\n",
    "# å›³: å„foldã”ã¨ã« 3ã‚«ãƒ©ãƒ ï¼ˆTrainåˆ†å¸ƒ, Valåˆ†å¸ƒ, match_idãƒ™ãƒ³å›³ï¼‰\n",
    "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(18, 18), sharey=False, sharex=False)\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=train_df[\"match_id\"])):\n",
    "    # foldåˆ—ã‚’ã‚»ãƒƒãƒˆ\n",
    "    train_df.loc[val_idx, \"fold\"] = i + 1\n",
    "\n",
    "    # train/val ã® xAG åˆ†å¸ƒã‚’å–å¾—ï¼ˆå…±é€šã‚¹ã‚±ãƒ¼ãƒ«ã«ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰\n",
    "    trn_counts = (\n",
    "        train_df.iloc[trn_idx][\"xAG\"].value_counts().sort_index()\n",
    "        .reindex(xAG_vals, fill_value=0)\n",
    "    )\n",
    "    val_counts = (\n",
    "        train_df.iloc[val_idx][\"xAG\"].value_counts().sort_index()\n",
    "        .reindex(xAG_vals, fill_value=0)\n",
    "    )\n",
    "\n",
    "    # å·¦åˆ—: å„foldã®trainãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ\n",
    "    ax_train = axes[i, 0]\n",
    "    ax_train.bar(trn_counts.index, trn_counts.values, width=0.08, color=\"steelblue\")\n",
    "    ax_train.set_title(f\"Fold {i+1} - Train xAG åˆ†å¸ƒ\")\n",
    "    ax_train.set_xlabel(\"xAG\")\n",
    "    ax_train.set_ylabel(\"é »åº¦\")\n",
    "\n",
    "    # ä¸­åˆ—: å„foldã®validationãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ\n",
    "    ax_val = axes[i, 1]\n",
    "    ax_val.bar(val_counts.index, val_counts.values, width=0.08, color=\"orange\")\n",
    "    ax_val.set_title(f\"Fold {i+1} - Val xAG åˆ†å¸ƒ\")\n",
    "    ax_val.set_xlabel(\"xAG\")\n",
    "    ax_val.set_ylabel(\"é »åº¦\")\n",
    "\n",
    "    # å³åˆ—: match_idã®ãƒ™ãƒ³å›³ï¼ˆTrain vs Valï¼‰\n",
    "    ax_venn = axes[i, 2]\n",
    "    trn_match_ids = set(train_df.iloc[trn_idx][\"match_id\"])\n",
    "    val_match_ids = set(train_df.iloc[val_idx][\"match_id\"])\n",
    "    v = venn2(\n",
    "        [trn_match_ids, val_match_ids],\n",
    "        set_labels=(f\"Train match_id (n={len(trn_match_ids)})\",\n",
    "                    f\"Val match_id (n={len(val_match_ids)})\"),\n",
    "        ax=ax_venn\n",
    "    )\n",
    "    ax_venn.set_title(f\"Fold {i+1} - match_id ã®é‡ãªã‚Š\")\n",
    "\n",
    "# xè»¸ã‚’å…±é€šã‚¹ã‚±ãƒ¼ãƒ«ã«æƒãˆã‚‹ï¼ˆåˆ†å¸ƒå›³ã®2ã‚«ãƒ©ãƒ ã«é©ç”¨ï¼‰\n",
    "for i in range(5):\n",
    "    for j in [0, 1]:\n",
    "        ax = axes[i, j]\n",
    "        ax.set_xlim(x_min - 0.05, x_max + 0.05)  # ç«¯ã‚’å°‘ã—ä½™è£•æŒãŸã›ã‚‹\n",
    "        ax.set_xticks(xAG_vals[::2])  # ãƒ©ãƒ™ãƒ«ã®æ•°ã‚’é–“å¼•ã\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27262c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"eÎ”xTã®Î»æœ€é©åŒ–ã¨ç‰¹å¾´é‡é›†ç´„ã‚’å®Ÿè¡Œä¸­...\")\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "edxt_feature_cols = []\n",
    "\n",
    "if xpass_predictions_df.empty:\n",
    "    print(\"xPassã®å¯¾è±¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€eÎ”xTç‰¹å¾´é‡ã¯è¿½åŠ ã•ã‚Œã¾ã›ã‚“ã€‚\")\n",
    "else:\n",
    "    xpass_predictions_df = xpass_predictions_df.copy()\n",
    "    xpass_predictions_df[\"xt_learned_delta\"] = xpass_predictions_df[\"xt_learned_delta\"].fillna(0.0)\n",
    "    xpass_predictions_df[\"xt_learned_start\"] = xpass_predictions_df[\"xt_learned_start\"].fillna(0.0)\n",
    "    xpass_predictions_df[\"success_component\"] = xpass_predictions_df[\"xpass_prob\"] * xpass_predictions_df[\"xt_learned_delta\"]\n",
    "    xpass_predictions_df[\"fail_component_raw\"] = (1.0 - xpass_predictions_df[\"xpass_prob\"]) * xpass_predictions_df[\"xt_learned_start\"]\n",
    "    xpass_predictions_df[\"fail_weight\"] = (1.0 - xpass_predictions_df[\"xpass_prob\"]).fillna(0.0)\n",
    "    train_actions = xpass_predictions_df[xpass_predictions_df[\"is_train_action\"]].copy()\n",
    "    global_start_mean = float(train_actions[\"xt_learned_start\"].mean()) if not train_actions.empty else 0.0\n",
    "    global_start_std = float(train_actions[\"xt_learned_start\"].std(ddof=0)) if not train_actions.empty else 0.0\n",
    "    if global_start_std < 1e-6:\n",
    "        global_start_std = 1.0\n",
    "    global_start_median = float(train_actions[\"xt_learned_start\"].median()) if not train_actions.empty else 0.0\n",
    "    global_start_mad = float((train_actions[\"xt_learned_start\"] - global_start_median).abs().median()) if not train_actions.empty else 0.0\n",
    "    if global_start_mad < 1e-6:\n",
    "        global_start_mad = 1.0\n",
    "    # ============================================================\n",
    "    # FIX ISSUE 1: Fold-aware normalization to prevent data leakage\n",
    "    # Compute group statistics from OTHER folds only for each validation fold\n",
    "    # ============================================================\n",
    "    # Initialize columns for fold-aware statistics\n",
    "    xpass_predictions_df[\"fail_group_mean\"] = global_start_mean\n",
    "    xpass_predictions_df[\"fail_group_std\"] = global_start_std\n",
    "    xpass_predictions_df[\"fail_group_median\"] = global_start_median\n",
    "    xpass_predictions_df[\"fail_group_mad\"] = global_start_mad\n",
    "    # For training data: use fold-aware statistics (exclude current fold)\n",
    "    train_actions_with_fold = train_actions.merge(\n",
    "        train_df[[\"match_id\", \"player_id\", \"fold\"]],\n",
    "        on=[\"match_id\", \"player_id\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    for fold in train_actions_with_fold[\"fold\"].dropna().unique():\n",
    "        # Get actions from OTHER folds (not current fold)\n",
    "        other_folds_actions = train_actions_with_fold[train_actions_with_fold[\"fold\"] != fold]\n",
    "        if other_folds_actions.empty:\n",
    "            continue\n",
    "        # Compute statistics from other folds only\n",
    "        fold_group_mean = other_folds_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].mean()\n",
    "        fold_group_std = other_folds_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].std(ddof=0)\n",
    "        fold_group_median = other_folds_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].median()\n",
    "        fold_group_mad = other_folds_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].apply(\n",
    "            lambda s: (s - s.median()).abs().median()\n",
    "        )\n",
    "        # Apply to current fold's validation data\n",
    "        # Create the mask properly\n",
    "        fold_match_player = train_df[train_df[\"fold\"] == fold][[\"match_id\", \"player_id\"]].copy()\n",
    "        fold_match_player[\"_in_fold\"] = True\n",
    "        xpass_with_fold = xpass_predictions_df.merge(\n",
    "            fold_match_player,\n",
    "            on=[\"match_id\", \"player_id\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        current_fold_mask = (xpass_with_fold[\"is_train_action\"]) & (xpass_with_fold[\"_in_fold\"] == True)\n",
    "        if current_fold_mask.sum() > 0:\n",
    "            xpass_predictions_df.loc[current_fold_mask, \"fail_group_mean\"] = (\n",
    "                xpass_predictions_df.loc[current_fold_mask, \"xpass_action_group\"]\n",
    "                .map(fold_group_mean)\n",
    "                .fillna(global_start_mean)\n",
    "            )\n",
    "            xpass_predictions_df.loc[current_fold_mask, \"fail_group_std\"] = (\n",
    "                xpass_predictions_df.loc[current_fold_mask, \"xpass_action_group\"]\n",
    "                .map(fold_group_std)\n",
    "                .fillna(global_start_std)\n",
    "            )\n",
    "            xpass_predictions_df.loc[current_fold_mask, \"fail_group_median\"] = (\n",
    "                xpass_predictions_df.loc[current_fold_mask, \"xpass_action_group\"]\n",
    "                .map(fold_group_median)\n",
    "                .fillna(global_start_median)\n",
    "            )\n",
    "            xpass_predictions_df.loc[current_fold_mask, \"fail_group_mad\"] = (\n",
    "                xpass_predictions_df.loc[current_fold_mask, \"xpass_action_group\"]\n",
    "                .map(fold_group_mad)\n",
    "                .fillna(global_start_mad)\n",
    "            )\n",
    "    # For test data: use statistics from ALL training data\n",
    "    test_mask = ~xpass_predictions_df[\"is_train_action\"]\n",
    "    if test_mask.sum() > 0:\n",
    "        group_mean_all = train_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].mean()\n",
    "        group_std_all = train_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].std(ddof=0)\n",
    "        group_median_all = train_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].median()\n",
    "        group_mad_all = train_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].apply(\n",
    "            lambda s: (s - s.median()).abs().median()\n",
    "        )\n",
    "        xpass_predictions_df.loc[test_mask, \"fail_group_mean\"] = (\n",
    "            xpass_predictions_df.loc[test_mask, \"xpass_action_group\"]\n",
    "            .map(group_mean_all)\n",
    "            .fillna(global_start_mean)\n",
    "        )\n",
    "        xpass_predictions_df.loc[test_mask, \"fail_group_std\"] = (\n",
    "            xpass_predictions_df.loc[test_mask, \"xpass_action_group\"]\n",
    "            .map(group_std_all)\n",
    "            .fillna(global_start_std)\n",
    "        )\n",
    "        xpass_predictions_df.loc[test_mask, \"fail_group_median\"] = (\n",
    "            xpass_predictions_df.loc[test_mask, \"xpass_action_group\"]\n",
    "            .map(group_median_all)\n",
    "            .fillna(global_start_median)\n",
    "        )\n",
    "        xpass_predictions_df.loc[test_mask, \"fail_group_mad\"] = (\n",
    "            xpass_predictions_df.loc[test_mask, \"xpass_action_group\"]\n",
    "            .map(group_mad_all)\n",
    "            .fillna(global_start_mad)\n",
    "        )\n",
    "    # Ensure minimum std and mad to avoid division by zero\n",
    "    xpass_predictions_df[\"fail_group_std\"] = xpass_predictions_df[\"fail_group_std\"].where(\n",
    "        xpass_predictions_df[\"fail_group_std\"] > 1e-6, global_start_std\n",
    "    )\n",
    "    xpass_predictions_df[\"fail_group_mad\"] = xpass_predictions_df[\"fail_group_mad\"].where(\n",
    "        xpass_predictions_df[\"fail_group_mad\"] > 1e-6, global_start_mad\n",
    "    )\n",
    "    # Validation: Ensure no NaN values remain\n",
    "    assert xpass_predictions_df[\"fail_group_mean\"].isna().sum() == 0, \"fail_group_mean has NaN values\"\n",
    "    assert xpass_predictions_df[\"fail_group_std\"].isna().sum() == 0, \"fail_group_std has NaN values\"\n",
    "    assert xpass_predictions_df[\"fail_group_median\"].isna().sum() == 0, \"fail_group_median has NaN values\"\n",
    "    assert xpass_predictions_df[\"fail_group_mad\"].isna().sum() == 0, \"fail_group_mad has NaN values\"\n",
    "    print(f\"âœ“ Fold-aware normalization applied: {len(train_actions_with_fold['fold'].dropna().unique())} folds processed\")\n",
    "    pass_train = train_actions[train_actions[\"xpass_action_group\"] == \"pass\"]\n",
    "    if not pass_train.empty:\n",
    "        pass_reference = np.sort(pass_train[\"xt_learned_start\"].to_numpy())\n",
    "    else:\n",
    "        pass_reference = None\n",
    "    def _quantile_center(values: np.ndarray, reference: np.ndarray) -> np.ndarray:\n",
    "        if reference is None or len(reference) == 0:\n",
    "            return np.zeros_like(values, dtype=float)\n",
    "        ranks = np.searchsorted(reference, values, side=\"left\")\n",
    "        quantiles = (ranks + 0.5) / len(reference)\n",
    "        quantiles = np.clip(quantiles, 1e-6, 1 - 1e-6)\n",
    "        return quantiles - 0.5\n",
    "    xpass_predictions_df[\"fail_component_scaled\"] = 0.0\n",
    "    pass_mask = xpass_predictions_df[\"xpass_action_group\"] == \"pass\"\n",
    "    if pass_mask.any():\n",
    "        if pass_reference is not None and len(pass_reference) > 10:\n",
    "            centered = _quantile_center(xpass_predictions_df.loc[pass_mask, \"xt_learned_start\"].to_numpy(), pass_reference)\n",
    "        else:\n",
    "            centered = (\n",
    "                (xpass_predictions_df.loc[pass_mask, \"xt_learned_start\"] - xpass_predictions_df.loc[pass_mask, \"fail_group_median\"]) / xpass_predictions_df.loc[pass_mask, \"fail_group_mad\"]\n",
    "            ).to_numpy()\n",
    "        xpass_predictions_df.loc[pass_mask, \"fail_component_scaled\"] = xpass_predictions_df.loc[pass_mask, \"fail_weight\"].to_numpy() * centered\n",
    "    non_pass_mask = ~pass_mask\n",
    "    if non_pass_mask.any():\n",
    "        centered = (\n",
    "            xpass_predictions_df.loc[non_pass_mask, \"xt_learned_start\"].to_numpy() - xpass_predictions_df.loc[non_pass_mask, \"fail_group_mean\"].to_numpy()\n",
    "        ) / xpass_predictions_df.loc[non_pass_mask, \"fail_group_std\"].to_numpy()\n",
    "        xpass_predictions_df.loc[non_pass_mask, \"fail_component_scaled\"] = xpass_predictions_df.loc[non_pass_mask, \"fail_weight\"].to_numpy() * centered\n",
    "    train_actions = xpass_predictions_df[xpass_predictions_df[\"is_train_action\"]].copy()\n",
    "    train_meta = train_df[[\"match_id\", \"player_id\", \"fold\", \"xAG\"]].copy()\n",
    "    fold_labels = sorted(train_df[\"fold\"].unique())\n",
    "    def _weighted_rmse_local(y_true, y_pred):\n",
    "        weights = make_sample_weight(y_true)\n",
    "        return float(np.sqrt(np.mean(weights * (y_true - y_pred) ** 2) + 1e-9))\n",
    "    aggregated_components = (\n",
    "        train_actions.groupby([\"match_id\", \"player_id\", \"xpass_action_group\"])\n",
    "        .agg(\n",
    "            success_sum=(\"success_component\", \"sum\"),\n",
    "            fail_sum_scaled=(\"fail_component_scaled\", \"sum\"),\n",
    "            fail_sum_raw=(\"fail_component_raw\", \"sum\"),\n",
    "            fail_weight_sum=(\"fail_weight\", \"sum\"),\n",
    "            action_count=(\"success_component\", \"count\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    lambda_per_type = {}\n",
    "    lambda_meta = []\n",
    "    lambda_bounds = {\n",
    "        \"pass\": (-0.3, 0.6),\n",
    "        \"cross\": (-0.6, 2.0),\n",
    "        \"dribble\": (-0.6, 2.0),\n",
    "        \"carry\": (-0.6, 2.0),\n",
    "        \"corner\": (-1.5, 3.0),\n",
    "        \"free_kick\": (-1.5, 3.0),\n",
    "    }\n",
    "    for action_group in sorted(xpass_predictions_df[\"xpass_action_group\"].dropna().unique()):\n",
    "        type_df = aggregated_components[aggregated_components[\"xpass_action_group\"] == action_group].copy()\n",
    "        type_df = type_df.merge(train_meta, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "        type_df = type_df.dropna(subset=[\"xAG\", \"fold\"])\n",
    "        if type_df.empty:\n",
    "            lambda_per_type[action_group] = 0.0\n",
    "            continue\n",
    "        lam_low, lam_high = lambda_bounds.get(action_group, (-1.0, 2.0))\n",
    "        def objective(trial):\n",
    "            lam = trial.suggest_float(\"lambda\", lam_low, lam_high)\n",
    "            preds = type_df[\"success_sum\"] - lam * type_df[\"fail_sum_scaled\"]\n",
    "            scores = []\n",
    "            for fold in fold_labels:\n",
    "                fold_mask = type_df[\"fold\"] == fold\n",
    "                if not fold_mask.any():\n",
    "                    continue\n",
    "                scores.append(\n",
    "                    _weighted_rmse_local(\n",
    "                        type_df.loc[fold_mask, \"xAG\"].to_numpy(),\n",
    "                        preds.loc[fold_mask].to_numpy(),\n",
    "                    )\n",
    "                )\n",
    "            return float(np.mean(scores)) if scores else 1.0\n",
    "        study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=SEED))\n",
    "        study.optimize(objective, n_trials=35, show_progress_bar=False)\n",
    "        best_lambda = float(study.best_params[\"lambda\"])\n",
    "        lambda_per_type[action_group] = best_lambda\n",
    "        lambda_meta.append(\n",
    "            {\n",
    "                \"action_type\": action_group,\n",
    "                \"lambda\": best_lambda,\n",
    "                \"lambda_min\": lam_low,\n",
    "                \"lambda_max\": lam_high,\n",
    "                \"train_rows\": int(type_df.shape[0]),\n",
    "                \"actions_per_player_mean\": float(type_df[\"action_count\"].mean()),\n",
    "                \"fail_scaled_mean\": float(type_df[\"fail_sum_scaled\"].mean()),\n",
    "            }\n",
    "        )\n",
    "    lambda_meta_df = pd.DataFrame(lambda_meta)\n",
    "    if not lambda_meta_df.empty:\n",
    "        display(lambda_meta_df.sort_values(\"lambda\"))\n",
    "        print(\"Î»åˆ†å¸ƒçµ±è¨ˆ:\")\n",
    "        display(lambda_meta_df[\"lambda\"].describe())\n",
    "    for action_group, lam_value in lambda_per_type.items():\n",
    "        type_actions = xpass_predictions_df[xpass_predictions_df[\"xpass_action_group\"] == action_group].copy()\n",
    "        if type_actions.empty:\n",
    "            continue\n",
    "        type_actions[\"edxt_value_scaled\"] = type_actions[\"success_component\"] - lam_value * type_actions[\"fail_component_scaled\"]\n",
    "        type_actions[\"edxt_positive_scaled\"] = np.clip(type_actions[\"edxt_value_scaled\"], 0.0, None)\n",
    "        type_actions[\"edxt_value\"] = type_actions[\"success_component\"] - lam_value * type_actions[\"fail_component_raw\"]\n",
    "        type_actions[\"edxt_positive\"] = np.clip(type_actions[\"edxt_value\"], 0.0, None)\n",
    "        agg_train = (\n",
    "            type_actions[type_actions[\"is_train_action\"]]\n",
    "            .groupby([\"match_id\", \"player_id\"])\n",
    "            .agg(\n",
    "                edxt_sum=(\"edxt_value\", \"sum\"),\n",
    "                edxt_mean=(\"edxt_value\", \"mean\"),\n",
    "                edxt_max=(\"edxt_value\", \"max\"),\n",
    "                edxt_positive_sum=(\"edxt_positive\", \"sum\"),\n",
    "                edxt_positive_mean=(\"edxt_positive\", \"mean\"),\n",
    "                edxt_scaled_sum=(\"edxt_value_scaled\", \"sum\"),\n",
    "                edxt_scaled_mean=(\"edxt_value_scaled\", \"mean\"),\n",
    "                edxt_scaled_max=(\"edxt_value_scaled\", \"max\"),\n",
    "                edxt_scaled_positive_sum=(\"edxt_positive_scaled\", \"sum\"),\n",
    "                edxt_scaled_positive_mean=(\"edxt_positive_scaled\", \"mean\"),\n",
    "                edxt_count=(\"edxt_value\", \"count\"),\n",
    "                success_sum=(\"success_component\", \"sum\"),\n",
    "                fail_sum_raw=(\"fail_component_raw\", \"sum\"),\n",
    "                fail_sum_scaled=(\"fail_component_scaled\", \"sum\"),\n",
    "                fail_weight_sum=(\"fail_weight\", \"sum\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "        agg_test = (\n",
    "            type_actions[~type_actions[\"is_train_action\"]]\n",
    "            .groupby([\"match_id\", \"player_id\"])\n",
    "            .agg(\n",
    "                edxt_sum=(\"edxt_value\", \"sum\"),\n",
    "                edxt_mean=(\"edxt_value\", \"mean\"),\n",
    "                edxt_max=(\"edxt_value\", \"max\"),\n",
    "                edxt_positive_sum=(\"edxt_positive\", \"sum\"),\n",
    "                edxt_positive_mean=(\"edxt_positive\", \"mean\"),\n",
    "                edxt_scaled_sum=(\"edxt_value_scaled\", \"sum\"),\n",
    "                edxt_scaled_mean=(\"edxt_value_scaled\", \"mean\"),\n",
    "                edxt_scaled_max=(\"edxt_value_scaled\", \"max\"),\n",
    "                edxt_scaled_positive_sum=(\"edxt_positive_scaled\", \"sum\"),\n",
    "                edxt_scaled_positive_mean=(\"edxt_positive_scaled\", \"mean\"),\n",
    "                edxt_count=(\"edxt_value\", \"count\"),\n",
    "                success_sum=(\"success_component\", \"sum\"),\n",
    "                fail_sum_raw=(\"fail_component_raw\", \"sum\"),\n",
    "                fail_sum_scaled=(\"fail_component_scaled\", \"sum\"),\n",
    "                fail_weight_sum=(\"fail_weight\", \"sum\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "        col_map = {\n",
    "            \"edxt_sum\": f\"{action_group}_edxt_sum\",\n",
    "            \"edxt_mean\": f\"{action_group}_edxt_mean\",\n",
    "            \"edxt_max\": f\"{action_group}_edxt_max\",\n",
    "            \"edxt_positive_sum\": f\"{action_group}_edxt_positive_sum\",\n",
    "            \"edxt_positive_mean\": f\"{action_group}_edxt_positive_mean\",\n",
    "            \"edxt_scaled_sum\": f\"{action_group}_edxt_scaled_sum\",\n",
    "            \"edxt_scaled_mean\": f\"{action_group}_edxt_scaled_mean\",\n",
    "            \"edxt_scaled_max\": f\"{action_group}_edxt_scaled_max\",\n",
    "            \"edxt_scaled_positive_sum\": f\"{action_group}_edxt_scaled_positive_sum\",\n",
    "            \"edxt_scaled_positive_mean\": f\"{action_group}_edxt_scaled_positive_mean\",\n",
    "            \"edxt_count\": f\"{action_group}_edxt_count\",\n",
    "            \"success_sum\": f\"{action_group}_edxt_success_sum\",\n",
    "            \"fail_sum_raw\": f\"{action_group}_edxt_fail_sum\",\n",
    "            \"fail_sum_scaled\": f\"{action_group}_edxt_fail_scaled_sum\",\n",
    "            \"fail_weight_sum\": f\"{action_group}_fail_weight_sum\",\n",
    "        }\n",
    "        train_df = train_df.merge(agg_train.rename(columns=col_map), on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "        test_df = test_df.merge(agg_test.rename(columns=col_map), on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "        for new_col in col_map.values():\n",
    "            if new_col not in train_df.columns:\n",
    "                train_df[new_col] = 0.0\n",
    "            if new_col not in test_df.columns:\n",
    "                test_df[new_col] = 0.0\n",
    "            train_df[new_col] = train_df[new_col].fillna(0.0)\n",
    "            test_df[new_col] = test_df[new_col].fillna(0.0)\n",
    "        edxt_feature_cols.extend(col_map.values())\n",
    "    openplay_groups = {\"pass\", \"cross\", \"dribble\", \"carry\"}\n",
    "    setpiece_groups = {\"corner\", \"free_kick\"}\n",
    "    def _sum_columns(df, cols, new_col):\n",
    "        found = [col for col in cols if col in df.columns]\n",
    "        if found:\n",
    "            df[new_col] = df[found].sum(axis=1)\n",
    "        else:\n",
    "            df[new_col] = 0.0\n",
    "    setpiece_scaled_cols = [f\"{g}_edxt_scaled_positive_sum\" for g in setpiece_groups]\n",
    "    openplay_scaled_cols = [f\"{g}_edxt_scaled_positive_sum\" for g in openplay_groups]\n",
    "    setpiece_raw_cols = [f\"{g}_edxt_positive_sum\" for g in setpiece_groups]\n",
    "    openplay_raw_cols = [f\"{g}_edxt_positive_sum\" for g in openplay_groups]\n",
    "    for df in (train_df, test_df):\n",
    "        _sum_columns(df, setpiece_scaled_cols, \"setpiece_edxt_scaled_positive_sum\")\n",
    "        _sum_columns(df, openplay_scaled_cols, \"openplay_edxt_scaled_positive_sum\")\n",
    "        _sum_columns(df, setpiece_raw_cols, \"setpiece_edxt_positive_sum\")\n",
    "        _sum_columns(df, openplay_raw_cols, \"openplay_edxt_positive_sum\")\n",
    "        scaled_denom = df[\"setpiece_edxt_scaled_positive_sum\"] + df[\"openplay_edxt_scaled_positive_sum\"]\n",
    "        raw_denom = df[\"setpiece_edxt_positive_sum\"] + df[\"openplay_edxt_positive_sum\"]\n",
    "        df[\"setpiece_edxt_scaled_ratio\"] = np.where(scaled_denom > 0, df[\"setpiece_edxt_scaled_positive_sum\"] / scaled_denom, 0.0)\n",
    "        df[\"setpiece_edxt_raw_ratio\"] = np.where(raw_denom > 0, df[\"setpiece_edxt_positive_sum\"] / raw_denom, 0.0)\n",
    "    edxt_feature_cols.extend([\n",
    "        \"setpiece_edxt_scaled_positive_sum\",\n",
    "        \"openplay_edxt_scaled_positive_sum\",\n",
    "        \"setpiece_edxt_positive_sum\",\n",
    "        \"openplay_edxt_positive_sum\",\n",
    "        \"setpiece_edxt_scaled_ratio\",\n",
    "        \"setpiece_edxt_raw_ratio\",\n",
    "    ])\n",
    "    edxt_feature_cols = sorted(dict.fromkeys(edxt_feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a69637",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"ãƒãƒ¼ãƒ æ–‡è„ˆç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¦ã„ã¾ã™...\")\n",
    "\n",
    "team_context_feature_cols = []\n",
    "team_base_candidates = [\n",
    "    col\n",
    "    for col in train_df.columns\n",
    "    if col.startswith(\"xt_learned_\") or col.startswith(\"possession_xt_\") or col.endswith(\"_edxt_sum\")\n",
    "]\n",
    "team_base_columns = [col for col in team_base_candidates if np.issubdtype(train_df[col].dtype, np.number)]\n",
    "\n",
    "if team_base_columns:\n",
    "    for df in (train_df, test_df):\n",
    "        for col in team_base_columns:\n",
    "            team_sum = df.groupby([\"match_id\", \"Squad\"])[col].transform(\"sum\")\n",
    "            sum_col = f\"{col}_team_sum\"\n",
    "            share_col = f\"{col}_team_share\"\n",
    "            lopo_col = f\"{col}_team_lopo\"\n",
    "            df[sum_col] = team_sum\n",
    "            df[share_col] = np.where(team_sum != 0, df[col] / team_sum, 0.0)\n",
    "            df[lopo_col] = team_sum - df[col]\n",
    "            df[sum_col] = df[sum_col].fillna(0.0)\n",
    "            df[share_col] = df[share_col].fillna(0.0)\n",
    "            df[lopo_col] = df[lopo_col].fillna(0.0)\n",
    "            if df is train_df:\n",
    "                team_context_feature_cols.extend([sum_col, share_col, lopo_col])\n",
    "\n",
    "    team_context_feature_cols = sorted(dict.fromkeys(team_context_feature_cols))\n",
    "else:\n",
    "    team_context_feature_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c9f3d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"ãƒªãƒ¼ã‚°åˆ¥ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç‰¹å¾´ã‚’ä½œæˆã—ã¦ã„ã¾ã™...\")\n",
    "\n",
    "comp_interaction_feature_cols = []\n",
    "comp_cross_base_features = [\n",
    "    col\n",
    "    for col in [\n",
    "        \"xt_learned_delta_sum\",\n",
    "        \"xt_learned_positive_delta_sum\",\n",
    "        \"possession_xt_positive_sum\",\n",
    "        \"possession_xt_delta_sum\",\n",
    "        \"possession_speed_ground_mean\",\n",
    "    ]\n",
    "    if col in train_df.columns\n",
    "]\n",
    "\n",
    "if comp_cross_base_features:\n",
    "    comp_dummy_train = pd.get_dummies(train_df[\"Comp\"].astype(str), prefix=\"comp_gate\", dtype=float)\n",
    "    comp_dummy_test = pd.get_dummies(test_df[\"Comp\"].astype(str), prefix=\"comp_gate\", dtype=float)\n",
    "    comp_dummy_train, comp_dummy_test = comp_dummy_train.align(comp_dummy_test, join=\"outer\", axis=1, fill_value=0.0)\n",
    "    comp_dummy_test = comp_dummy_test[comp_dummy_train.columns]\n",
    "\n",
    "    train_base = train_df[comp_cross_base_features].fillna(0.0)\n",
    "    test_base = test_df[comp_cross_base_features].fillna(0.0)\n",
    "\n",
    "    for base_col in comp_cross_base_features:\n",
    "        train_values = train_base[base_col].to_numpy()\n",
    "        test_values = test_base[base_col].to_numpy()\n",
    "        for comp_col in comp_dummy_train.columns:\n",
    "            feat_name = f\"{base_col}__{comp_col}\"\n",
    "            train_df[feat_name] = train_values * comp_dummy_train[comp_col].to_numpy()\n",
    "            test_df[feat_name] = test_values * comp_dummy_test[comp_col].to_numpy()\n",
    "            comp_interaction_feature_cols.append(feat_name)\n",
    "\n",
    "    comp_interaction_feature_cols = sorted(dict.fromkeys(comp_interaction_feature_cols))\n",
    "else:\n",
    "    comp_interaction_feature_cols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66d81c",
   "metadata": {
    "id": "A7xHPcUziuhW"
   },
   "source": [
    "## ç‰¹å¾´é‡ã®çµ±åˆ\n",
    "\n",
    "ä½œæˆã—ãŸå…¨ã¦ã®ç‰¹å¾´é‡ã‚’çµ±åˆã—ã€train/testãƒ‡ãƒ¼ã‚¿ã«ãƒãƒ¼ã‚¸ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a9eca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiPaa-Dz6Gvj",
    "lines_to_next_cell": 2,
    "outputId": "cc523b94-b8ff-47fd-b87c-8ced83eb52a0"
   },
   "outputs": [],
   "source": [
    "# å¿œç”¨ç‰¹å¾´é‡ã‚’train/testã¸ãƒãƒ¼ã‚¸\n",
    "train_df = (\n",
    "    train_df\n",
    "    .merge(success_rates, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(zone_actions, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(per_minute_features, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(offense_defense_balance, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(pass_leads_to_shot, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(progressive_features, on=['match_id', 'player_id'], how='left')\n",
    ")\n",
    "\n",
    "train_df['pass_leads_to_shot'] = train_df['pass_leads_to_shot'].fillna(0)\n",
    "\n",
    "progressive_cols = [col for col in progressive_features.columns if col not in ['match_id', 'player_id']]\n",
    "for col in progressive_cols:\n",
    "    train_df[col] = train_df[col].fillna(0.0)\n",
    "\n",
    "\n",
    "test_df = (\n",
    "    test_df\n",
    "    .merge(success_rates, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(zone_actions, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(per_minute_features, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(offense_defense_balance, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(pass_leads_to_shot, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(progressive_features, on=['match_id', 'player_id'], how='left')\n",
    ")\n",
    "\n",
    "test_df['pass_leads_to_shot'] = test_df['pass_leads_to_shot'].fillna(0)\n",
    "for col in progressive_cols:\n",
    "    test_df[col] = test_df[col].fillna(0.0)\n",
    "\n",
    "print(f\"ãƒãƒ¼ã‚¸å¾Œã®trainãƒ‡ãƒ¼ã‚¿shape: {train_df.shape}\")\n",
    "print(f\"ãƒãƒ¼ã‚¸å¾Œã®testãƒ‡ãƒ¼ã‚¿shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311c1ec",
   "metadata": {
    "id": "FHzc1BjgZYRR"
   },
   "source": [
    "## ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†å‰²\n",
    "\n",
    "åˆå›ã®baselineã§ã¯ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åˆ†å‰²ã™ã‚‹KFoldã‚’ç”¨ã„ã¾ã—ãŸãŒã€ä»Šå›ã¯ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã«åˆã‚ã›ãŸåˆ¥ã®åˆ†å‰²æ–¹æ³•ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "\n",
    "EDAã§ç¢ºèªã—ãŸã‚ˆã†ã«ã€ä»Šå›ã¯trainãƒ‡ãƒ¼ã‚¿ã¨testãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã¯ã€match_idã®é‡ãªã‚Šã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n",
    "ã™ãªã‚ã¡ã€testãƒ‡ãƒ¼ã‚¿ã‚’äºˆæ¸¬ã™ã‚‹ã¨ãã«ã¯ã€ã“ã‚Œã¾ã§è¦‹ãŸã“ã¨ã®ãªã„è©¦åˆã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦äºˆæ¸¬ã‚’ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "ã“ã®çŠ¶æ³ã‚’trainãƒ‡ãƒ¼ã‚¿å†…éƒ¨ã§ã®Cross Validationã§ã‚‚ãªã‚‹ã¹ãå†ç¾ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€å®Ÿéš›ã®ã‚¿ã‚¹ã‚¯ã«è¿‘ã„çŠ¶æ³ã§æ­£ã—ã„è©•ä¾¡ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã“ã“ã§ã¯ã€GroupKFoldã‚’ç”¨ã„ã¦ã€trainãƒ‡ãƒ¼ã‚¿ã‚’match_idãŒè¢«ã‚‰ãªã„ã‚ˆã†ã«5åˆ†å‰²ã—ã¾ã™ã€‚ã“ã†ã™ã‚‹ã“ã¨ã§ã€å„foldã§ã®trainãƒ‡ãƒ¼ã‚¿ã¨validãƒ‡ãƒ¼ã‚¿ã®match_idãŒé‡ãªã‚‰ãªããªã‚Šã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b372196",
   "metadata": {
    "id": "EqDZiepKaIf3"
   },
   "source": [
    "## ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç‰¹å¾´é‡ã®ä½œæˆ\n",
    "print(\"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç‰¹å¾´é‡ã‚’ä½œæˆä¸­...\")\n",
    "\n",
    "# SquadÃ—Opponentã®äº¤äº’ä½œç”¨ç‰¹å¾´ã‚’ä½œæˆ\n",
    "train_df[\"Squad_x_Opponent\"] = train_df[\"Squad\"].astype(str) + \"_vs_\" + train_df[\"Opponent\"].astype(str)\n",
    "test_df[\"Squad_x_Opponent\"] = test_df[\"Squad\"].astype(str) + \"_vs_\" + test_df[\"Opponent\"].astype(str)\n",
    "\n",
    "target_encoding_cols = [\"player_id\", \"Squad\", \"Opponent\", \"Squad_x_Opponent\"]\n",
    "global_mean = train_df[\"xAG\"].mean()\n",
    "smoothing = 10.0\n",
    "fold_labels = sorted(train_df[\"fold\"].unique())\n",
    "\n",
    "for col in target_encoding_cols:\n",
    "    enc_col = f\"{col}_target_enc\"\n",
    "    train_df[enc_col] = np.nan\n",
    "\n",
    "    for fold in fold_labels:\n",
    "        trn = train_df[train_df[\"fold\"] != fold]\n",
    "        val_mask = train_df[\"fold\"] == fold\n",
    "\n",
    "        stats = trn.groupby(col)[\"xAG\"].agg([\"sum\", \"count\"])\n",
    "        stats[\"encoding\"] = (stats[\"sum\"] + global_mean * smoothing) / (stats[\"count\"] + smoothing)\n",
    "\n",
    "        train_df.loc[val_mask, enc_col] = train_df.loc[val_mask, col].map(stats[\"encoding\"]).fillna(global_mean)\n",
    "\n",
    "    overall_stats = train_df.groupby(col)[\"xAG\"].agg([\"sum\", \"count\"])\n",
    "    overall_stats[\"encoding\"] = (overall_stats[\"sum\"] + global_mean * smoothing) / (overall_stats[\"count\"] + smoothing)\n",
    "\n",
    "    test_df[enc_col] = test_df[col].map(overall_stats[\"encoding\"]).fillna(global_mean)\n",
    "\n",
    "    missing_train = train_df[enc_col].isna().sum()\n",
    "    missing_test = test_df[enc_col].isna().sum()\n",
    "\n",
    "    if missing_train > 0:\n",
    "        train_df.loc[train_df[enc_col].isna(), enc_col] = global_mean\n",
    "    if missing_test > 0:\n",
    "        test_df.loc[test_df[enc_col].isna(), enc_col] = global_mean\n",
    "\n",
    "    print(f\"  {col}: train missing {int(missing_train)}, test missing {int(missing_test)}\")\n",
    "\n",
    "print(\"ãƒªãƒ¼ã‚°/ãƒãƒ¼ãƒ ãƒã‚¤ã‚¢ã‚¹èª¿æ•´ç‰¹å¾´ã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "train_df[\"Comp_target_enc\"] = np.nan\n",
    "comp_smoothing = 5.0\n",
    "\n",
    "for fold in fold_labels:\n",
    "    trn = train_df[train_df[\"fold\"] != fold]\n",
    "    val_mask = train_df[\"fold\"] == fold\n",
    "\n",
    "    comp_stats = trn.groupby(\"Comp\")[\"xAG\"].agg([\"sum\", \"count\"])\n",
    "    comp_stats[\"encoding\"] = (comp_stats[\"sum\"] + global_mean * comp_smoothing) / (comp_stats[\"count\"] + comp_smoothing)\n",
    "\n",
    "    train_df.loc[val_mask, \"Comp_target_enc\"] = train_df.loc[val_mask, \"Comp\"].map(comp_stats[\"encoding\"]).fillna(global_mean)\n",
    "\n",
    "comp_overall_stats = train_df.groupby(\"Comp\")[\"xAG\"].agg([\"sum\", \"count\"])\n",
    "comp_overall_stats[\"encoding\"] = (comp_overall_stats[\"sum\"] + global_mean * comp_smoothing) / (comp_overall_stats[\"count\"] + comp_smoothing)\n",
    "\n",
    "test_df[\"Comp_target_enc\"] = test_df[\"Comp\"].map(comp_overall_stats[\"encoding\"]).fillna(global_mean)\n",
    "\n",
    "train_df[\"Comp_target_enc\"] = train_df[\"Comp_target_enc\"].fillna(global_mean)\n",
    "\n",
    "test_df[\"Comp_target_enc\"] = test_df[\"Comp_target_enc\"].fillna(global_mean)\n",
    "\n",
    "train_df[\"Squad_comp_residual\"] = train_df[\"Squad_target_enc\"] - train_df[\"Comp_target_enc\"]\n",
    "test_df[\"Squad_comp_residual\"] = test_df[\"Squad_target_enc\"] - test_df[\"Comp_target_enc\"]\n",
    "\n",
    "train_df[\"Squad_global_residual\"] = train_df[\"Squad_target_enc\"] - global_mean\n",
    "test_df[\"Squad_global_residual\"] = test_df[\"Squad_target_enc\"] - global_mean\n",
    "\n",
    "# diff between Squad and Opponent TE for matchup effect\n",
    "train_df[\"Squad_vs_opponent_gap\"] = train_df[\"Squad_target_enc\"] - train_df[\"Opponent_target_enc\"]\n",
    "test_df[\"Squad_vs_opponent_gap\"] = test_df[\"Squad_target_enc\"] - test_df[\"Opponent_target_enc\"]\n",
    "\n",
    "print(\"  Squad_comp_residual ãªã©ã®æ–°ç‰¹å¾´ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb98842",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "507qeMbXaIf3",
    "lines_to_next_cell": 2,
    "outputId": "bc0b39f4-fe13-4491-8f88-71c960669942"
   },
   "outputs": [],
   "source": [
    "\n",
    "# å„ç‰¹å¾´é‡ã‚°ãƒ«ãƒ¼ãƒ—ã®å®šç¾©\n",
    "base_features = [\"age\", \"action_count\", \"avg_x\", \"avg_y\", \"minutes_played\", \"goal_count\"]\n",
    "categorical_features = [\"Comp\", \"Squad\", \"Venue\"]\n",
    "action_type_features = [col for col in train_df.columns if (col.startswith('type_')) and (col.endswith('_count'))]\n",
    "success_rate_features = [\n",
    "    col for col in train_df.columns\n",
    "    if col.endswith('_success_rate') and not col.startswith('progressive_')\n",
    "]\n",
    "zone_features = [col for col in train_df.columns if col.startswith('zone_')]\n",
    "per_minute_features = [col for col in train_df.columns if col.endswith('_per_minute')]\n",
    "ad_balance_features = ['type_offensive_actions', 'type_defensive_actions', 'type_offensive_action_ratio']\n",
    "sequencial_features = ['pass_leads_to_shot']\n",
    "progressive_feature_cols = [\n",
    "    col for col in train_df.columns\n",
    "    if col.startswith('progressive_')\n",
    "    or col in ['deep_completion_count', 'final_third_entry_count', 'penalty_area_entry_count']\n",
    "]\n",
    "xt_cols = [col for col in train_df.columns if col.startswith('xt_')]\n",
    "target_encoding_features = [f\"{col}_target_enc\" for col in [\"player_id\", \"Squad\", \"Opponent\", \"Squad_x_Opponent\"]]\n",
    "extra_bias_features = [\"Comp_target_enc\", \"Squad_comp_residual\", \"Squad_global_residual\", \"Squad_vs_opponent_gap\"]\n",
    "possession_features = [col for col in train_df.columns if col.startswith('possession_')]\n",
    "pass_network_features = [col for col in train_df.columns if col.startswith('pass_net_')]\n",
    "edxt_features = sorted(globals().get('edxt_feature_cols', []))\n",
    "team_context_features = sorted(globals().get('team_context_feature_cols', []))\n",
    "comp_interaction_features = sorted(globals().get('comp_interaction_feature_cols', []))\n",
    "\n",
    "all_features = (\n",
    "    base_features\n",
    "    + categorical_features\n",
    "    + action_type_features\n",
    "    + success_rate_features\n",
    "    + zone_features\n",
    "    + per_minute_features\n",
    "    + ad_balance_features\n",
    "    + sequencial_features\n",
    "    + progressive_feature_cols\n",
    "    + xt_cols\n",
    "    + target_encoding_features\n",
    "    + extra_bias_features\n",
    "    + possession_features\n",
    "    + pass_network_features\n",
    "    + edxt_features\n",
    "    + team_context_features\n",
    "    + comp_interaction_features\n",
    ")\n",
    "\n",
    "all_features = list(dict.fromkeys(all_features))\n",
    "\n",
    "# è¿½åŠ : é«˜åº¦ç‰¹å¾´é‡ã‚’ all_features ã«å«ã‚ã‚‹ï¼ˆå­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆã®å‰ã«å®Ÿæ–½ï¼‰\n",
    "advanced_candidates = [\n",
    "    \"second_assist_count\",\n",
    "    \"SCA_1\",\n",
    "    \"SCA_2\",\n",
    "    \"GCA_1\",\n",
    "    \"GCA_2\",\n",
    "    \"nstep_to_shot\",\n",
    "    \"nstep_xt_delta\",\n",
    "    \"pass_dist_mean\",\n",
    "    \"pass_dist_max\",\n",
    "    \"to_goal_angle_abs_mean\",\n",
    "    \"to_goal_dist_mean\",\n",
    "    \"pass_to_shot_latency_mean\",\n",
    "    \"pass_to_shot_latency_min\",\n",
    "    \"risk_creativity_sum\",\n",
    "    \"xpass_mean\",\n",
    "    \"xpass_min\",\n",
    "    \"pass_success_minus_xpass\",\n",
    "    \"xpass_deep_mean\",\n",
    "    \"xpass_box_mean\",\n",
    "    # æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰\n",
    "    \"xAG_expanding_mean\",\n",
    "    \"xAG_rolling3_mean\",\n",
    "    \"xAG_diff_prev\",\n",
    "    # ğŸ†• æ–°ç‰¹å¾´é‡ï¼ˆEXP0025ï¼‰\n",
    "    \"first_half_actions\", \"second_half_actions\", \"final_15min_actions\",\n",
    "    \"early_10min_actions\", \"time_weighted_intensity\",\n",
    "    \"defensive_zone_actions\", \"middle_zone_actions\", \"attacking_zone_actions\",\n",
    "    \"halfspace_left_actions\", \"halfspace_right_actions\", \"central_corridor_actions\",\n",
    "    \"final_third_penetrations\", \"box_entries\",\n",
    "    \"betweenness_centrality\", \"closeness_centrality\", \"degree_centrality\",\n",
    "    \"pass_receiver_diversity\", \"unique_pass_partners\",\n",
    "    \"longchain_to_shot\", \"longchain_xt_delta\",\n",
    "    \"position_variance_x\", \"position_variance_y\", \"position_range_x\",\n",
    "    \"position_range_y\", \"avg_action_distance\",\n",
    "]\n",
    "advanced_features = [c for c in advanced_candidates if c in train_df.columns]\n",
    "if advanced_features:\n",
    "    all_features = list(dict.fromkeys(all_features + advanced_features))\n",
    "    print(f\"è¿½åŠ ã•ã‚ŒãŸé«˜åº¦ç‰¹å¾´é‡ï¼ˆå­¦ç¿’å‰åæ˜ ï¼‰: {len(advanced_features)}å€‹ (ğŸ†•æ–°ç‰¹å¾´é‡25å€‹å«ã‚€)\")\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã«ã¤ã„ã¦ã¯ã€åˆ—ã®å‹ã‚’ã€Œcategoryã€ã«å¤‰æ›´ã—ã¦ãŠã\n",
    "for col in categorical_features:\n",
    "    train_df[col] = train_df[col].astype(\"category\")\n",
    "    test_df[col] = test_df[col].astype(\"category\")\n",
    "\n",
    "print(f\"  - ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡æ•°: {len(all_features)}å€‹\")\n",
    "print(f\"  - åŸºæœ¬ç‰¹å¾´é‡: {len(base_features)}å€‹\")\n",
    "print(f\"  - ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡: {len(categorical_features)}å€‹\")\n",
    "print(f\"  - ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‰¹å¾´é‡(type_*_count): {len(action_type_features)}å€‹\")\n",
    "print(f\"  - æˆåŠŸç‡ç³»: {len(success_rate_features)}å€‹\")\n",
    "print(f\"  - ã‚¾ãƒ¼ãƒ³ç³»: {len(zone_features)}å€‹\")\n",
    "print(f\"  - per_minuteç³»: {len(per_minute_features)}å€‹\")\n",
    "print(f\"  - æ”»å®ˆãƒãƒ©ãƒ³ã‚¹ç³»: {len(ad_balance_features)}å€‹\")\n",
    "print(f\"  - æ™‚ç³»åˆ—ç³»: {len(sequencial_features)}å€‹\")\n",
    "print(f\"  - ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ç³»: {len(progressive_feature_cols)}å€‹\")\n",
    "print(f\"  - xTç³»: {len(xt_cols)}å€‹\")\n",
    "print(f\"  - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç³»: {len(target_encoding_features)}å€‹\")\n",
    "print(f\"  - ãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³é€²æ”»ç³»: {len(possession_features)}å€‹\")\n",
    "print(f\"  - ãƒ‘ã‚¹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç³»: {len(pass_network_features)}å€‹\")\n",
    "print(f\"  - eÎ”xTç³»: {len(edxt_features)}å€‹\")\n",
    "print(f\"  - ãƒãƒ¼ãƒ æ–‡è„ˆç³»: {len(team_context_features)}å€‹\")\n",
    "print(f\"  - ãƒªãƒ¼ã‚°ç›¸äº’ä½œç”¨ç³»: {len(comp_interaction_features)}å€‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc2649",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUaVQAMtR2wk",
    "outputId": "a5af6982-d1c3-4d7d-f5aa-a51963962df1"
   },
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\n",
    "X_train = train_df[all_features + [\"fold\"]]\n",
    "y_train = train_df[\"xAG\"]\n",
    "X_test = test_df[all_features]\n",
    "\n",
    "print(f\"\\nãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: X_train {X_train.shape}, y_train {y_train.shape}, X_test {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db8d55",
   "metadata": {
    "id": "cCk52KvKaIf3"
   },
   "source": [
    "## ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆLightGBMï¼‰\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc463b",
   "metadata": {
    "id": "fBFkOqtLhraM",
    "lines_to_next_cell": 2
   },
   "source": [
    "ç‰¹å¾´é‡ã®æ•°ã‚‚å¢—ãˆã¦ãŠã‚Šã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯æ¢ç´¢ã—ã¦ã¿ãªã„ã¨åˆ†ã‹ã‚Šã¾ã›ã‚“ã€‚\n",
    "\n",
    "ã“ã“ã§ã¯ã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã«è‰¯ã•ãã†ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã‚‹Optunaã‚’ç”¨ã„ã¦æœ€é©åŒ–ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "Optunaã¯æ¢ç´¢ç©ºé–“ã‹ã‚‰è©¦è¡Œå›æ•°ã”ã¨ã«å€™è£œã‚’ææ¡ˆã—ã€è‰¯ã‹ã£ãŸè©¦è¡Œã®æƒ…å ±ã‚’æ´»ã‹ã—ãªãŒã‚‰æ¬¡ã®æ¢ç´¢ã«åæ˜ ã•ã›ã‚‹ãƒ™ã‚¤ã‚ºçš„æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆTPEã‚µãƒ³ãƒ—ãƒ©ãƒ¼ï¼‰ã‚’åˆ©ç”¨ã§ãã‚‹ãŸã‚ã€ç·å½“ãŸã‚Šã®GridSearchã‚ˆã‚Šã‚‚å°‘ãªã„è©¦è¡Œã§è‰¯ã„çµæœã«è¾¿ã‚Šç€ãã‚„ã™ã„ã®ãŒãƒ¡ãƒªãƒƒãƒˆã§ã™ã€‚\n",
    "ï¼ˆå‚è€ƒ: https://zenn.dev/robes/articles/d53ff6d665650f ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a8dd6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngpAJwwnaIf3",
    "outputId": "321e83a6-aee6-4b0a-88c6-199be978c2c2"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Optunaã§æœ€é©åŒ–ã—ãªã„ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "base_params = {\n",
    "    \"objective\": \"regression_l2\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"random_state\": SEED,\n",
    "    \"verbosity\": -1,\n",
    "    \"force_col_wise\": True,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"feature_fraction\": 0.8,\n",
    "}\n",
    "\n",
    "# Optunaã§æ¢ç´¢ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¦‚è¦\n",
    "optuna_search_space = {\n",
    "    \"num_leaves\": (10, 64),\n",
    "    \"learning_rate\": (0.01, 0.1),\n",
    "    \"min_child_samples\": (10, 50),\n",
    "}\n",
    "\n",
    "print(\"Optunaç”¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šå®Œäº†\")\n",
    "print(f\"æ¢ç´¢å¯¾è±¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {list(optuna_search_space.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e53304",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hkjQJvTvhMO",
    "outputId": "61949fbb-9b97-43cd-9bfc-e704053383ba"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    base_dir = Path(__file__).resolve().parent\n",
    "except NameError:  # __file__ ã¯ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè¡Œæ™‚ã«ã¯å®šç¾©ã•ã‚Œãªã„\n",
    "    base_dir = Path.cwd()\n",
    "\n",
    "log_dir = base_dir / \"logs\"\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_training_run(\n",
    "    cv_scores,\n",
    "    oof_score,\n",
    "    optuna_summary,\n",
    "    best_params,\n",
    "    log_directory: Path,\n",
    "    log_prefix: str = \"host_baseline_002\",\n",
    "):\n",
    "    \"\"\"Persist CV metrics to reusable JSON/text logs.\"\"\"\n",
    "\n",
    "    timestamp = datetime.now().astimezone().isoformat(timespec=\"seconds\")\n",
    "\n",
    "    metrics_payload = {\n",
    "        \"run_timestamp\": timestamp,\n",
    "        \"cv\": {\n",
    "            \"scores\": [float(score) for score in cv_scores],\n",
    "            \"mean\": float(np.mean(cv_scores)),\n",
    "            \"std\": float(np.std(cv_scores)),\n",
    "        },\n",
    "        \"per_fold\": {f\"fold_{idx + 1}\": float(score) for idx, score in enumerate(cv_scores)},\n",
    "        \"oof_rmse\": float(oof_score),\n",
    "        \"optuna\": optuna_summary,\n",
    "        \"best_params\": {key: (float(val) if isinstance(val, (np.floating, np.integer)) else val)\n",
    "                         for key, val in best_params.items()},\n",
    "    }\n",
    "\n",
    "    metrics_path = log_directory / f\"{log_prefix}_metrics.json\"\n",
    "    metrics_path.write_text(json.dumps(metrics_payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    log_lines = [\n",
    "        f\"[{timestamp}] {log_prefix}\",\n",
    "        f\"  CV mean: {metrics_payload['cv']['mean']:.4f}\",\n",
    "        f\"  CV std: {metrics_payload['cv']['std']:.4f}\",\n",
    "        f\"  OOF RMSE: {metrics_payload['oof_rmse']:.4f}\",\n",
    "    ]\n",
    "    for idx, score in enumerate(cv_scores, start=1):\n",
    "        log_lines.append(f\"  Fold {idx}: {score:.4f}\")\n",
    "\n",
    "    log_lines.append(\n",
    "        \"  Optuna best trial: \"\n",
    "        f\"{optuna_summary['best_trial_number']} (CV mean {optuna_summary['best_cv_value']:.6f}, \"\n",
    "        f\"fold1 RMSE {optuna_summary['fold1_val_rmse']:.6f})\"\n",
    "    )\n",
    "\n",
    "    log_path = log_directory / f\"{log_prefix}_training.log\"\n",
    "    with log_path.open(\"a\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(\"\\n\".join(log_lines) + \"\\n\")\n",
    "\n",
    "\n",
    "# Optunaã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "print(\"Optunaã«ã‚ˆã‚‹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "\n",
    "# Fold 1ã‚’æ¤œè¨¼ç”¨ã«ç¢ºä¿ï¼ˆå¾Œã§ã‚¹ã‚³ã‚¢ç¢ºèªã«åˆ©ç”¨ï¼‰\n",
    "trn_mask = train_df[\"fold\"] != 1\n",
    "val_mask = train_df[\"fold\"] == 1\n",
    "\n",
    "X_tr = train_df.loc[trn_mask, all_features].copy()\n",
    "X_val = train_df.loc[val_mask, all_features].copy()\n",
    "y_tr = y_train.loc[trn_mask].copy()\n",
    "y_val = y_train.loc[val_mask].copy()\n",
    "\n",
    "def objective(trial):\n",
    "    params = base_params.copy()\n",
    "    params.update({\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", *optuna_search_space[\"num_leaves\"]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", *optuna_search_space[\"learning_rate\"], log=True),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", *optuna_search_space[\"min_child_samples\"]),\n",
    "    })\n",
    "\n",
    "    cv_scores = []\n",
    "    for fold in range(1, 4):  # è¨ˆç®—é‡ã‚’æŠ‘ãˆã‚‹ãŸã‚Fold1~3ã§CV\n",
    "        trn_mask_cv = train_df[\"fold\"] != fold\n",
    "        val_mask_cv = train_df[\"fold\"] == fold\n",
    "\n",
    "        X_tr_cv = train_df.loc[trn_mask_cv, all_features].copy()\n",
    "        X_val_cv = train_df.loc[val_mask_cv, all_features].copy()\n",
    "        y_tr_cv = y_train.loc[trn_mask_cv].copy()\n",
    "        y_val_cv = y_train.loc[val_mask_cv].copy()\n",
    "\n",
    "        train_weights_cv = make_sample_weight(y_tr_cv)\n",
    "        val_weights_cv = make_sample_weight(y_val_cv)\n",
    "        train_data = lgb.Dataset(X_tr_cv, label=y_tr_cv, weight=train_weights_cv)\n",
    "        val_data = lgb.Dataset(X_val_cv, label=y_val_cv, weight=val_weights_cv)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[val_data],\n",
    "            feval=weighted_rmse_feval,\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)],\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_val_cv, num_iteration=model.best_iteration)\n",
    "        cv_scores.append(weighted_rmse(y_val_cv, preds))\n",
    "\n",
    "    return float(np.mean(cv_scores))\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=SEED))\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "best_params = study.best_trial.params.copy()\n",
    "best_lgbm_params = base_params.copy()\n",
    "best_lgbm_params.update(best_params)\n",
    "\n",
    "# Fold1ã§ã®ã‚¹ã‚³ã‚¢ã‚’å†ç¢ºèª\n",
    "train_weights = make_sample_weight(y_tr)\n",
    "val_weights = make_sample_weight(y_val)\n",
    "train_data = lgb.Dataset(X_tr, label=y_tr, weight=train_weights)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, weight=val_weights)\n",
    "best_model = lgb.train(\n",
    "    best_lgbm_params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    feval=weighted_rmse_feval,\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)],\n",
    ")\n",
    "\n",
    "val_pred = best_model.predict(X_val, num_iteration=best_model.best_iteration)\n",
    "val_score = weighted_rmse(y_val, val_pred)\n",
    "\n",
    "print(\"=== Optunaãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœ ===\")\n",
    "print(f\"æœ€è‰¯Trialç•ªå·: {study.best_trial.number}\")\n",
    "print(f\"å¹³å‡CV RMSE: {study.best_value:.6f}\")\n",
    "print(f\"Fold1 Validation RMSE: {val_score:.6f}\")\n",
    "print(\"æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f10f28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1o2kC3wsi0n",
    "lines_to_next_cell": 2,
    "outputId": "2e156a42-4637-433a-f6db-76205a1e3b21"
   },
   "outputs": [],
   "source": [
    "# æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®5-Fold Cross Validation\n",
    "print(\"æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®5-Fold Cross Validationã‚’é–‹å§‹...\")\n",
    "\n",
    "# å˜èª¿æ€§åˆ¶ç´„ã®è¨­å®š\n",
    "# xAGã¨å˜èª¿å¢—åŠ é–¢ä¿‚ã«ã‚ã‚‹ç‰¹å¾´é‡ã‚’é¸å®š\n",
    "monotone_increase_features = [\n",
    "    # ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ç³»ï¼ˆæ”»æ’ƒçš„ãªå‰é€²ãƒ—ãƒ¬ãƒ¼ â†’ xAGå¢—åŠ ï¼‰\n",
    "    'progressive_pass_count',\n",
    "    'progressive_pass_success',\n",
    "    'progressive_pass_distance_total',\n",
    "    'progressive_pass_distance_mean',\n",
    "    'progressive_carry_count',\n",
    "    'progressive_carry_success',\n",
    "    'progressive_carry_distance_total',\n",
    "    'progressive_carry_distance_mean',\n",
    "    'deep_completion_count',  # ãƒ‡ã‚£ãƒ¼ãƒ—ã‚¾ãƒ¼ãƒ³åˆ°é”æ•°\n",
    "    'final_third_entry_count',  # ãƒ•ã‚¡ã‚¤ãƒŠãƒ«ã‚µãƒ¼ãƒ‰é€²å…¥æ•°\n",
    "    'penalty_area_entry_count',  # ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚¨ãƒªã‚¢é€²å…¥æ•°\n",
    "\n",
    "    # ã‚·ãƒ¥ãƒ¼ãƒˆãƒ»ã‚´ãƒ¼ãƒ«ç³»ï¼ˆå‰µé€ æ€§ã®æŒ‡æ¨™ï¼‰\n",
    "    'goal_count',  # ã‚´ãƒ¼ãƒ«æ•°\n",
    "    'pass_leads_to_shot',  # ãƒ‘ã‚¹â†’ã‚·ãƒ§ãƒƒãƒˆã®é€£é–\n",
    "\n",
    "    # æ”»æ’ƒçš„ã‚¾ãƒ¼ãƒ³æ´»å‹•ï¼ˆå‰ç·šã§ã®ãƒ—ãƒ¬ãƒ¼ â†’ xAGå¢—åŠ ï¼‰\n",
    "    'zone_attacking_actions',  # æ”»æ’ƒã‚¾ãƒ¼ãƒ³ã§ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°\n",
    "    'zone_attacking_actions_ratio',  # æ”»æ’ƒã‚¾ãƒ¼ãƒ³æ¯”ç‡\n",
    "\n",
    "    # æ”»æ’ƒçš„ãƒãƒ©ãƒ³ã‚¹\n",
    "    'type_offensive_actions',  # æ”»æ’ƒã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°\n",
    "    'type_offensive_action_ratio',  # æ”»æ’ƒã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¯”ç‡\n",
    "]\n",
    "\n",
    "missing_monotone_features = [feat for feat in monotone_increase_features if feat not in all_features]\n",
    "if missing_monotone_features:\n",
    "    print(\"å˜èª¿æ€§åˆ¶ç´„å¯¾è±¡ã¨ã—ã¦æŒ‡å®šã—ãŸã‚‚ã®ã®ã€ç‰¹å¾´é‡ä¸€è¦§ã«å­˜åœ¨ã—ãªã„åˆ—ãŒã‚ã‚Šã¾ã™:\")\n",
    "    for feat in missing_monotone_features:\n",
    "        print(f\"  - {feat}\")\n",
    "\n",
    "applied_monotone_features = [feat for feat in monotone_increase_features if feat in all_features]\n",
    "\n",
    "# all_featureså†…ã§ã®å„ç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã—ã€å˜èª¿æ€§ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰\n",
    "monotone_constraints = [0] * len(all_features)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯åˆ¶ç´„ãªã—(0)\n",
    "for feat in applied_monotone_features:\n",
    "    idx = all_features.index(feat)\n",
    "    monotone_constraints[idx] = 1  # å˜èª¿å¢—åŠ åˆ¶ç´„\n",
    "\n",
    "print(f\"\\nå˜èª¿æ€§åˆ¶ç´„ã‚’é©ç”¨: {len(applied_monotone_features)}å€‹ã®ç‰¹å¾´é‡\")\n",
    "print(\"å˜èª¿å¢—åŠ åˆ¶ç´„ã‚’é©ç”¨ã—ãŸç‰¹å¾´é‡:\")\n",
    "for feat in applied_monotone_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "# LightGBMå­¦ç¿’ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šï¼ˆOptunaã§æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰\n",
    "lgbm_params = {\n",
    "    \"objective\": \"regression_l2\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"random_state\": SEED,\n",
    "    \"verbosity\": -1,\n",
    "    \"force_col_wise\": True,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"monotone_constraints\": monotone_constraints,  # å˜èª¿æ€§åˆ¶ç´„ã‚’è¿½åŠ \n",
    "    \"monotone_constraints_method\": \"advanced\",  # advanced methodã‚’ä½¿ç”¨\n",
    "}\n",
    "\n",
    "# Optunaã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸\n",
    "lgbm_params.update(best_params)\n",
    "\n",
    "print(f\"\\nä½¿ç”¨ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {lgbm_params}\")\n",
    "\n",
    "# 5-Foldã§ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆæœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰\n",
    "oof_preds = np.zeros(len(X_train))\n",
    "cv_scores = []\n",
    "models = []\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "# Training the models on the entire training data\n",
    "for fold in range(5):\n",
    "    print(f\"=== Fold {fold + 1} ===\")\n",
    "\n",
    "    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "    trn_mask = train_df[\"fold\"] != fold+1\n",
    "    val_mask = train_df[\"fold\"] == fold+1\n",
    "\n",
    "    X_tr = train_df.loc[trn_mask, all_features].copy()\n",
    "    X_val = train_df.loc[val_mask, all_features].copy()\n",
    "    y_tr = y_train.loc[trn_mask].copy()\n",
    "    y_val = y_train.loc[val_mask].copy()\n",
    "\n",
    "    # LightGBMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
    "    train_weights = make_sample_weight(y_tr)\n",
    "    val_weights = make_sample_weight(y_val)\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr, weight=train_weights)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, weight=val_weights, reference=train_data)\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆæœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰\n",
    "    model = lgb.train(\n",
    "        lgbm_params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=[\"train\", \"val\"],\n",
    "        feval=weighted_rmse_feval,\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "    )\n",
    "\n",
    "    # validationãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬ã€ã‚¹ã‚³ã‚¢ç®—å‡º\n",
    "    y_pred_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    oof_preds[val_mask] = y_pred_val\n",
    "    score = weighted_rmse(y_val, y_pred_val)\n",
    "    cv_scores.append(score)\n",
    "    models.append(model)  # ã“ã®foldã®ãƒ¢ãƒ‡ãƒ«ã‚’modelsã«æ ¼ç´\n",
    "\n",
    "    print(f\"Fold {fold + 1} RMSE: {score:.4f}\")\n",
    "\n",
    "    # ç‰¹å¾´é‡é‡è¦åº¦ç®—å‡º\n",
    "    fold_importance = pd.DataFrame({\n",
    "        \"feature\": all_features,\n",
    "        \"importance\": model.feature_importance(importance_type=\"gain\"),\n",
    "        \"fold\": fold + 1\n",
    "    })\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "cv_mean = float(np.mean(cv_scores))\n",
    "cv_std = float(np.std(cv_scores))\n",
    "\n",
    "print(\"=== Cross Validation Results (Optimized Parameters) ===\")\n",
    "print(f\"CV RMSE: {cv_mean:.4f} (+/- {cv_std * 2:.4f})\")\n",
    "for i, score in enumerate(cv_scores):\n",
    "    print(f\"Fold {i + 1}: {score:.4f}\")\n",
    "\n",
    "# OOFäºˆæ¸¬ã®ã‚¹ã‚³ã‚¢ç®—å‡º\n",
    "oof_score = weighted_rmse(y_train, oof_preds)\n",
    "print(f\"OOF RMSE: {oof_score:.4f}\")\n",
    "\n",
    "optuna_summary = {\n",
    "    \"best_trial_number\": int(study.best_trial.number),\n",
    "    \"best_cv_value\": float(study.best_value),\n",
    "    \"fold1_val_rmse\": float(val_score),\n",
    "}\n",
    "\n",
    "save_training_run(\n",
    "    cv_scores=cv_scores,\n",
    "    oof_score=oof_score,\n",
    "    optuna_summary=optuna_summary,\n",
    "    best_params=best_params,\n",
    "    log_directory=log_dir,\n",
    ")\n",
    "\n",
    "print(f\"ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {log_dir / 'host_baseline_002_metrics.json'}\")\n",
    "print(f\"ãƒ­ã‚°ã‚’è¿½è¨˜ã—ã¾ã—ãŸ: {log_dir / 'host_baseline_002_training.log'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d339c",
   "metadata": {},
   "source": [
    "## CatBoost ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
    "\n",
    "CatBoostã‚’ä½¿ç”¨ã—ã¦ã€LGBMã¨ç›¸è£œçš„ãªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "\n",
    "**CatBoostã®ç‰¹å¾´:**\n",
    "- **Ordered Target Statistics**: ãƒªãƒ¼ã‚¯ã‚’å›é¿ã—ãªãŒã‚‰ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’åŠ¹æœçš„ã«å‡¦ç†\n",
    "- **é«˜æ¬¡äº¤äº’ä½œç”¨**: ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°é–“ã®è¤‡é›‘ãªäº¤äº’ä½œç”¨ã‚’è‡ªå‹•çš„ã«å­¦ç¿’\n",
    "- **å¯¾ç§°æœ¨æ§‹é€ **: ã‚ˆã‚Šå®‰å®šã—ãŸäºˆæ¸¬ã‚’å®Ÿç¾\n",
    "\n",
    "**å®Ÿè£…æ–¹é‡:**\n",
    "- ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š\n",
    "- LGBMã¨ç•°ãªã‚‹seed/åˆ—ã‚µãƒ–ã‚»ãƒƒãƒˆã§å¤šæ§˜æ€§ã‚’ç¢ºä¿\n",
    "- å˜èª¿æ€§åˆ¶ç´„ã¯å¿…è¦æœ€å°é™ã«æŠ‘åˆ¶\n",
    "- é‡ã¿ä»˜ãRMSEã«å¯¾å¿œã—ãŸã‚µãƒ³ãƒ—ãƒ«é‡ã¿ã‚’ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ebff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostç”¨ã®ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã‚’æ˜ç¤ºçš„ã«å®šç¾©\n",
    "catboost_categorical_features = ['Comp', 'Squad', 'Venue']\n",
    "\n",
    "# CatBoostã§ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ï¼ˆLGBMã¨åŒã˜ç‰¹å¾´é‡ã‚’ä½¿ç”¨ï¼‰\n",
    "catboost_features = all_features.copy()\n",
    "\n",
    "print(f\"CatBoostã§ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡æ•°: {len(catboost_features)}å€‹\")\n",
    "print(f\"ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡: {catboost_categorical_features}\")\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
    "cat_features_idx = [catboost_features.index(col) for col in catboost_categorical_features if col in catboost_features]\n",
    "print(f\"ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {cat_features_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostç”¨ã®Optunaãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–\n",
    "print(\"CatBoost ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’é–‹å§‹...\")\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    \"\"\"\n",
    "    CatBoostç”¨ã®Optunaç›®çš„é–¢æ•°\n",
    "    LGBMã¨ç›¸è£œæ€§ã‚’æŒãŸã›ã‚‹ãŸã‚ã€ç•°ãªã‚‹æ¢ç´¢ç©ºé–“ã‚’è¨­å®š\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'iterations': 1000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.1, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': 'RMSE',\n",
    "        'random_seed': SEED + 100,  # LGBMã¨ç•°ãªã‚‹seedã§å¤šæ§˜æ€§ç¢ºä¿\n",
    "        'verbose': False,\n",
    "        'early_stopping_rounds': 100,\n",
    "        'cat_features': cat_features_idx,\n",
    "    }\n",
    "    \n",
    "    # Fold 1ã®ã¿ã§è©•ä¾¡ï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚ï¼‰\n",
    "    fold = 0\n",
    "    trn_mask = train_df['fold'] != fold + 1\n",
    "    val_mask = train_df['fold'] == fold + 1\n",
    "    \n",
    "    X_tr = train_df.loc[trn_mask, catboost_features].copy()\n",
    "    X_val = train_df.loc[val_mask, catboost_features].copy()\n",
    "    y_tr = y_train.loc[trn_mask].copy()\n",
    "    y_val = y_train.loc[val_mask].copy()\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ã‚’è¨ˆç®—\n",
    "    train_weights = make_sample_weight(y_tr)\n",
    "    \n",
    "    # CatBoost Poolä½œæˆ\n",
    "    train_pool = cb.Pool(\n",
    "        data=X_tr,\n",
    "        label=y_tr,\n",
    "        weight=train_weights,\n",
    "        cat_features=cat_features_idx\n",
    "    )\n",
    "    val_pool = cb.Pool(\n",
    "        data=X_val,\n",
    "        label=y_val,\n",
    "        cat_features=cat_features_idx\n",
    "    )\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
    "    model = cb.CatBoostRegressor(**params)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        verbose=False,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    # äºˆæ¸¬ã¨ã‚¹ã‚³ã‚¢è¨ˆç®—\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    val_score = weighted_rmse(y_val, y_pred_val)\n",
    "    \n",
    "    return val_score\n",
    "\n",
    "# Optunaæœ€é©åŒ–å®Ÿè¡Œ\n",
    "catboost_study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=SEED)\n",
    ")\n",
    "\n",
    "catboost_study.optimize(\n",
    "    objective_catboost,\n",
    "    n_trials=30,  # LGBMã¨åŒæ§˜ã«30è©¦è¡Œ\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "catboost_best_params = catboost_study.best_params\n",
    "print(f\"\\nCatBoostæœ€é©åŒ–å®Œäº†\")\n",
    "print(f\"Best trial: {catboost_study.best_trial.number}\")\n",
    "print(f\"Best validation RMSE: {catboost_study.best_value:.4f}\")\n",
    "print(f\"Best parameters: {catboost_best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostç”¨ã®å˜èª¿æ€§åˆ¶ç´„è¨­å®š\n",
    "# LGBMã‚ˆã‚Šã‚‚åˆ¶ç´„ã‚’ç·©ã‚ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®å¤šæ§˜æ€§ã‚’ç¢ºä¿\n",
    "print(\"CatBoostå˜èª¿æ€§åˆ¶ç´„ã‚’è¨­å®šä¸­...\")\n",
    "\n",
    "# æœ€ã‚‚é‡è¦ãªç‰¹å¾´é‡ã®ã¿ã«å˜èª¿æ€§åˆ¶ç´„ã‚’é©ç”¨ï¼ˆLGBMã‚ˆã‚Šå°‘ãªã‚ï¼‰\n",
    "catboost_monotone_increase_features = [\n",
    "    'goal_count',  # ã‚´ãƒ¼ãƒ«æ•°\n",
    "    'pass_leads_to_shot',  # ãƒ‘ã‚¹â†’ã‚·ãƒ§ãƒƒãƒˆ\n",
    "    'progressive_pass_count',  # ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ãƒ‘ã‚¹æ•°\n",
    "    'deep_completion_count',  # ãƒ‡ã‚£ãƒ¼ãƒ—ã‚¾ãƒ¼ãƒ³åˆ°é”\n",
    "    'penalty_area_entry_count',  # ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚¨ãƒªã‚¢é€²å…¥\n",
    "    'zone_attacking_actions',  # æ”»æ’ƒã‚¾ãƒ¼ãƒ³ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n",
    "]\n",
    "\n",
    "# ç‰¹å¾´é‡ãŒå­˜åœ¨ã™ã‚‹ã‚‚ã®ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "applied_catboost_monotone_features = [\n",
    "    feat for feat in catboost_monotone_increase_features \n",
    "    if feat in catboost_features\n",
    "]\n",
    "\n",
    "# CatBoostã®å˜èª¿æ€§åˆ¶ç´„å½¢å¼: æ–‡å­—åˆ—ã®ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š\n",
    "# å½¢å¼: \"feature_idx1,feature_idx2,...\" ã§æ–¹å‘ã‚’æŒ‡å®š\n",
    "# ã¾ãŸã¯å„ç‰¹å¾´é‡ã«å¯¾ã—ã¦ (idx, direction) ã®ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆ\n",
    "# ã“ã“ã§ã¯ã€ç‰¹å¾´é‡åãƒ™ãƒ¼ã‚¹ã§è¾æ›¸å½¢å¼ã‚’ä½¿ç”¨\n",
    "\n",
    "# CatBoostã®å˜èª¿æ€§åˆ¶ç´„: å…¨ç‰¹å¾´é‡ã«å¯¾ã™ã‚‹åˆ¶ç´„ãƒªã‚¹ãƒˆï¼ˆ0=åˆ¶ç´„ãªã—, 1=å¢—åŠ , -1=æ¸›å°‘ï¼‰\n",
    "catboost_monotone_constraints = [0] * len(catboost_features)\n",
    "\n",
    "for feat in applied_catboost_monotone_features:\n",
    "    if feat in catboost_features:\n",
    "        idx = catboost_features.index(feat)\n",
    "        catboost_monotone_constraints[idx] = 1  # å˜èª¿å¢—åŠ åˆ¶ç´„\n",
    "\n",
    "print(f\"å˜èª¿æ€§åˆ¶ç´„ã‚’é©ç”¨: {len(applied_catboost_monotone_features)}å€‹ã®ç‰¹å¾´é‡\")\n",
    "print(f\"  (LGBMã®{len(applied_monotone_features)}å€‹ã‹ã‚‰å‰Šæ¸›ã—ã€ãƒ¢ãƒ‡ãƒ«ã®å¤šæ§˜æ€§ã‚’ç¢ºä¿)\")\n",
    "for feat in applied_catboost_monotone_features:\n",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe199d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostã§ã®5-Fold Cross Validation\n",
    "print(\"\\nCatBoostã§ã®5-Fold Cross Validationã‚’é–‹å§‹...\")\n",
    "\n",
    "# æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ã«è¨­å®š\n",
    "catboost_params = {\n",
    "    'iterations': 1000,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': SEED + 100,  # LGBMã¨ç•°ãªã‚‹seed\n",
    "    'verbose': False,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'cat_features': cat_features_idx,\n",
    "    'monotone_constraints': catboost_monotone_constraints,  # å˜èª¿æ€§åˆ¶ç´„\n",
    "}\n",
    "\n",
    "# Optunaã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸\n",
    "catboost_params.update(catboost_best_params)\n",
    "\n",
    "print(f\"ä½¿ç”¨ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {catboost_params}\")\n",
    "\n",
    "# CVçµæœã‚’æ ¼ç´\n",
    "catboost_oof_preds = np.zeros(len(X_train))\n",
    "catboost_cv_scores = []\n",
    "catboost_models = []\n",
    "catboost_feature_importance = pd.DataFrame()\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"\\n=== CatBoost Fold {fold + 1} ===\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "    trn_mask = train_df['fold'] != fold + 1\n",
    "    val_mask = train_df['fold'] == fold + 1\n",
    "    \n",
    "    X_tr = train_df.loc[trn_mask, catboost_features].copy()\n",
    "    X_val = train_df.loc[val_mask, catboost_features].copy()\n",
    "    y_tr = y_train.loc[trn_mask].copy()\n",
    "    y_val = y_train.loc[val_mask].copy()\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ã‚’è¨ˆç®—\n",
    "    train_weights = make_sample_weight(y_tr)\n",
    "    \n",
    "    # CatBoost Poolä½œæˆ\n",
    "    train_pool = cb.Pool(\n",
    "        data=X_tr,\n",
    "        label=y_tr,\n",
    "        weight=train_weights,  # é‡ã¿ä»˜ãRMSEå¯¾å¿œ\n",
    "        cat_features=cat_features_idx\n",
    "    )\n",
    "    val_pool = cb.Pool(\n",
    "        data=X_val,\n",
    "        label=y_val,\n",
    "        cat_features=cat_features_idx\n",
    "    )\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
    "    model = cb.CatBoostRegressor(**catboost_params)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        verbose=100,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    # äºˆæ¸¬ã¨ã‚¹ã‚³ã‚¢è¨ˆç®—\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    catboost_oof_preds[val_mask] = y_pred_val\n",
    "    score = weighted_rmse(y_val, y_pred_val)\n",
    "    catboost_cv_scores.append(score)\n",
    "    catboost_models.append(model)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Weighted RMSE: {score:.4f}\")\n",
    "    \n",
    "    # ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—\n",
    "    fold_importance = pd.DataFrame({\n",
    "        'feature': catboost_features,\n",
    "        'importance': model.get_feature_importance(),\n",
    "        'fold': fold + 1\n",
    "    })\n",
    "    catboost_feature_importance = pd.concat(\n",
    "        [catboost_feature_importance, fold_importance], \n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "# CVçµæœã®ã‚µãƒãƒªãƒ¼\n",
    "catboost_cv_mean = float(np.mean(catboost_cv_scores))\n",
    "catboost_cv_std = float(np.std(catboost_cv_scores))\n",
    "\n",
    "print(\"\\n=== CatBoost Cross Validation Results ===\")\n",
    "print(f\"CV Weighted RMSE: {catboost_cv_mean:.4f} (+/- {catboost_cv_std * 2:.4f})\")\n",
    "for i, score in enumerate(catboost_cv_scores):\n",
    "    print(f\"Fold {i + 1}: {score:.4f}\")\n",
    "\n",
    "# OOFäºˆæ¸¬ã®ã‚¹ã‚³ã‚¢\n",
    "catboost_oof_score = weighted_rmse(y_train, catboost_oof_preds)\n",
    "print(f\"\\nCatBoost OOF Weighted RMSE: {catboost_oof_score:.4f}\")\n",
    "\n",
    "# LGBMã¨ã®æ¯”è¼ƒ\n",
    "print(f\"\\n--- ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ ---\")\n",
    "print(f\"LightGBM OOF RMSE: {oof_score:.4f}\")\n",
    "print(f\"CatBoost OOF RMSE: {catboost_oof_score:.4f}\")\n",
    "print(f\"å·®åˆ†: {catboost_oof_score - oof_score:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225234a7",
   "metadata": {},
   "source": [
    "## ãƒ¢ãƒ‡ãƒ«ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆLightGBM + CatBoostï¼‰\n",
    "\n",
    "LightGBMã¨CatBoostã®äºˆæ¸¬ã‚’åŠ é‡å¹³å‡ã§ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ã¾ã™ã€‚\n",
    "\n",
    "**ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥:**\n",
    "- OOFäºˆæ¸¬ã§ãƒ–ãƒ¬ãƒ³ãƒ‰æ¯”ç‡ã‚’æœ€é©åŒ–\n",
    "- ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã§æœ€é©ãªé‡ã¿ã‚’æ¢ç´¢\n",
    "- LGBMã¨CatBoostã®ç›¸è£œæ€§ã‚’æ´»ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOFäºˆæ¸¬ã‚’ä½¿ã£ã¦ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æ¯”ç‡ã‚’æœ€é©åŒ–\n",
    "print(\"ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æ¯”ç‡ã‚’æœ€é©åŒ–ä¸­...\")\n",
    "\n",
    "best_blend_weight = 0.5\n",
    "best_blend_score = float('inf')\n",
    "\n",
    "# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã§æœ€é©ãªé‡ã¿ã‚’æ¢ç´¢\n",
    "for lgb_weight in np.arange(0.0, 1.01, 0.05):\n",
    "    catboost_weight = 1.0 - lgb_weight\n",
    "    \n",
    "    # ãƒ–ãƒ¬ãƒ³ãƒ‰äºˆæ¸¬\n",
    "    blended_oof = lgb_weight * oof_preds + catboost_weight * catboost_oof_preds\n",
    "    \n",
    "    # ã‚¹ã‚³ã‚¢è¨ˆç®—\n",
    "    blend_score = weighted_rmse(y_train, blended_oof)\n",
    "    \n",
    "    if blend_score < best_blend_score:\n",
    "        best_blend_score = blend_score\n",
    "        best_blend_weight = lgb_weight\n",
    "\n",
    "best_catboost_weight = 1.0 - best_blend_weight\n",
    "\n",
    "print(f\"\\n=== æœ€é©ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æ¯”ç‡ ===\")\n",
    "print(f\"LightGBMé‡ã¿: {best_blend_weight:.2f}\")\n",
    "print(f\"CatBoosté‡ã¿: {best_catboost_weight:.2f}\")\n",
    "print(f\"\\n--- ã‚¹ã‚³ã‚¢æ¯”è¼ƒ ---\")\n",
    "print(f\"LightGBM OOF: {oof_score:.4f}\")\n",
    "print(f\"CatBoost OOF: {catboost_oof_score:.4f}\")\n",
    "print(f\"ãƒ–ãƒ¬ãƒ³ãƒ‰OOF: {best_blend_score:.4f}\")\n",
    "print(f\"\\nLGBMã‹ã‚‰ã®æ”¹å–„: {best_blend_score - oof_score:+.4f}\")\n",
    "print(f\"CatBoostã‹ã‚‰ã®æ”¹å–„: {best_blend_score - catboost_oof_score:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68552b49",
   "metadata": {},
   "source": [
    "## ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ¨è«–ï¼ˆãƒ–ãƒ¬ãƒ³ãƒ‰ãƒ¢ãƒ‡ãƒ«ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f3511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ¨è«–\n",
    "print(\"CatBoostã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ¨è«–ã‚’å®Ÿè¡Œä¸­...\")\n",
    "\n",
    "catboost_test_preds = np.zeros(len(X_test))\n",
    "\n",
    "for fold, model in enumerate(catboost_models):\n",
    "    fold_preds = model.predict(test_df[catboost_features])\n",
    "    catboost_test_preds += fold_preds / 5\n",
    "    print(f\"Fold {fold + 1}: äºˆæ¸¬å®Œäº†\")\n",
    "\n",
    "print(f\"\\nCatBoostäºˆæ¸¬çµ±è¨ˆ:\")\n",
    "print(f\"  Mean: {catboost_test_preds.mean():.4f}\")\n",
    "print(f\"  Std: {catboost_test_preds.std():.4f}\")\n",
    "print(f\"  Min: {catboost_test_preds.min():.4f}\")\n",
    "print(f\"  Max: {catboost_test_preds.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ¨è«–ï¼ˆæ—¢å­˜ã®modelsã‚’ä½¿ç”¨ï¼‰\n",
    "print(\"LightGBMã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ¨è«–ã‚’å®Ÿè¡Œä¸­...\")\n",
    "\n",
    "lgbm_test_preds = np.zeros(len(X_test))\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    fold_preds = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    lgbm_test_preds += fold_preds / 5\n",
    "    print(f\"Fold {fold + 1}: äºˆæ¸¬å®Œäº†\")\n",
    "\n",
    "print(f\"\\nLightGBMäºˆæ¸¬çµ±è¨ˆ:\")\n",
    "print(f\"  Mean: {lgbm_test_preds.mean():.4f}\")\n",
    "print(f\"  Std: {lgbm_test_preds.std():.4f}\")\n",
    "print(f\"  Min: {lgbm_test_preds.min():.4f}\")\n",
    "print(f\"  Max: {lgbm_test_preds.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€é©ãªé‡ã¿ã§ãƒ–ãƒ¬ãƒ³ãƒ‰äºˆæ¸¬ã‚’ä½œæˆ\n",
    "print(\"\\nãƒ–ãƒ¬ãƒ³ãƒ‰äºˆæ¸¬ã‚’ä½œæˆä¸­...\")\n",
    "\n",
    "blended_test_preds = (\n",
    "    best_blend_weight * lgbm_test_preds + \n",
    "    best_catboost_weight * catboost_test_preds\n",
    ")\n",
    "\n",
    "print(f\"\\nãƒ–ãƒ¬ãƒ³ãƒ‰äºˆæ¸¬çµ±è¨ˆ:\")\n",
    "print(f\"  Mean: {blended_test_preds.mean():.4f}\")\n",
    "print(f\"  Std: {blended_test_preds.std():.4f}\")\n",
    "print(f\"  Min: {blended_test_preds.min():.4f}\")\n",
    "print(f\"  Max: {blended_test_preds.max():.4f}\")\n",
    "\n",
    "# äºˆæ¸¬å€¤ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].hist(lgbm_test_preds, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].set_title('LightGBMäºˆæ¸¬åˆ†å¸ƒ', fontsize=14)\n",
    "axes[0].set_xlabel('xAGäºˆæ¸¬å€¤')\n",
    "axes[0].set_ylabel('é »åº¦')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].hist(catboost_test_preds, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1].set_title('CatBoostäºˆæ¸¬åˆ†å¸ƒ', fontsize=14)\n",
    "axes[1].set_xlabel('xAGäºˆæ¸¬å€¤')\n",
    "axes[1].set_ylabel('é »åº¦')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "axes[2].hist(blended_test_preds, bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[2].set_title('ãƒ–ãƒ¬ãƒ³ãƒ‰äºˆæ¸¬åˆ†å¸ƒ', fontsize=14)\n",
    "axes[2].set_xlabel('xAGäºˆæ¸¬å€¤')\n",
    "axes[2].set_ylabel('é »åº¦')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«é–“ã®ç›¸é–¢ã‚’ç¢ºèª\n",
    "correlation = np.corrcoef(lgbm_test_preds, catboost_test_preds)[0, 1]\n",
    "print(f\"\\nLGBMã¨CatBoostã®äºˆæ¸¬ç›¸é–¢: {correlation:.4f}\")\n",
    "print(f\"(ç›¸é–¢ãŒä½ã„ã»ã©ã€ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«ã‚ˆã‚‹æ”¹å–„åŠ¹æœãŒå¤§ãã„)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e55003",
   "metadata": {
    "id": "Sap_9i9DaIf3"
   },
   "source": [
    "## ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ¨è«–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a3a3b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Xs1lGqfaIf4",
    "outputId": "47eceb84-34b8-480a-dfd5-85eebb203bc7"
   },
   "outputs": [],
   "source": [
    "# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ï¼ˆ5ãƒ¢ãƒ‡ãƒ«ã®å¹³å‡ï¼‰ on Test Data\n",
    "test_preds = np.zeros(len(X_test))\n",
    "\n",
    "for model in models:\n",
    "    pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    test_preds += pred\n",
    "\n",
    "test_preds /= len(models)\n",
    "\n",
    "\n",
    "print(f\"\\n=== Test Set Predictions ===\")\n",
    "print(f\"äºˆæ¸¬xAGç¯„å›²: {test_preds.min():.3f} ã€œ {test_preds.max():.3f}\")\n",
    "\n",
    "# test_dfã«äºˆæ¸¬çµæœã‚’è¿½åŠ \n",
    "test_df['predicted_xAG'] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a2d48",
   "metadata": {
    "id": "yL_4w1qWaIf4"
   },
   "source": [
    "## äºˆæ¸¬çµæœã®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7b95c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 998
    },
    "id": "KLKnE3KajdZp",
    "outputId": "d9b9cad3-dedc-458d-aad3-e23986d7e5a3"
   },
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡é‡è¦åº¦ã®å¹³å‡è¨ˆç®—\n",
    "feature_importance_mean = feature_importance.groupby('feature')['importance'].agg(['mean', 'std']).reset_index()\n",
    "feature_importance_mean = feature_importance_mean.sort_values('mean', ascending=False)\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance_mean.head(15), x='mean', y='feature')\n",
    "plt.title('Top 15 Feature Importance (Weighted RMSE Baseline xAG Model)')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ç‰¹å¾´é‡é‡è¦åº¦ Top 10:\")\n",
    "print(feature_importance_mean.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517699b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "kGIeBEIPaIf4",
    "outputId": "92e7fb77-a19e-45f3-c778-c010f56a2adf"
   },
   "outputs": [],
   "source": [
    "# train, testäºˆæ¸¬å€¤ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(oof_preds, stat='density', kde=True, alpha=0.2, label='OOFäºˆæ¸¬', linewidth=0)\n",
    "sns.histplot(test_preds, stat='density', kde=True, alpha=0.2, label='Testäºˆæ¸¬', linewidth=0)\n",
    "\n",
    "# trainæ­£è§£å€¤ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–\n",
    "vc = y_train.value_counts().sort_index()\n",
    "heights = vc / vc.sum() / 0.1 # æ£’ã‚°ãƒ©ãƒ•ã®é«˜ã•ã‚’density ã«åˆã‚ã›ã‚‹\n",
    "plt.bar(vc.index, heights, width=0.03, alpha=0.6, label='OOFæ­£è§£', align='center')\n",
    "\n",
    "plt.xlabel('xAG')\n",
    "plt.ylabel('å¯†åº¦')\n",
    "plt.xlim(0, 1)\n",
    "plt.title('xAGäºˆæ¸¬å€¤ã®åˆ†å¸ƒï¼ˆOOFäºˆæ¸¬ vs Testäºˆæ¸¬ vs OOFæ­£è§£ï¼‰')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c4b9d8",
   "metadata": {
    "id": "61-ufcOruCGb"
   },
   "source": [
    "æ­£è§£ãŒ0.0ã®ãƒ‡ãƒ¼ã‚¿ã®é‡ã¿ä»˜ã‘ãŒå°ã•ã„ãŸã‚ã€å…¨ä½“çš„ã«æ­£ã®å€¤ã‚’äºˆæƒ³ã™ã‚‹å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add31d1",
   "metadata": {
    "id": "u4I2O1ntaIf4"
   },
   "source": [
    "## æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf7400",
   "metadata": {
    "id": "cbhq5ARAaIf4",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ãƒ–ãƒ¬ãƒ³ãƒ‰ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã§æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ\n",
    "submission_df['xAG'] = blended_test_preds\n",
    "\n",
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n",
    "submission_path = log_dir / 'submission_blend_lgbm_catboost.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {submission_path}\")\n",
    "print(f\"\\næå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®çµ±è¨ˆ:\")\n",
    "print(submission_df['xAG'].describe())\n",
    "\n",
    "# å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜\n",
    "submission_lgbm = submission_df.copy()\n",
    "submission_lgbm['xAG'] = lgbm_test_preds\n",
    "submission_lgbm.to_csv(log_dir / 'submission_lgbm_only.csv', index=False)\n",
    "print(f\"\\nLightGBMå˜ç‹¬ã®æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜: {log_dir / 'submission_lgbm_only.csv'}\")\n",
    "\n",
    "submission_catboost = submission_df.copy()\n",
    "submission_catboost['xAG'] = catboost_test_preds\n",
    "submission_catboost.to_csv(log_dir / 'submission_catboost_only.csv', index=False)\n",
    "print(f\"CatBoostå˜ç‹¬ã®æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜: {log_dir / 'submission_catboost_only.csv'}\")\n",
    "\n",
    "# ã‚µãƒãƒªãƒ¼è¡¨ç¤º\n",
    "print(\"\\n=== æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼ ===\")\n",
    "print(f\"LightGBM OOF RMSE: {oof_score:.4f}\")\n",
    "print(f\"CatBoost OOF RMSE: {catboost_oof_score:.4f}\")\n",
    "print(f\"ãƒ–ãƒ¬ãƒ³ãƒ‰OOF RMSE: {best_blend_score:.4f}\")\n",
    "print(f\"\\nãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æ¯”ç‡:\")\n",
    "print(f\"  LightGBM: {best_blend_weight:.2f}\")\n",
    "print(f\"  CatBoost: {best_catboost_weight:.2f}\")\n",
    "print(f\"\\næå‡ºãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "print(f\"  1. submission_blend_lgbm_catboost.csv (æ¨å¥¨)\")\n",
    "print(f\"  2. submission_lgbm_only.csv\")\n",
    "print(f\"  3. submission_catboost_only.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "all",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "all,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09a43976bef243599b2e9b64cffb91b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3e34a9bb0d24577acc83d7ae4b2486d",
       "IPY_MODEL_dcffd72448ea44bf9ec8aec5b31762f6",
       "IPY_MODEL_3a83f4956d7d41938ef54f146a5cc541"
      ],
      "layout": "IPY_MODEL_69216dc0f0f4422e8166c4a8f8abe666"
     }
    },
    "09a7b0f32ef942afb2963f355e80a8bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a83f4956d7d41938ef54f146a5cc541": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b6ef11c003d4a79b3924bc396c0ff56",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_78773c5f4ebc47fea4077d687ab0ea0c",
      "value": "â€‡40041/40041â€‡[03:10&lt;00:00,â€‡234.12it/s]"
     }
    },
    "5b6ef11c003d4a79b3924bc396c0ff56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e50717143ae4771b600c2a5f73488e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69216dc0f0f4422e8166c4a8f8abe666": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78773c5f4ebc47fea4077d687ab0ea0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79fcd266aa524e9b9d656b2eab1a8cd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3e34a9bb0d24577acc83d7ae4b2486d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79fcd266aa524e9b9d656b2eab1a8cd3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_09a7b0f32ef942afb2963f355e80a8bc",
      "value": "Calculatingâ€‡successâ€‡rates:â€‡100%"
     }
    },
    "dc043a4a5ed74b1c9b6cc8e027e5b2b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcffd72448ea44bf9ec8aec5b31762f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc043a4a5ed74b1c9b6cc8e027e5b2b6",
      "max": 40041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e50717143ae4771b600c2a5f73488e2",
      "value": 40041
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
