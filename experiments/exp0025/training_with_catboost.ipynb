{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0efba513",
   "metadata": {
    "id": "HU48Dzb4iuhP"
   },
   "source": [
    "# xAG予測コンペ　ベースラインコード（その2）\n",
    "\n",
    "ベースラインコード（host_baseline_001.ipynb）について、特徴量の追加作成やパラメータ最適化を行った改善版コードです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a57b0d9",
   "metadata": {
    "id": "4N4IPuA_J7sw"
   },
   "outputs": [],
   "source": [
    "#第一回はこちら\n",
    "#https://www.kaggle.com/competitions/dsdojo_1/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55e515",
   "metadata": {
    "id": "cdc2NNOJiuhU"
   },
   "source": [
    "---\n",
    "## セットアップ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8529b3a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZJyn-MciuhU",
    "outputId": "eb7079dd-b265-4b57-fda9-ff61cec466b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: japanize_matplotlib in /usr/local/lib/python3.11/site-packages (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (from japanize_matplotlib) (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib->japanize_matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->japanize_matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: catboost in /usr/local/lib/python3.11/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (from catboost) (3.10.6)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from catboost) (1.16.2)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.11/site-packages (from catboost) (6.3.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.11/site-packages (from plotly->catboost) (2.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 必要モジュールでColab環境にないものはinstall\n",
    "!pip install japanize_matplotlib\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b3b3db",
   "metadata": {
    "id": "km_jW_2YiuhU",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 必要モジュールをimport\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "import networkx as nx\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ランダム性を伴う処理を行うため、結果の再現性を保つにはシード値を固定しておく必要があります\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c13b46",
   "metadata": {
    "id": "ah17yN7bu-Mu",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# コンペの評価指標に合わせた目的関数/評価関数の定義\n",
    "WEIGHTED_TARGET_THRESHOLD = 0.1\n",
    "WEIGHTED_POSITIVE_WEIGHT = 5.0\n",
    "\n",
    "def make_sample_weight(y_true):\n",
    "    \"\"\"\n",
    "    ターゲットに応じた重みベクトルを生成\n",
    "    \"\"\"\n",
    "    y_array = np.asarray(y_true, dtype=float)\n",
    "    return np.where(y_array >= WEIGHTED_TARGET_THRESHOLD, WEIGHTED_POSITIVE_WEIGHT, 1.0)\n",
    "\n",
    "def weighted_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    重み付きRMSE評価関数\n",
    "    コンペの評価指標に合わせて実装\n",
    "    \"\"\"\n",
    "    weights = make_sample_weight(y_true)\n",
    "    squared_errors = (y_true - y_pred) ** 2\n",
    "    weighted_squared_errors = weights * squared_errors\n",
    "    pw_rmse = np.sqrt(np.mean(weighted_squared_errors) + 1e-9)\n",
    "    return float(pw_rmse)\n",
    "\n",
    "def weighted_rmse_feval(y_pred, dtrain):\n",
    "    \"\"\"\n",
    "    LightGBM用の重み付きRMSE評価関数\n",
    "    \"\"\"\n",
    "    y_true = dtrain.get_label()\n",
    "    weighted_rmse_value = weighted_rmse(y_true, y_pred)\n",
    "    return \"weighted_rmse\", weighted_rmse_value, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df386a04",
   "metadata": {
    "id": "v0L9gXW5iuhU"
   },
   "outputs": [],
   "source": [
    "# 表示できるdfの行、列数を増やす\n",
    "pd.set_option(\"display.max_rows\", 100)    # 最大100行まで表示\n",
    "pd.set_option(\"display.max_columns\", 100) # 最大100列まで表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b86531",
   "metadata": {
    "id": "29WdPR8riuhV"
   },
   "source": [
    "## データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5cbd03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 804
    },
    "id": "e6eZzzhRiuhV",
    "lines_to_next_cell": 2,
    "outputId": "b494a902-ca3a-4cde-d9e9-52c00f7f2c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ読み込み元パス: ../../data\n",
      "trainデータ形状: (27870, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Round</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Result</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>xAG</th>\n",
       "      <th>player_name</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>URL</th>\n",
       "      <th>player_id</th>\n",
       "      <th>match_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-09</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 4</td>\n",
       "      <td>Away</td>\n",
       "      <td>W 2–1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Leicester City</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-17</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 5</td>\n",
       "      <td>Home</td>\n",
       "      <td>D 0–0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-23</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 6</td>\n",
       "      <td>Away</td>\n",
       "      <td>W 4–0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Stoke City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day            Comp        Round Venue Result    Squad  \\\n",
       "0  2017-09-09  Sat  Premier League  Matchweek 4  Away  W 2–1  Chelsea   \n",
       "1  2017-09-17  Sun  Premier League  Matchweek 5  Home  D 0–0  Chelsea   \n",
       "2  2017-09-23  Sat  Premier League  Matchweek 6  Away  W 4–0  Chelsea   \n",
       "\n",
       "         Opponent  xAG  player_name  birth_date  \\\n",
       "0  Leicester City  0.1  Eden Hazard  1991-01-07   \n",
       "1         Arsenal  0.0  Eden Hazard  1991-01-07   \n",
       "2      Stoke City  0.0  Eden Hazard  1991-01-07   \n",
       "\n",
       "                                                 URL player_id match_id  \n",
       "0  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499753  \n",
       "1  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499760  \n",
       "2  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499776  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testデータ形状: (12798, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Round</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Result</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>player_name</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>URL</th>\n",
       "      <th>player_id</th>\n",
       "      <th>match_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 27</td>\n",
       "      <td>Home</td>\n",
       "      <td>W 3–0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 28</td>\n",
       "      <td>Away</td>\n",
       "      <td>L 1–2</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Manchester Utd</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2499996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 29</td>\n",
       "      <td>Away</td>\n",
       "      <td>L 0–1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>https://fbref.com/en/players/a39bb753/Eden-Hazard</td>\n",
       "      <td>25707</td>\n",
       "      <td>2500004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day            Comp         Round Venue Result    Squad  \\\n",
       "0  2018-02-12  Mon  Premier League  Matchweek 27  Home  W 3–0  Chelsea   \n",
       "1  2018-02-25  Sun  Premier League  Matchweek 28  Away  L 1–2  Chelsea   \n",
       "2  2018-03-04  Sun  Premier League  Matchweek 29  Away  L 0–1  Chelsea   \n",
       "\n",
       "          Opponent  player_name  birth_date  \\\n",
       "0        West Brom  Eden Hazard  1991-01-07   \n",
       "1   Manchester Utd  Eden Hazard  1991-01-07   \n",
       "2  Manchester City  Eden Hazard  1991-01-07   \n",
       "\n",
       "                                                 URL player_id match_id  \n",
       "0  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499979  \n",
       "1  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2499996  \n",
       "2  https://fbref.com/en/players/a39bb753/Eden-Hazard     25707  2500004  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "アクションデータ形状: (2303958, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>match_date</th>\n",
       "      <th>match_venue</th>\n",
       "      <th>match_status</th>\n",
       "      <th>home_team_name</th>\n",
       "      <th>away_team_name</th>\n",
       "      <th>match_winner</th>\n",
       "      <th>period_id</th>\n",
       "      <th>time_seconds</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>player_id</th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "      <th>type_name</th>\n",
       "      <th>result_name</th>\n",
       "      <th>bodypart_name</th>\n",
       "      <th>team_name_short</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>player_name</th>\n",
       "      <th>jersey_number</th>\n",
       "      <th>minutes_played</th>\n",
       "      <th>is_starter</th>\n",
       "      <th>competition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2576335</td>\n",
       "      <td>May 20, 2018 at 8:45:00 PM GMT+2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Played</td>\n",
       "      <td>SS Lazio</td>\n",
       "      <td>FC Internazionale Milano</td>\n",
       "      <td>3161</td>\n",
       "      <td>1</td>\n",
       "      <td>2.417590</td>\n",
       "      <td>3161</td>\n",
       "      <td>False</td>\n",
       "      <td>3344</td>\n",
       "      <td>53.55</td>\n",
       "      <td>34.00</td>\n",
       "      <td>65.10</td>\n",
       "      <td>39.44</td>\n",
       "      <td>pass</td>\n",
       "      <td>success</td>\n",
       "      <td>foot</td>\n",
       "      <td>Internazionale</td>\n",
       "      <td>1993-02-12</td>\n",
       "      <td>Rafael Alcântara do Nascimento</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "      <td>Italian first division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576335</td>\n",
       "      <td>May 20, 2018 at 8:45:00 PM GMT+2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Played</td>\n",
       "      <td>SS Lazio</td>\n",
       "      <td>FC Internazionale Milano</td>\n",
       "      <td>3161</td>\n",
       "      <td>1</td>\n",
       "      <td>3.904412</td>\n",
       "      <td>3161</td>\n",
       "      <td>False</td>\n",
       "      <td>116349</td>\n",
       "      <td>65.10</td>\n",
       "      <td>39.44</td>\n",
       "      <td>66.15</td>\n",
       "      <td>61.88</td>\n",
       "      <td>pass</td>\n",
       "      <td>success</td>\n",
       "      <td>foot</td>\n",
       "      <td>Internazionale</td>\n",
       "      <td>1991-08-24</td>\n",
       "      <td>Matías Vecino Falero</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>True</td>\n",
       "      <td>Italian first division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2576335</td>\n",
       "      <td>May 20, 2018 at 8:45:00 PM GMT+2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Played</td>\n",
       "      <td>SS Lazio</td>\n",
       "      <td>FC Internazionale Milano</td>\n",
       "      <td>3161</td>\n",
       "      <td>1</td>\n",
       "      <td>6.484211</td>\n",
       "      <td>3161</td>\n",
       "      <td>False</td>\n",
       "      <td>135903</td>\n",
       "      <td>66.15</td>\n",
       "      <td>61.88</td>\n",
       "      <td>69.30</td>\n",
       "      <td>48.96</td>\n",
       "      <td>pass</td>\n",
       "      <td>success</td>\n",
       "      <td>foot</td>\n",
       "      <td>Internazionale</td>\n",
       "      <td>1994-05-27</td>\n",
       "      <td>João Pedro Cavaco Cancelo</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>True</td>\n",
       "      <td>Italian first division</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id                        match_date match_venue match_status  \\\n",
       "0  2576335  May 20, 2018 at 8:45:00 PM GMT+2         NaN       Played   \n",
       "1  2576335  May 20, 2018 at 8:45:00 PM GMT+2         NaN       Played   \n",
       "2  2576335  May 20, 2018 at 8:45:00 PM GMT+2         NaN       Played   \n",
       "\n",
       "  home_team_name            away_team_name  match_winner  period_id  \\\n",
       "0       SS Lazio  FC Internazionale Milano          3161          1   \n",
       "1       SS Lazio  FC Internazionale Milano          3161          1   \n",
       "2       SS Lazio  FC Internazionale Milano          3161          1   \n",
       "\n",
       "   time_seconds  team_id  is_home player_id  start_x  start_y  end_x  end_y  \\\n",
       "0      2.417590     3161    False      3344    53.55    34.00  65.10  39.44   \n",
       "1      3.904412     3161    False    116349    65.10    39.44  66.15  61.88   \n",
       "2      6.484211     3161    False    135903    66.15    61.88  69.30  48.96   \n",
       "\n",
       "  type_name result_name bodypart_name team_name_short  birth_date  \\\n",
       "0      pass     success          foot  Internazionale  1993-02-12   \n",
       "1      pass     success          foot  Internazionale  1991-08-24   \n",
       "2      pass     success          foot  Internazionale  1994-05-27   \n",
       "\n",
       "                      player_name  jersey_number  minutes_played  is_starter  \\\n",
       "0  Rafael Alcântara do Nascimento              0              69        True   \n",
       "1            Matías Vecino Falero              0              96        True   \n",
       "2       João Pedro Cavaco Cancelo              0              96        True   \n",
       "\n",
       "              competition  \n",
       "0  Italian first division  \n",
       "1  Italian first division  \n",
       "2  Italian first division  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ローカル実行用のパス設定\n",
    "base_path = '../../data'\n",
    "print(f\"データ読み込み元パス: {base_path}\")\n",
    "\n",
    "# データ読み込み\n",
    "# player_idやmatch_idの数値的大小に意味はないのでstring形式で読み込み\n",
    "train_df = pd.read_csv(f\"{base_path}/match_train_data.csv\", dtype={\"player_id\": \"string\", \"match_id\": \"string\"})\n",
    "test_df = pd.read_csv(f\"{base_path}/match_test_data.csv\", dtype={\"player_id\": \"string\", \"match_id\": \"string\"})\n",
    "actions_df = pd.read_csv(f\"{base_path}/action_data.csv\", dtype={\"player_id\": \"string\", \"match_id\": \"string\"})\n",
    "submission_df = pd.read_csv(f\"{base_path}/sample_submission.csv\")\n",
    "\n",
    "print(f\"trainデータ形状: {train_df.shape}\")\n",
    "display(train_df.head(3))\n",
    "\n",
    "print(f\"\\ntestデータ形状: {test_df.shape}\")\n",
    "display(test_df.head(3))\n",
    "\n",
    "print(f\"\\nアクションデータ形状: {actions_df.shape}\")\n",
    "display(actions_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e550dd29",
   "metadata": {
    "id": "a4Pt7U5biuhV"
   },
   "source": [
    "## 特徴量エンジニアリング - 基本特徴量\n",
    "\n",
    "まず、001と同じ基本的な特徴量を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7623bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3d_UMBliuhV",
    "outputId": "3eec7699-ba5f-4497-855d-8c6c40c55b20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "マージ後のtrainデータ形状: (27870, 15)\n",
      "\n",
      "マージ後のtestデータ形状: (12798, 14)\n"
     ]
    }
   ],
   "source": [
    "# 所与のデータから簡単に計算できる年齢特徴量を追加する\n",
    "\n",
    "# 2017/18シーズン終了時点での年齢を計算\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "train_df['birth_date'] = pd.to_datetime(train_df['birth_date'])\n",
    "train_df['age'] = (train_df['Date'] - train_df['birth_date']).dt.days / 365.25\n",
    "\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "test_df['birth_date'] = pd.to_datetime(test_df['birth_date'])\n",
    "test_df['age'] = (test_df['Date'] - test_df['birth_date']).dt.days / 365.25\n",
    "\n",
    "print(f\"\\nマージ後のtrainデータ形状: {train_df.shape}\")\n",
    "print(f\"\\nマージ後のtestデータ形状: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8e12ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_urDy8riuhV",
    "outputId": "ef6080ba-2f4d-42ed-aea8-35cffd58e420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分析対象となる試合×選手: 40505組\n",
      "抽出されたアクション数: 1867094件\n"
     ]
    }
   ],
   "source": [
    "# アクションデータから試合×選手レベルの特徴量を作成\n",
    "\n",
    "# train/testに含まれる試合×選手の組み合わせを作成する\n",
    "target_match_players_train = train_df[['match_id', 'player_id']].drop_duplicates()\n",
    "target_match_players_test = test_df[['match_id', 'player_id']].drop_duplicates()\n",
    "target_match_players = pd.concat([target_match_players_train, target_match_players_test]).drop_duplicates()\n",
    "\n",
    "print(f\"分析対象となる試合×選手: {len(target_match_players)}組\")\n",
    "\n",
    "# アクションデータのうち、train/testデータに含まれる試合×選手のアクションのみを抽出\n",
    "relevant_actions = actions_df.merge(\n",
    "    target_match_players,\n",
    "    on=['match_id', 'player_id'],\n",
    "    how='inner'\n",
    ")\n",
    "print(f\"抽出されたアクション数: {len(relevant_actions)}件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafb9b9a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced_features imported and reloaded (early cell).\n"
     ]
    }
   ],
   "source": [
    "# 追加（早い段階に挿入）: 高度特徴量ユーティリティの読み込み\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "try:\n",
    "    ROOT = Path.cwd().resolve().parents[1]\n",
    "    if str(ROOT) not in sys.path:\n",
    "        sys.path.append(str(ROOT))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# モジュールをリロード（修正を反映させる）\n",
    "from scripts import advanced_features\n",
    "importlib.reload(advanced_features)\n",
    "\n",
    "from scripts.advanced_features import (\n",
    "    build_nstep_chain_features,\n",
    "    build_second_assist_sca_gca,\n",
    "    build_pass_geometry_and_timing,\n",
    "    build_xpass_risk_features,\n",
    "    add_player_trend,\n",
    "    # 🆕 新特徴量関数\n",
    "    build_time_based_features,\n",
    "    build_zone_based_features,\n",
    "    build_pass_network_centrality,\n",
    "    build_extended_chain_features,\n",
    "    build_dynamic_positioning_features,\n",
    ")\n",
    "print(\"advanced_features imported and reloaded (early cell).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ff206d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "hXudsW7vjuBf",
    "outputId": "5dcd2476-bef4-4b52-a970-22614a3b7fd9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_home</th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>False</td>\n",
       "      <td>1.05</td>\n",
       "      <td>34.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>True</td>\n",
       "      <td>87.15</td>\n",
       "      <td>33.32</td>\n",
       "      <td>105.0</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>False</td>\n",
       "      <td>8.40</td>\n",
       "      <td>40.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>True</td>\n",
       "      <td>100.80</td>\n",
       "      <td>29.92</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>True</td>\n",
       "      <td>95.55</td>\n",
       "      <td>34.68</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_home  start_x  start_y  end_x  end_y\n",
       "328     False     1.05    34.68    0.0   37.4\n",
       "448      True    87.15    33.32  105.0   37.4\n",
       "905     False     8.40    40.12    0.0   30.6\n",
       "3296     True   100.80    29.92  105.0   30.6\n",
       "4080     True    95.55    34.68  105.0   34.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_home</th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>False</td>\n",
       "      <td>103.95</td>\n",
       "      <td>33.32</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>True</td>\n",
       "      <td>87.15</td>\n",
       "      <td>33.32</td>\n",
       "      <td>105.0</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>False</td>\n",
       "      <td>96.60</td>\n",
       "      <td>27.88</td>\n",
       "      <td>105.0</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>True</td>\n",
       "      <td>100.80</td>\n",
       "      <td>29.92</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>True</td>\n",
       "      <td>95.55</td>\n",
       "      <td>34.68</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_home  start_x  start_y  end_x  end_y\n",
       "328     False   103.95    33.32  105.0   30.6\n",
       "448      True    87.15    33.32  105.0   37.4\n",
       "905     False    96.60    27.88  105.0   37.4\n",
       "3296     True   100.80    29.92  105.0   30.6\n",
       "4080     True    95.55    34.68  105.0   34.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 位置データについては、homeとawayで基準が異なる\n",
    "# homeの場合は、x=0が自陣ゴールライン、x=105が敵陣ゴールライン、y=0が右サイドライン、y=68が左サイドラインに対応する\n",
    "# awayでは逆になるため、homeの選手とawayの選手で平均的なx,yの値を比較することができない\n",
    "display(relevant_actions[(relevant_actions[\"type_name\"] == \"shot\") & (relevant_actions[\"result_name\"] == \"success\")][[\"is_home\", \"start_x\", \"start_y\", \"end_x\", \"end_y\"]].head())\n",
    "\n",
    "# そこで、位置を標準化するため、awayチームの場合は、x' = 105-x, y' = 68-yに修正する\n",
    "relevant_actions.loc[relevant_actions['is_home'] == False, 'start_x'] = 105 - relevant_actions.loc[relevant_actions['is_home'] == False, 'start_x']\n",
    "relevant_actions.loc[relevant_actions['is_home'] == False, 'end_x'] = 105 - relevant_actions.loc[relevant_actions['is_home'] == False, 'end_x']\n",
    "relevant_actions.loc[relevant_actions['is_home'] == False, 'start_y'] = 68 - relevant_actions.loc[relevant_actions['is_home'] == False, 'start_y']\n",
    "relevant_actions.loc[relevant_actions['is_home'] == False, 'end_y'] = 68 - relevant_actions.loc[relevant_actions['is_home'] == False, 'end_y']\n",
    "\n",
    "relevant_actions[(relevant_actions[\"type_name\"] == \"shot\") & (relevant_actions[\"result_name\"] == \"success\")][[\"is_home\", \"start_x\", \"start_y\", \"end_x\", \"end_y\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86955e67",
   "metadata": {
    "id": "sQOHu5iUnWLA"
   },
   "source": [
    "is_homeの値に関係なく、ゴールした場合end_x=105となっており、位置が標準化されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baa26226",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "5LCBi5A3joBl",
    "outputId": "935dbfa8-dd0f-44c5-e3f9-c2e8d4b26b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成したデータ形状: (40041, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>action_count</th>\n",
       "      <th>avg_x</th>\n",
       "      <th>avg_y</th>\n",
       "      <th>minutes_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>80</td>\n",
       "      <td>53.84</td>\n",
       "      <td>30.40</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>16</td>\n",
       "      <td>77.44</td>\n",
       "      <td>43.05</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>30</td>\n",
       "      <td>67.24</td>\n",
       "      <td>35.36</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  action_count  avg_x  avg_y  minutes_played\n",
       "0  2499719    120339            80  53.84  30.40              70\n",
       "1  2499719     12829            16  77.44  43.05              98\n",
       "2  2499719     14763            30  67.24  35.36              75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 基本的な統計特徴量の作成\n",
    "# groupby()とagg()を組み合わせることで、列ごとに任意の集計方法を指定できる。\n",
    "match_player_stats = (\n",
    "    relevant_actions\n",
    "    .groupby(['match_id', 'player_id'])\n",
    "    .agg(\n",
    "        action_count   = ('type_name', 'size'), # アクション数合計\n",
    "        avg_x          = ('start_x', 'mean'), # 平均ポジション（前後方向）\n",
    "        avg_y          = ('start_y', 'mean'), # 平均ポジション（左右方向）\n",
    "        minutes_played = ('minutes_played', 'first')  # 出場時間\n",
    "    )\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(f\"作成したデータ形状: {match_player_stats.shape}\")\n",
    "display(match_player_stats.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea35255",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing advanced features from relevant_actions (early) ...\n",
      "Advanced feature blocks created (early).\n"
     ]
    }
   ],
   "source": [
    "# 追加（relevant_actions直後）: 高度特徴量計算\n",
    "print(\"Computing advanced features from relevant_actions (early) ...\")\n",
    "\n",
    "nstep_block = build_nstep_chain_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    team_col=\"team_id\",\n",
    "    type_col=\"type_name\",\n",
    "    n_steps=3,\n",
    "    gamma=0.7,\n",
    ")\n",
    "\n",
    "second_assist, sca1, sca2, gca1, gca2 = build_second_assist_sca_gca(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    team_col=\"team_id\",\n",
    "    type_col=\"type_name\",\n",
    "    result_col=\"result_name\",\n",
    ")\n",
    "\n",
    "pass_geom, pass_latency = build_pass_geometry_and_timing(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    type_col=\"type_name\",\n",
    ")\n",
    "\n",
    "xpass_risk = build_xpass_risk_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    type_col=\"type_name\",\n",
    "    result_col=\"result_name\",\n",
    ")\n",
    "\n",
    "print(\"Advanced feature blocks created (early).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ec0719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算中: 新特徴量 (時間帯別/ゾーン別/ネットワーク/拡張連鎖/動的ポジショニング)...\n",
      "新特徴量ブロック作成完了\n",
      "  - 時間帯別: 40041行\n",
      "  - ゾーン別: 40041行\n",
      "  - ネットワーク中心性: 39831行\n",
      "  - 拡張連鎖: 40041行\n",
      "  - 動的ポジショニング: 40041行\n"
     ]
    }
   ],
   "source": [
    "# 🆕 新特徴量の計算 (EXP0025追加)\n",
    "print(\"計算中: 新特徴量 (時間帯別/ゾーン別/ネットワーク/拡張連鎖/動的ポジショニング)...\")\n",
    "\n",
    "# 1. 時間帯別パフォーマンス\n",
    "time_based_features = build_time_based_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    time_col=\"time_seconds\",\n",
    "    period_col=\"period_id\"\n",
    ")\n",
    "\n",
    "# 2. ゾーン別アクション密度\n",
    "zone_based_features = build_zone_based_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\"\n",
    ")\n",
    "\n",
    "# 3. パスネットワーク中心性\n",
    "network_centrality_features = build_pass_network_centrality(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    team_col=\"team_id\",\n",
    "    type_col=\"type_name\",\n",
    "    time_col=\"time_seconds\"\n",
    ")\n",
    "\n",
    "# 4. 拡張シーケンス連鎖 (7手先)\n",
    "extended_chain_features = build_extended_chain_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\",\n",
    "    team_col=\"team_id\",\n",
    "    type_col=\"type_name\",\n",
    "    n_steps=7,\n",
    "    gamma=0.6\n",
    ")\n",
    "\n",
    "# 5. 動的ポジショニング\n",
    "dynamic_positioning_features = build_dynamic_positioning_features(\n",
    "    relevant_actions,\n",
    "    match_col=\"match_id\",\n",
    "    player_col=\"player_id\"\n",
    ")\n",
    "\n",
    "print(\"新特徴量ブロック作成完了\")\n",
    "print(f\"  - 時間帯別: {len(time_based_features)}行\")\n",
    "print(f\"  - ゾーン別: {len(zone_based_features)}行\")\n",
    "print(f\"  - ネットワーク中心性: {len(network_centrality_features)}行\")\n",
    "print(f\"  - 拡張連鎖: {len(extended_chain_features)}行\")\n",
    "print(f\"  - 動的ポジショニング: {len(dynamic_positioning_features)}行\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1abe8e04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "RAZHAVEanr4A",
    "outputId": "a989b03e-8c48-472d-9aaf-03b24fac09bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成したデータ形状: (40041, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>goal_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  goal_count\n",
       "0  2499719    120339           0\n",
       "1  2499719     12829           2\n",
       "2  2499719     14763           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ゴール数の集計\n",
    "# type_nameにshotが含まれて、成功したアクションはゴールになる\n",
    "is_shot  = relevant_actions['type_name'].isin(['shot', 'shot_freekick', 'shot_penalty'])\n",
    "is_success = relevant_actions['result_name'].eq('success')\n",
    "is_goal = (is_shot & is_success).astype(int)\n",
    "\n",
    "match_player_goals = (\n",
    "    relevant_actions\n",
    "    .assign(is_goal=is_goal) # is_goal列を追加\n",
    "    .groupby(['match_id', 'player_id'], as_index=False)['is_goal']\n",
    "    .sum() # ゴールであるアクションを合計\n",
    "    .rename(columns={'is_goal': 'goal_count'})\n",
    ")\n",
    "\n",
    "print(f\"作成したデータ形状: {match_player_goals.shape}\")\n",
    "display(match_player_goals.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b94f8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "ZHhHF5_tiuhV",
    "outputId": "dfa2bb40-8395-43e4-c7c8-afe51f28a8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成したデータ形状: (40041, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>type_bad_touch_count</th>\n",
       "      <th>type_clearance_count</th>\n",
       "      <th>type_corner_crossed_count</th>\n",
       "      <th>type_corner_short_count</th>\n",
       "      <th>type_cross_count</th>\n",
       "      <th>type_dribble_count</th>\n",
       "      <th>type_foul_count</th>\n",
       "      <th>type_freekick_crossed_count</th>\n",
       "      <th>type_freekick_short_count</th>\n",
       "      <th>type_goalkick_count</th>\n",
       "      <th>type_interception_count</th>\n",
       "      <th>type_keeper_save_count</th>\n",
       "      <th>type_pass_count</th>\n",
       "      <th>type_shot_count</th>\n",
       "      <th>type_shot_freekick_count</th>\n",
       "      <th>type_shot_penalty_count</th>\n",
       "      <th>type_tackle_count</th>\n",
       "      <th>type_take_on_count</th>\n",
       "      <th>type_throw_in_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  type_bad_touch_count  type_clearance_count  \\\n",
       "0  2499719    120339                     0                     2   \n",
       "1  2499719     12829                     0                     0   \n",
       "2  2499719     14763                     0                     0   \n",
       "\n",
       "   type_corner_crossed_count  type_corner_short_count  type_cross_count  \\\n",
       "0                          0                        0                 2   \n",
       "1                          0                        0                 1   \n",
       "2                          0                        0                 1   \n",
       "\n",
       "   type_dribble_count  type_foul_count  type_freekick_crossed_count  \\\n",
       "0                   4                0                            0   \n",
       "1                   2                0                            0   \n",
       "2                   5                3                            0   \n",
       "\n",
       "   type_freekick_short_count  type_goalkick_count  type_interception_count  \\\n",
       "0                          0                    0                        5   \n",
       "1                          0                    0                        0   \n",
       "2                          0                    0                        0   \n",
       "\n",
       "   type_keeper_save_count  type_pass_count  type_shot_count  \\\n",
       "0                       0               66                1   \n",
       "1                       0               11                2   \n",
       "2                       0               17                2   \n",
       "\n",
       "   type_shot_freekick_count  type_shot_penalty_count  type_tackle_count  \\\n",
       "0                         0                        0                  0   \n",
       "1                         0                        0                  0   \n",
       "2                         0                        0                  1   \n",
       "\n",
       "   type_take_on_count  type_throw_in_count  \n",
       "0                   0                    0  \n",
       "1                   0                    0  \n",
       "2                   1                    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# アクションタイプ数の集計\n",
    "# type_name列の値ごとに数を集計する\n",
    "action_type_stats = (\n",
    "    relevant_actions\n",
    "    .groupby(['match_id', 'player_id', 'type_name'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)  # type_name を列に展開、欠損は0で埋める\n",
    "    .rename_axis(None, axis=1)\n",
    "    .add_prefix('type_').add_suffix('_count') # 列名に接頭辞と接尾辞を追加する（type_nameがshotなら「type_shot_count」になる）\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(f\"作成したデータ形状: {action_type_stats.shape}\")\n",
    "display(action_type_stats.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "401b8c4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMpQ9RL1n1h8",
    "lines_to_next_cell": 2,
    "outputId": "e3a47fbf-85f2-44ee-d77c-2acb13ee8c48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベース特徴量マージ後のtrainデータshape: (27870, 39)\n",
      "ベース特徴量マージ後のtestデータshape: (12798, 38)\n"
     ]
    }
   ],
   "source": [
    "# ベース特徴量をtrain/testへマージ\n",
    "train_df = (\n",
    "    train_df\n",
    "    .merge(match_player_stats, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(match_player_goals, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(action_type_stats, on=['match_id', 'player_id'], how='left')\n",
    ")\n",
    "\n",
    "\n",
    "test_df = (\n",
    "    test_df\n",
    "    .merge(match_player_stats, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(match_player_goals, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(action_type_stats, on=['match_id', 'player_id'], how='left')\n",
    ")\n",
    "\n",
    "\n",
    "action_type_cols = [col for col in train_df.columns if col.startswith('type_')]\n",
    "stats_count_cols = ['action_count', 'minutes_played', 'goal_count']\n",
    "\n",
    "for col in action_type_cols + stats_count_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0)\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(0)\n",
    "\n",
    "print(f\"ベース特徴量マージ後のtrainデータshape: {train_df.shape}\")\n",
    "print(f\"ベース特徴量マージ後のtestデータshape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755da67",
   "metadata": {
    "id": "vGTCBG_BiuhV"
   },
   "source": [
    "## 特徴量エンジニアリング - 応用特徴量\n",
    "\n",
    "ここから、より高度な特徴量を作成していきます。各特徴量の意図と計算方法を詳しく説明します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e83c8d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "09a43976bef243599b2e9b64cffb91b4",
      "d3e34a9bb0d24577acc83d7ae4b2486d",
      "dcffd72448ea44bf9ec8aec5b31762f6",
      "3a83f4956d7d41938ef54f146a5cc541",
      "69216dc0f0f4422e8166c4a8f8abe666",
      "79fcd266aa524e9b9d656b2eab1a8cd3",
      "09a7b0f32ef942afb2963f355e80a8bc",
      "dc043a4a5ed74b1c9b6cc8e027e5b2b6",
      "5e50717143ae4771b600c2a5f73488e2",
      "5b6ef11c003d4a79b3924bc396c0ff56",
      "78773c5f4ebc47fea4077d687ab0ea0c"
     ]
    },
    "id": "maM2mFbTiuhV",
    "lines_to_next_cell": 1,
    "outputId": "6c028ca4-a3f4-41f8-b6f5-79d096d17f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アクション成功率特徴量を計算中...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a510d3ed5b144b83a584091a12a86973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating success rates:   0%|          | 0/40041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成したデータ形状: (40041, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>pass_success_rate</th>\n",
       "      <th>shot_success_rate</th>\n",
       "      <th>take_on_success_rate</th>\n",
       "      <th>cross_success_rate</th>\n",
       "      <th>corner_crossed_success_rate</th>\n",
       "      <th>freekick_crossed_success_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  pass_success_rate  shot_success_rate  \\\n",
       "0  2499719    120339           0.924242                0.0   \n",
       "1  2499719     12829           0.636364                1.0   \n",
       "2  2499719     14763           0.647059                0.5   \n",
       "\n",
       "   take_on_success_rate  cross_success_rate  corner_crossed_success_rate  \\\n",
       "0                   0.0                 1.0                          0.0   \n",
       "1                   0.0                 0.0                          0.0   \n",
       "2                   1.0                 0.0                          0.0   \n",
       "\n",
       "   freekick_crossed_success_rate  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# アクション成功率特徴量\n",
    "# アシストに繋がる可能性を評価するため、各種アクションの成功率を計算する\n",
    "\n",
    "# 成功率を計算するアクションタイプ\n",
    "action_types_with_result = ['pass', 'shot', 'take_on', 'cross', 'corner_crossed', 'freekick_crossed']  # take_onはドリブルでの仕掛け\n",
    "\n",
    "success_rates_list = []\n",
    "print(\"アクション成功率特徴量を計算中...\")\n",
    "\n",
    "for (match_id, player_id), group in tqdm(relevant_actions.groupby(['match_id', 'player_id']), desc=\"Calculating success rates\"):\n",
    "    row_data = {'match_id': match_id, 'player_id': player_id}\n",
    "\n",
    "    for action_type in action_types_with_result:\n",
    "        type_actions = group[group['type_name'] == action_type] # 対象アクションを抽出\n",
    "\n",
    "        if len(type_actions) > 0:\n",
    "            success_count = len(type_actions[type_actions['result_name'] == 'success'])\n",
    "            total_count = len(type_actions)\n",
    "\n",
    "            # 成功率を計算\n",
    "            success_rate = success_count / total_count\n",
    "            row_data[f'{action_type}_success_rate'] = success_rate\n",
    "        else:\n",
    "            # 該当アクションがない場合は0\n",
    "            row_data[f'{action_type}_success_rate'] = 0\n",
    "\n",
    "    success_rates_list.append(row_data)\n",
    "\n",
    "success_rates = pd.DataFrame(success_rates_list)\n",
    "\n",
    "print(f\"作成したデータ形状: {success_rates.shape}\")\n",
    "display(success_rates.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b0bff5f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced features merged (early).\n",
      "🆕 新特徴量 25個を追加しました\n"
     ]
    }
   ],
   "source": [
    "# 追加（ベース特徴量マージの直前）: 高度特徴量のマージ\n",
    "def _merge_many(df, parts):\n",
    "    for part in parts:\n",
    "        if part is None or (hasattr(part, \"empty\") and part.empty):\n",
    "            continue\n",
    "        df = df.merge(part, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "    return df\n",
    "\n",
    "train_df = _merge_many(\n",
    "    train_df,\n",
    "    [\n",
    "        nstep_block,\n",
    "        second_assist,\n",
    "        sca1,\n",
    "        sca2,\n",
    "        gca1,\n",
    "        gca2,\n",
    "        pass_geom,\n",
    "        pass_latency,\n",
    "        xpass_risk,\n",
    "        # 🆕 新特徴量\n",
    "        time_based_features,\n",
    "        zone_based_features,\n",
    "        network_centrality_features,\n",
    "        extended_chain_features,\n",
    "        dynamic_positioning_features,\n",
    "    ],\n",
    ")\n",
    "\n",
    "test_df = _merge_many(\n",
    "    test_df,\n",
    "    [\n",
    "        nstep_block,\n",
    "        second_assist,\n",
    "        sca1,\n",
    "        sca2,\n",
    "        gca1,\n",
    "        gca2,\n",
    "        pass_geom,\n",
    "        pass_latency,\n",
    "        xpass_risk,\n",
    "        # 🆕 新特徴量\n",
    "        time_based_features,\n",
    "        zone_based_features,\n",
    "        network_centrality_features,\n",
    "        extended_chain_features,\n",
    "        dynamic_positioning_features,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Fill NA and types（ここで欠損を潰す）\n",
    "count_cols = [\"second_assist_count\", \"SCA_1\", \"SCA_2\", \"GCA_1\", \"GCA_2\"]\n",
    "for col in count_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0).astype(int)\n",
    "        test_df[col] = test_df[col].fillna(0).astype(int)\n",
    "\n",
    "num_cols = [\n",
    "    \"nstep_to_shot\",\n",
    "    \"nstep_xt_delta\",\n",
    "    \"pass_dist_mean\",\n",
    "    \"pass_dist_max\",\n",
    "    \"to_goal_angle_abs_mean\",\n",
    "    \"to_goal_dist_mean\",\n",
    "    \"pass_to_shot_latency_mean\",\n",
    "    \"pass_to_shot_latency_min\",\n",
    "    \"risk_creativity_sum\",\n",
    "    \"xpass_mean\",\n",
    "    \"xpass_min\",\n",
    "    \"pass_success_minus_xpass\",\n",
    "    \"xpass_deep_mean\",\n",
    "    \"xpass_box_mean\",\n",
    "]\n",
    "for col in num_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0.0)\n",
    "        test_df[col] = test_df[col].fillna(0.0)\n",
    "\n",
    "# 🆕 新特徴量の欠損値処理\n",
    "new_feature_cols = [\n",
    "    # 時間帯別\n",
    "    \"first_half_actions\", \"second_half_actions\", \"final_15min_actions\",\n",
    "    \"early_10min_actions\", \"time_weighted_intensity\",\n",
    "    # ゾーン別\n",
    "    \"defensive_zone_actions\", \"middle_zone_actions\", \"attacking_zone_actions\",\n",
    "    \"halfspace_left_actions\", \"halfspace_right_actions\", \"central_corridor_actions\",\n",
    "    \"final_third_penetrations\", \"box_entries\",\n",
    "    # ネットワーク中心性\n",
    "    \"betweenness_centrality\", \"closeness_centrality\", \"degree_centrality\",\n",
    "    \"pass_receiver_diversity\", \"unique_pass_partners\",\n",
    "    # 拡張連鎖\n",
    "    \"longchain_to_shot\", \"longchain_xt_delta\",\n",
    "    # 動的ポジショニング\n",
    "    \"position_variance_x\", \"position_variance_y\", \"position_range_x\",\n",
    "    \"position_range_y\", \"avg_action_distance\",\n",
    "]\n",
    "for col in new_feature_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0.0)\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(0.0)\n",
    "\n",
    "print(\"Advanced features merged (early).\")\n",
    "print(f\"🆕 新特徴量 {len(new_feature_cols)}個を追加しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef22e643",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "追加された高度特徴量: 38個 (🆕新特徴量含む)\n"
     ]
    }
   ],
   "source": [
    "# 追加（all_features定義セルの直後を想定）: all_features に高度特徴量を含める\n",
    "advanced_candidates = [\n",
    "    \"second_assist_count\",\n",
    "    \"SCA_1\",\n",
    "    \"SCA_2\",\n",
    "    \"GCA_1\",\n",
    "    \"GCA_2\",\n",
    "    \"nstep_to_shot\",\n",
    "    \"nstep_xt_delta\",\n",
    "    \"pass_dist_mean\",\n",
    "    \"pass_dist_max\",\n",
    "    \"to_goal_angle_abs_mean\",\n",
    "    \"to_goal_dist_mean\",\n",
    "    \"pass_to_shot_latency_mean\",\n",
    "    \"pass_to_shot_latency_min\",\n",
    "    \"risk_creativity_sum\",\n",
    "    \"xpass_mean\",\n",
    "    \"xpass_min\",\n",
    "    \"pass_success_minus_xpass\",\n",
    "    \"xpass_deep_mean\",\n",
    "    \"xpass_box_mean\",\n",
    "    # 時系列トレンド\n",
    "    \"xAG_expanding_mean\",\n",
    "    \"xAG_rolling3_mean\",\n",
    "    \"xAG_diff_prev\",\n",
    "    # 🆕 新特徴量\n",
    "    \"first_half_actions\", \"second_half_actions\", \"final_15min_actions\",\n",
    "    \"early_10min_actions\", \"time_weighted_intensity\",\n",
    "    \"defensive_zone_actions\", \"middle_zone_actions\", \"attacking_zone_actions\",\n",
    "    \"halfspace_left_actions\", \"halfspace_right_actions\", \"central_corridor_actions\",\n",
    "    \"final_third_penetrations\", \"box_entries\",\n",
    "    \"betweenness_centrality\", \"closeness_centrality\", \"degree_centrality\",\n",
    "    \"pass_receiver_diversity\", \"unique_pass_partners\",\n",
    "    \"longchain_to_shot\", \"longchain_xt_delta\",\n",
    "    \"position_variance_x\", \"position_variance_y\", \"position_range_x\",\n",
    "    \"position_range_y\", \"avg_action_distance\",\n",
    "]\n",
    "advanced_features = [c for c in advanced_candidates if c in train_df.columns]\n",
    "try:\n",
    "    all_features = list(dict.fromkeys(all_features + advanced_features))\n",
    "except NameError:\n",
    "    _advanced_features_pending = advanced_features\n",
    "print(f\"追加された高度特徴量: {len(advanced_features)}個 (🆕新特徴量含む)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13635c99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "yjC2SnrIiuhW",
    "outputId": "ac96bf5f-28cf-4e2f-a395-3c52f5b32736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "位置ベース特徴量を計算中...\n",
      "\n",
      "ゾーン別アクション統計:\n",
      "  defensive エリア: 平均 13.5 アクション\n",
      "  midfield  エリア: 平均 20.8 アクション\n",
      "  attacking エリア: 平均 12.3 アクション\n",
      "\n",
      "作成したデータ形状: (40041, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>start_zone</th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>zone_attacking_actions</th>\n",
       "      <th>zone_defensive_actions</th>\n",
       "      <th>zone_midfield_actions</th>\n",
       "      <th>zone_attacking_actions_ratio</th>\n",
       "      <th>zone_midfield_actions_ratio</th>\n",
       "      <th>zone_defensive_actions_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "start_zone match_id player_id  zone_attacking_actions  zone_defensive_actions  \\\n",
       "0           2499719    120339                      19                      16   \n",
       "1           2499719     12829                      12                       0   \n",
       "2           2499719     14763                      15                       5   \n",
       "\n",
       "start_zone  zone_midfield_actions  zone_attacking_actions_ratio  \\\n",
       "0                              45                        0.2375   \n",
       "1                               4                        0.7500   \n",
       "2                              10                        0.5000   \n",
       "\n",
       "start_zone  zone_midfield_actions_ratio  zone_defensive_actions_ratio  \n",
       "0                              0.562500                      0.200000  \n",
       "1                              0.250000                      0.000000  \n",
       "2                              0.333333                      0.166667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 位置ベース特徴量\n",
    "# フィールド上での活動エリアを分析し、攻撃的な選手を識別\n",
    "\n",
    "print(\"位置ベース特徴量を計算中...\")\n",
    "\n",
    "# フィールドを3つのエリアに分割（x座標ベース）\n",
    "def categorize_position(x):\n",
    "    \"\"\"x座標からフィールドエリアを判定\"\"\"\n",
    "    if x < 35:\n",
    "        return 'defensive'  # 守備的エリア\n",
    "    elif x < 70:\n",
    "        return 'midfield'   # 中盤エリア\n",
    "    else:\n",
    "        return 'attacking'  # 攻撃的エリア\n",
    "\n",
    "# 各アクションのエリアを判定\n",
    "relevant_actions['start_zone'] = relevant_actions['start_x'].apply(categorize_position)\n",
    "\n",
    "# ゾーン別アクション数を集計\n",
    "zone_actions = (\n",
    "    relevant_actions\n",
    "    .pivot_table(\n",
    "        index=['match_id', 'player_id'],\n",
    "        columns='start_zone',\n",
    "        values='period_id',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "    .add_prefix('zone_')\n",
    "    .add_suffix('_actions')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 各ゾーンでのアクション比率を計算\n",
    "zone_actions['total_actions'] = (\n",
    "    zone_actions.get('zone_defensive_actions', 0) +\n",
    "    zone_actions.get('zone_midfield_actions', 0) +\n",
    "    zone_actions.get('zone_attacking_actions', 0)\n",
    ")\n",
    "\n",
    "zone_actions['zone_attacking_actions_ratio'] = np.where(\n",
    "    zone_actions['total_actions'] > 0,\n",
    "    zone_actions.get('zone_attacking_actions', 0) / zone_actions['total_actions'],\n",
    "    0\n",
    ")\n",
    "\n",
    "zone_actions['zone_midfield_actions_ratio'] = np.where(\n",
    "    zone_actions['total_actions'] > 0,\n",
    "    zone_actions.get('zone_midfield_actions', 0) / zone_actions['total_actions'],\n",
    "    0\n",
    ")\n",
    "\n",
    "zone_actions['zone_defensive_actions_ratio'] = np.where(\n",
    "    zone_actions['total_actions'] > 0,\n",
    "    zone_actions.get('zone_defensive_actions', 0) / zone_actions['total_actions'],\n",
    "    0\n",
    ")\n",
    "zone_actions = zone_actions.drop(columns=['total_actions'])\n",
    "\n",
    "print(f\"\\nゾーン別アクション統計:\")\n",
    "for zone in ['defensive', 'midfield', 'attacking']:\n",
    "    col_name = f'zone_{zone}_actions'\n",
    "    if col_name in zone_actions.columns:\n",
    "        mean_val = zone_actions[col_name].mean()\n",
    "        print(f\"  {zone:10s}エリア: 平均 {mean_val:.1f} アクション\")\n",
    "\n",
    "print(f\"\\n作成したデータ形状: {zone_actions.shape}\")\n",
    "display(zone_actions.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64cc03e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "W2m7WIjGiuhW",
    "outputId": "87b1e9c5-034e-4850-89e4-65e627031806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "時間正規化特徴量を計算中...\n",
      "\n",
      "作成したデータ形状: (40041, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>action_count_per_minute</th>\n",
       "      <th>goal_count_per_minute</th>\n",
       "      <th>type_bad_touch_count_per_minute</th>\n",
       "      <th>type_clearance_count_per_minute</th>\n",
       "      <th>type_corner_crossed_count_per_minute</th>\n",
       "      <th>type_corner_short_count_per_minute</th>\n",
       "      <th>type_cross_count_per_minute</th>\n",
       "      <th>type_dribble_count_per_minute</th>\n",
       "      <th>type_foul_count_per_minute</th>\n",
       "      <th>type_freekick_crossed_count_per_minute</th>\n",
       "      <th>type_freekick_short_count_per_minute</th>\n",
       "      <th>type_goalkick_count_per_minute</th>\n",
       "      <th>type_interception_count_per_minute</th>\n",
       "      <th>type_keeper_save_count_per_minute</th>\n",
       "      <th>type_pass_count_per_minute</th>\n",
       "      <th>type_shot_count_per_minute</th>\n",
       "      <th>type_shot_freekick_count_per_minute</th>\n",
       "      <th>type_shot_penalty_count_per_minute</th>\n",
       "      <th>type_tackle_count_per_minute</th>\n",
       "      <th>type_take_on_count_per_minute</th>\n",
       "      <th>type_throw_in_count_per_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  action_count_per_minute  goal_count_per_minute  \\\n",
       "0  2499719    120339                 1.142857               0.000000   \n",
       "1  2499719     12829                 0.163265               0.020408   \n",
       "2  2499719     14763                 0.400000               0.013333   \n",
       "\n",
       "   type_bad_touch_count_per_minute  type_clearance_count_per_minute  \\\n",
       "0                              0.0                         0.028571   \n",
       "1                              0.0                         0.000000   \n",
       "2                              0.0                         0.000000   \n",
       "\n",
       "   type_corner_crossed_count_per_minute  type_corner_short_count_per_minute  \\\n",
       "0                                   0.0                                 0.0   \n",
       "1                                   0.0                                 0.0   \n",
       "2                                   0.0                                 0.0   \n",
       "\n",
       "   type_cross_count_per_minute  type_dribble_count_per_minute  \\\n",
       "0                     0.028571                       0.057143   \n",
       "1                     0.010204                       0.020408   \n",
       "2                     0.013333                       0.066667   \n",
       "\n",
       "   type_foul_count_per_minute  type_freekick_crossed_count_per_minute  \\\n",
       "0                        0.00                                     0.0   \n",
       "1                        0.00                                     0.0   \n",
       "2                        0.04                                     0.0   \n",
       "\n",
       "   type_freekick_short_count_per_minute  type_goalkick_count_per_minute  \\\n",
       "0                                   0.0                             0.0   \n",
       "1                                   0.0                             0.0   \n",
       "2                                   0.0                             0.0   \n",
       "\n",
       "   type_interception_count_per_minute  type_keeper_save_count_per_minute  \\\n",
       "0                            0.071429                                0.0   \n",
       "1                            0.000000                                0.0   \n",
       "2                            0.000000                                0.0   \n",
       "\n",
       "   type_pass_count_per_minute  type_shot_count_per_minute  \\\n",
       "0                    0.942857                    0.014286   \n",
       "1                    0.112245                    0.020408   \n",
       "2                    0.226667                    0.026667   \n",
       "\n",
       "   type_shot_freekick_count_per_minute  type_shot_penalty_count_per_minute  \\\n",
       "0                                  0.0                                 0.0   \n",
       "1                                  0.0                                 0.0   \n",
       "2                                  0.0                                 0.0   \n",
       "\n",
       "   type_tackle_count_per_minute  type_take_on_count_per_minute  \\\n",
       "0                      0.000000                       0.000000   \n",
       "1                      0.000000                       0.000000   \n",
       "2                      0.013333                       0.013333   \n",
       "\n",
       "   type_throw_in_count_per_minute  \n",
       "0                             0.0  \n",
       "1                             0.0  \n",
       "2                             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 時間正規化特徴量\n",
    "# 出場時間による影響を排除し、公平な比較を可能にする\n",
    "\n",
    "print(\"時間正規化特徴量を計算中...\")\n",
    "\n",
    "per_minute_features = match_player_stats.copy()\n",
    "\n",
    "# 全体アクション数の正規化\n",
    "per_minute_features['action_count_per_minute'] = np.where(\n",
    "    per_minute_features['minutes_played'] > 0,\n",
    "    per_minute_features['action_count'] / per_minute_features['minutes_played'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# ゴール数をマージ・ゼロ埋め\n",
    "per_minute_features = per_minute_features.merge(\n",
    "    match_player_goals,\n",
    "    on=['match_id', 'player_id'],\n",
    "    how='left'\n",
    ")\n",
    "per_minute_features['goal_count'] = per_minute_features['goal_count'].fillna(0)\n",
    "\n",
    "# ゴール数の正規化\n",
    "per_minute_features['goal_count_per_minute'] = np.where(\n",
    "    per_minute_features['minutes_played'] > 0,\n",
    "    per_minute_features['goal_count'] / per_minute_features['minutes_played'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# アクションタイプ別アクション数をマージ・ゼロ埋め\n",
    "per_minute_features = per_minute_features.merge(\n",
    "    action_type_stats,\n",
    "    on=['match_id', 'player_id'],\n",
    "    how='left'\n",
    ")\n",
    "action_type_cols = [col for col in per_minute_features.columns if col.startswith('type_') and col.endswith('_count')] # アクションタイプ別アクション数の列\n",
    "for col in action_type_cols:\n",
    "    per_minute_features[col] = per_minute_features[col].fillna(0)\n",
    "\n",
    "# アクションタイプ別アクション数の正規化\n",
    "for col in action_type_cols:\n",
    "    new_col_name = col.replace('_count', '_count_per_minute')\n",
    "    per_minute_features[new_col_name] = np.where(\n",
    "        per_minute_features['minutes_played'] > 0,\n",
    "        per_minute_features[col] / per_minute_features['minutes_played'],\n",
    "        0\n",
    "    )\n",
    "\n",
    "# 新規作成した列のみに絞り込み\n",
    "per_minute_cols = [col for col in per_minute_features.columns if col.endswith('_per_minute')]\n",
    "per_minute_features = per_minute_features[['match_id', 'player_id'] + per_minute_cols]\n",
    "\n",
    "print(f\"\\n作成したデータ形状: {per_minute_features.shape}\")\n",
    "display(per_minute_features.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a302cfed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "5m47SqPMiuhW",
    "outputId": "5ceb8fa8-cc5a-478a-bb4b-7be3075b35f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "攻撃/守備バランス特徴量を計算中...\n",
      "\n",
      "作成したデータ形状: (40010, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>action_type</th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>type_defensive_actions</th>\n",
       "      <th>type_offensive_actions</th>\n",
       "      <th>type_offensive_action_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>120339</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>12829</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>14763</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "action_type match_id player_id  type_defensive_actions  \\\n",
       "0            2499719    120339                       7   \n",
       "1            2499719     12829                       0   \n",
       "2            2499719     14763                       1   \n",
       "\n",
       "action_type  type_offensive_actions  type_offensive_action_ratio  \n",
       "0                                73                     0.912500  \n",
       "1                                16                     1.000000  \n",
       "2                                26                     0.962963  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 攻撃/守備バランス特徴量\n",
    "# 選手のプレースタイルを定量化し、攻撃的な選手を識別\n",
    "\n",
    "print(\"攻撃/守備バランス特徴量を計算中...\")\n",
    "\n",
    "# 攻撃/守備アクションの定義\n",
    "offensive_actions = ['shot', 'pass', 'cross', 'take_on', 'dribble']\n",
    "defensive_actions = ['tackle', 'interception', 'clearance']\n",
    "\n",
    "# 各アクションの分類を付与\n",
    "def categorize_ad(action):\n",
    "    if action in offensive_actions:\n",
    "        return 'offensive'\n",
    "    elif action in defensive_actions:\n",
    "        return 'defensive'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "relevant_actions['action_type'] = relevant_actions['type_name'].apply(categorize_ad)\n",
    "\n",
    "# 攻守別アクション数を集計\n",
    "offense_defense_balance = (\n",
    "    relevant_actions\n",
    "    .pivot_table(\n",
    "        index=['match_id', 'player_id'],\n",
    "        columns='action_type',\n",
    "        values='period_id',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "    .add_prefix('type_')\n",
    "    .add_suffix('_actions')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 攻守バランス指標を計算\n",
    "offense_defense_balance['total_actions'] = (\n",
    "    offense_defense_balance.get('type_offensive_actions', 0) +\n",
    "    offense_defense_balance.get('type_defensive_actions', 0)\n",
    ")\n",
    "\n",
    "offense_defense_balance['type_offensive_action_ratio'] = np.where(\n",
    "    offense_defense_balance['total_actions'] > 0,\n",
    "    offense_defense_balance['type_offensive_actions'] / offense_defense_balance['total_actions'],\n",
    "    0\n",
    ")\n",
    "\n",
    "offense_defense_balance = offense_defense_balance.drop(columns=['total_actions'])\n",
    "\n",
    "print(f\"\\n作成したデータ形状: {offense_defense_balance.shape}\")\n",
    "display(offense_defense_balance.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a599156",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "sLKXukn5pIUx",
    "outputId": "3c3f0531-8bd0-4e66-9c7e-dacfa3a0b86a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "次アクションがシュートのパス数を計算中...\n"
     ]
    }
   ],
   "source": [
    "# 時系列要素を加味した特徴量\n",
    "# xAGの定義を考えると、パスした味方のシュートが多いほどxAGは高くなる\n",
    "# そこで、次アクションがシュートであるパスの数を選手-試合ごとに集計する\n",
    "\n",
    "print(\"次アクションがシュートのパス数を計算中...\")\n",
    "\n",
    "# 直後のアクションタイプをシフトで付与\n",
    "relevant_actions = relevant_actions.sort_values(['match_id', 'period_id', 'time_seconds'])  # 念の為アクションを時間でソート\n",
    "relevant_actions[\"next_type\"] = relevant_actions.groupby(\"match_id\")[\"type_name\"].shift(-1)\n",
    "\n",
    "# pass → shot となっている行を抽出\n",
    "pass_to_shot = relevant_actions[\n",
    "    (relevant_actions[\"type_name\"] == \"pass\") &\n",
    "    (relevant_actions[\"next_type\"] == \"shot\")\n",
    "]\n",
    "\n",
    "# match_id, player_idごとにカウント\n",
    "pass_leads_to_shot = (\n",
    "    pass_to_shot.groupby([\"match_id\", \"player_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"pass_leads_to_shot\")\n",
    ")\n",
    "\n",
    "print(f\"\\n作成したデータ形状: {pass_leads_to_shot.shape}\")\n",
    "display(pass_leads_to_shot.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12a383",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# プログレッシブ/ディープ系の特徴量\n",
    "print(\"プログレッシブ/ディープ系特徴量を計算中...\")\n",
    "\n",
    "PASS_PROGRESSIVE_TYPES = {\"pass\", \"cross\", \"freekick_crossed\", \"corner_crossed\"}\n",
    "CARRY_PROGRESSIVE_TYPES = {\"carry\", \"dribble\", \"take_on\"}\n",
    "\n",
    "progressive_pass_actions = relevant_actions[\n",
    "    relevant_actions[\"type_name\"].isin(PASS_PROGRESSIVE_TYPES)\n",
    "].copy()\n",
    "\n",
    "if not progressive_pass_actions.empty:\n",
    "    dx = (progressive_pass_actions[\"end_x\"] - progressive_pass_actions[\"start_x\"]).fillna(0.0)\n",
    "    dy = (progressive_pass_actions[\"end_y\"] - progressive_pass_actions[\"start_y\"]).fillna(0.0)\n",
    "else:\n",
    "    dx = pd.Series(dtype=float)\n",
    "    dy = pd.Series(dtype=float)\n",
    "\n",
    "progressive_pass_actions[\"delta_x\"] = dx\n",
    "progressive_pass_actions[\"delta_total\"] = np.hypot(dx, dy)\n",
    "progressive_pass_actions[\"is_completed\"] = progressive_pass_actions[\"result_name\"] == \"success\"\n",
    "\n",
    "FINAL_THIRD_X = 70.0\n",
    "DEEP_COMPLETION_X = 85.0\n",
    "PENALTY_AREA_X = 88.0\n",
    "PROGRESS_ADVANCE_MIN = 10.0\n",
    "\n",
    "progressive_pass_actions[\"is_progressive\"] = (\n",
    "    (progressive_pass_actions[\"delta_x\"] >= PROGRESS_ADVANCE_MIN)\n",
    "    | (\n",
    "        (progressive_pass_actions[\"start_x\"] < FINAL_THIRD_X)\n",
    "        & (progressive_pass_actions[\"end_x\"] >= FINAL_THIRD_X)\n",
    "    )\n",
    "    | (progressive_pass_actions[\"end_x\"] >= DEEP_COMPLETION_X)\n",
    ")\n",
    "\n",
    "progressive_pass_actions[\"progressive_attempt\"] = progressive_pass_actions[\"is_progressive\"].astype(int)\n",
    "progressive_pass_actions[\"progressive_success\"] = (\n",
    "    progressive_pass_actions[\"is_progressive\"] & progressive_pass_actions[\"is_completed\"]\n",
    ").astype(int)\n",
    "progressive_pass_actions[\"progressive_distance\"] = np.where(\n",
    "    progressive_pass_actions[\"is_progressive\"],\n",
    "    progressive_pass_actions[\"delta_total\"],\n",
    "    0.0,\n",
    ")\n",
    "\n",
    "progressive_pass_actions[\"is_final_third_entry\"] = (\n",
    "    progressive_pass_actions[\"is_completed\"]\n",
    "    & (progressive_pass_actions[\"start_x\"] < FINAL_THIRD_X)\n",
    "    & (progressive_pass_actions[\"end_x\"] >= FINAL_THIRD_X)\n",
    ")\n",
    "progressive_pass_actions[\"is_deep_completion\"] = (\n",
    "    progressive_pass_actions[\"is_completed\"]\n",
    "    & (progressive_pass_actions[\"end_x\"] >= DEEP_COMPLETION_X)\n",
    ")\n",
    "progressive_pass_actions[\"is_penalty_area_entry\"] = (\n",
    "    progressive_pass_actions[\"is_completed\"]\n",
    "    & (progressive_pass_actions[\"end_x\"] >= PENALTY_AREA_X)\n",
    ")\n",
    "\n",
    "pass_progressive_features = (\n",
    "    progressive_pass_actions.groupby([\"match_id\", \"player_id\"]).agg(\n",
    "        progressive_pass_count=(\"progressive_attempt\", \"sum\"),\n",
    "        progressive_pass_success=(\"progressive_success\", \"sum\"),\n",
    "        progressive_pass_distance_total=(\"progressive_distance\", \"sum\"),\n",
    "        final_third_entry_count=(\"is_final_third_entry\", \"sum\"),\n",
    "        deep_completion_count=(\"is_deep_completion\", \"sum\"),\n",
    "        penalty_area_entry_count=(\"is_penalty_area_entry\", \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "if \"progressive_pass_count\" in pass_progressive_features:\n",
    "    pass_progressive_features[\"progressive_pass_success_rate\"] = np.where(\n",
    "        pass_progressive_features[\"progressive_pass_count\"] > 0,\n",
    "        pass_progressive_features[\"progressive_pass_success\"]\n",
    "        / pass_progressive_features[\"progressive_pass_count\"],\n",
    "        0.0,\n",
    "    )\n",
    "    pass_progressive_features[\"progressive_pass_distance_mean\"] = np.where(\n",
    "        pass_progressive_features[\"progressive_pass_count\"] > 0,\n",
    "        pass_progressive_features[\"progressive_pass_distance_total\"]\n",
    "        / pass_progressive_features[\"progressive_pass_count\"],\n",
    "        0.0,\n",
    "    )\n",
    "else:\n",
    "    pass_progressive_features[\"progressive_pass_success_rate\"] = []\n",
    "    pass_progressive_features[\"progressive_pass_distance_mean\"] = []\n",
    "\n",
    "carry_actions = relevant_actions[\n",
    "    relevant_actions[\"type_name\"].isin(CARRY_PROGRESSIVE_TYPES)\n",
    "].copy()\n",
    "\n",
    "if not carry_actions.empty:\n",
    "    carry_actions[\"end_x\"] = carry_actions[\"end_x\"].fillna(carry_actions[\"start_x\"])\n",
    "    carry_actions[\"end_y\"] = carry_actions[\"end_y\"].fillna(carry_actions[\"start_y\"])\n",
    "    carry_dx = (carry_actions[\"end_x\"] - carry_actions[\"start_x\"]).fillna(0.0)\n",
    "    carry_dy = (carry_actions[\"end_y\"] - carry_actions[\"start_y\"]).fillna(0.0)\n",
    "    carry_actions[\"delta_total\"] = np.hypot(carry_dx, carry_dy)\n",
    "    carry_actions[\"delta_x\"] = carry_dx\n",
    "    carry_actions[\"is_success\"] = carry_actions[\"result_name\"] == \"success\"\n",
    "    carry_actions[\"is_progressive\"] = (\n",
    "        (carry_actions[\"delta_x\"] >= 5.0)\n",
    "        | (\n",
    "            (carry_actions[\"start_x\"] < FINAL_THIRD_X)\n",
    "            & (carry_actions[\"end_x\"] >= FINAL_THIRD_X)\n",
    "        )\n",
    "    )\n",
    "    carry_actions[\"progressive_carry_attempt\"] = carry_actions[\"is_progressive\"].astype(int)\n",
    "    carry_actions[\"progressive_carry_success\"] = (\n",
    "        carry_actions[\"is_progressive\"] & carry_actions[\"is_success\"]\n",
    "    ).astype(int)\n",
    "    carry_actions[\"progressive_carry_distance\"] = np.where(\n",
    "        carry_actions[\"is_progressive\"], carry_actions[\"delta_total\"], 0.0\n",
    "    )\n",
    "\n",
    "    carry_progressive_features = (\n",
    "        carry_actions.groupby([\"match_id\", \"player_id\"]).agg(\n",
    "            progressive_carry_count=(\"progressive_carry_attempt\", \"sum\"),\n",
    "            progressive_carry_success=(\"progressive_carry_success\", \"sum\"),\n",
    "            progressive_carry_distance_total=(\"progressive_carry_distance\", \"sum\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    carry_progressive_features[\"progressive_carry_success_rate\"] = np.where(\n",
    "        carry_progressive_features[\"progressive_carry_count\"] > 0,\n",
    "        carry_progressive_features[\"progressive_carry_success\"]\n",
    "        / carry_progressive_features[\"progressive_carry_count\"],\n",
    "        0.0,\n",
    "    )\n",
    "    carry_progressive_features[\"progressive_carry_distance_mean\"] = np.where(\n",
    "        carry_progressive_features[\"progressive_carry_count\"] > 0,\n",
    "        carry_progressive_features[\"progressive_carry_distance_total\"]\n",
    "        / carry_progressive_features[\"progressive_carry_count\"],\n",
    "        0.0,\n",
    "    )\n",
    "else:\n",
    "    carry_progressive_features = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"match_id\",\n",
    "            \"player_id\",\n",
    "            \"progressive_carry_count\",\n",
    "            \"progressive_carry_success\",\n",
    "            \"progressive_carry_distance_total\",\n",
    "            \"progressive_carry_success_rate\",\n",
    "            \"progressive_carry_distance_mean\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "progressive_features = pass_progressive_features.merge(\n",
    "    carry_progressive_features,\n",
    "    on=[\"match_id\", \"player_id\"],\n",
    "    how=\"outer\",\n",
    ").fillna(0.0)\n",
    "\n",
    "print(f\"作成したプログレッシブ系特徴量: {progressive_features.shape}\")\n",
    "display(progressive_features.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習型 xT (Expected Threat) 特徴量\n",
    "print(\"学習型xT (value iteration) 特徴量を計算中...\")\n",
    "\n",
    "# グリッド定義 (16x12)\n",
    "GRID_X_EDGES = np.linspace(0, 105, 17)\n",
    "GRID_Y_EDGES = np.linspace(0, 68, 13)\n",
    "NUM_X = len(GRID_X_EDGES) - 1\n",
    "NUM_Y = len(GRID_Y_EDGES) - 1\n",
    "NUM_ZONES = NUM_X * NUM_Y\n",
    "\n",
    "def map_to_zone(x_array: np.ndarray, y_array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Map coordinates to xT grid zone indices (0-191).\"\"\"\n",
    "    x_idx = np.clip(np.digitize(x_array, GRID_X_EDGES) - 1, 0, NUM_X - 1)\n",
    "    y_idx = np.clip(np.digitize(y_array, GRID_Y_EDGES) - 1, 0, NUM_Y - 1)\n",
    "    return (y_idx * NUM_X + x_idx).astype(int)\n",
    "\n",
    "# 利用するアクション種別\n",
    "distribution_actions = {\n",
    "    \"pass\", \"cross\", \"throw_in\", \"corner_crossed\", \"freekick_crossed\",\n",
    "    \"carry\", \"take_on\", \"dribble\", \"goal_kick\", \"clearance\"\n",
    "}\n",
    "shot_actions = {\"shot\", \"shot_penalty\", \"shot_freekick\"}\n",
    "\n",
    "# 学習用xTはtrainのアクションのみを使用（リーク防止）\n",
    "train_match_ids_xt = set(train_df[\"match_id\"])\n",
    "train_actions = relevant_actions[relevant_actions[\"match_id\"].isin(train_match_ids_xt)].copy()\n",
    "\n",
    "# 座標欠損をゼロ埋めしてゾーン算出用に準備（trainのみ）\n",
    "start_x_train = train_actions[\"start_x\"].fillna(0).to_numpy()\n",
    "start_y_train = train_actions[\"start_y\"].fillna(0).to_numpy()\n",
    "start_zones_train = map_to_zone(start_x_train, start_y_train)\n",
    "\n",
    "transition_counts = np.zeros((NUM_ZONES, NUM_ZONES), dtype=np.float64)\n",
    "shot_counts = np.zeros(NUM_ZONES, dtype=np.float64)\n",
    "goal_counts = np.zeros(NUM_ZONES, dtype=np.float64)\n",
    "ball_loss_counts = np.zeros(NUM_ZONES, dtype=np.float64)\n",
    "\n",
    "# ショット関連統計（trainのみ）\n",
    "shot_mask_train = train_actions[\"type_name\"].isin(shot_actions)\n",
    "if shot_mask_train.any():\n",
    "    shot_zones_train = start_zones_train[shot_mask_train.to_numpy()]\n",
    "    shot_counts += np.bincount(shot_zones_train, minlength=NUM_ZONES)\n",
    "    goal_flags_train = train_actions.loc[shot_mask_train, \"result_name\"].eq(\"success\").to_numpy(dtype=np.float64)\n",
    "    goal_counts += np.bincount(shot_zones_train, weights=goal_flags_train, minlength=NUM_ZONES)\n",
    "\n",
    "# パス・キャリー等のポゼッション遷移統計（trainのみ）\n",
    "move_mask_train = train_actions[\"type_name\"].isin(distribution_actions)\n",
    "if move_mask_train.any():\n",
    "    move_actions_train = train_actions.loc[move_mask_train].copy()\n",
    "    move_start_zones_train = map_to_zone(\n",
    "        move_actions_train[\"start_x\"].fillna(0).to_numpy(),\n",
    "        move_actions_train[\"start_y\"].fillna(0).to_numpy(),\n",
    "    )\n",
    "    move_success_train = move_actions_train[\"result_name\"].eq(\"success\").to_numpy()\n",
    "\n",
    "    if (~move_success_train).any():\n",
    "        ball_loss_counts += np.bincount(move_start_zones_train[~move_success_train], minlength=NUM_ZONES)\n",
    "\n",
    "    valid_success_idx_train = move_success_train & move_actions_train[\"end_x\"].notna().to_numpy() & move_actions_train[\"end_y\"].notna().to_numpy()\n",
    "    if valid_success_idx_train.any():\n",
    "        success_start_zones_train = move_start_zones_train[valid_success_idx_train]\n",
    "        success_end_zones_train = map_to_zone(\n",
    "            move_actions_train.loc[valid_success_idx_train, \"end_x\"].to_numpy(),\n",
    "            move_actions_train.loc[valid_success_idx_train, \"end_y\"].to_numpy(),\n",
    "        )\n",
    "        np.add.at(transition_counts, (success_start_zones_train, success_end_zones_train), 1.0)\n",
    "\n",
    "# xT価値反復（train統計で推定）\n",
    "transition_totals = transition_counts.sum(axis=1)\n",
    "total_counts = transition_totals + shot_counts + ball_loss_counts\n",
    "safe_totals = np.where(total_counts == 0, 1.0, total_counts)\n",
    "\n",
    "transition_probs = np.divide(\n",
    "    transition_counts,\n",
    "    safe_totals[:, None],\n",
    "    out=np.zeros_like(transition_counts),\n",
    "    where=safe_totals[:, None] > 0,\n",
    ")\n",
    "shot_prob = shot_counts / safe_totals\n",
    "goal_given_shot = np.divide(\n",
    "    goal_counts,\n",
    "    shot_counts,\n",
    "    out=np.zeros_like(goal_counts),\n",
    "    where=shot_counts > 0,\n",
    ")\n",
    "immediate_reward = shot_prob * goal_given_shot\n",
    "\n",
    "gamma = 0.95\n",
    "xt_values = immediate_reward.copy()\n",
    "max_iterations = 500\n",
    "for iteration in range(max_iterations):\n",
    "    updated = immediate_reward + gamma * transition_probs.dot(xt_values)\n",
    "    max_delta = np.max(np.abs(updated - xt_values))\n",
    "    xt_values = updated\n",
    "    if max_delta < 1e-6:\n",
    "        break\n",
    "else:\n",
    "    iteration += 1  # 収束しなかった場合のインジケータ\n",
    "\n",
    "print(f\"学習型xT value iteration: {iteration + 1} step(s), max_delta={max_delta:.2e}\")\n",
    "print(f\"xT値の範囲: min={xt_values.min():.5f}, max={xt_values.max():.5f}\")\n",
    "\n",
    "# アクションベースのxT特徴量付与（trainで学習したxt_valuesを全行へ適用）\n",
    "# 全行（train+test）の開始ゾーンを算出\n",
    "start_x_all = relevant_actions[\"start_x\"].fillna(0).to_numpy()\n",
    "start_y_all = relevant_actions[\"start_y\"].fillna(0).to_numpy()\n",
    "start_zones_all = map_to_zone(start_x_all, start_y_all)\n",
    "\n",
    "end_x = relevant_actions[\"end_x\"].to_numpy()\n",
    "end_y = relevant_actions[\"end_y\"].to_numpy()\n",
    "has_end_coords = np.isfinite(end_x) & np.isfinite(end_y)\n",
    "end_zones_all = np.zeros(len(relevant_actions), dtype=int)\n",
    "if has_end_coords.any():\n",
    "    end_zones_all[has_end_coords] = map_to_zone(end_x[has_end_coords], end_y[has_end_coords])\n",
    "\n",
    "start_values = xt_values[start_zones_all]\n",
    "end_values = np.zeros(len(relevant_actions), dtype=np.float64)\n",
    "end_values[has_end_coords] = xt_values[end_zones_all[has_end_coords]]\n",
    "\n",
    "success_flag = relevant_actions[\"result_name\"].eq(\"success\").astype(int).to_numpy()\n",
    "end_values_on_success = np.where(success_flag == 1, end_values, 0.0)\n",
    "\n",
    "relevant_actions[\"xt_learned_start\"] = start_values\n",
    "relevant_actions[\"xt_learned_end\"] = end_values\n",
    "relevant_actions[\"xt_learned_delta\"] = end_values_on_success - start_values\n",
    "relevant_actions[\"xt_learned_positive_delta\"] = np.clip(relevant_actions[\"xt_learned_delta\"], 0.0, None)\n",
    "relevant_actions[\"xt_learned_success\"] = success_flag\n",
    "relevant_actions[\"xt_learned_end_on_success\"] = np.where(success_flag == 1, end_values, np.nan)\n",
    "relevant_actions[\"xt_learned_delta_on_success\"] = np.where(success_flag == 1, relevant_actions[\"xt_learned_delta\"], np.nan)\n",
    "\n",
    "xt_learned_features = (\n",
    "    relevant_actions.groupby([\"match_id\", \"player_id\"])\n",
    "    .agg(\n",
    "        xt_learned_start_mean=(\"xt_learned_start\", \"mean\"),\n",
    "        xt_learned_start_max=(\"xt_learned_start\", \"max\"),\n",
    "        xt_learned_delta_sum=(\"xt_learned_delta\", \"sum\"),\n",
    "        xt_learned_delta_mean=(\"xt_learned_delta\", \"mean\"),\n",
    "        xt_learned_positive_delta_sum=(\"xt_learned_positive_delta\", \"sum\"),\n",
    "        xt_learned_positive_delta_mean=(\"xt_learned_positive_delta\", \"mean\"),\n",
    "        xt_learned_success_rate=(\"xt_learned_success\", \"mean\"),\n",
    "        xt_learned_action_count=(\"xt_learned_success\", \"count\"),\n",
    "        xt_learned_end_success_mean=(\"xt_learned_end_on_success\", \"mean\"),\n",
    "        xt_learned_delta_success_mean=(\"xt_learned_delta_on_success\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "xt_learned_feature_cols = [col for col in xt_learned_features.columns if col not in {\"match_id\", \"player_id\"}]\n",
    "\n",
    "train_df = train_df.merge(xt_learned_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "test_df = test_df.merge(xt_learned_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "\n",
    "train_df[xt_learned_feature_cols] = train_df[xt_learned_feature_cols].fillna(0.0)\n",
    "test_df[xt_learned_feature_cols] = test_df[xt_learned_feature_cols].fillna(0.0)\n",
    "\n",
    "train_df[\"xt_learned_action_count\"] = train_df[\"xt_learned_action_count\"].astype(int)\n",
    "test_df[\"xt_learned_action_count\"] = test_df[\"xt_learned_action_count\"].astype(int)\n",
    "\n",
    "print(\"学習型xT特徴量（サンプル）:\")\n",
    "display(xt_learned_features.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321279ba",
   "metadata": {
    "id": "hHxhgz7ypDWn"
   },
   "source": [
    "## Possession-Level Progression Features\n",
    "\n",
    "Learned xT highlights forward threat, so we aggregate possession speed and directness as complementary signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2f6d8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Calculating possession progression features...\")\n",
    "\n",
    "pos_actions = (\n",
    "    relevant_actions\n",
    "    .reset_index(drop=False)\n",
    "    .sort_values([\"match_id\", \"period_id\", \"time_seconds\", \"index\"], kind=\"mergesort\")\n",
    "    .rename(columns={\"index\": \"action_index\"})\n",
    "    .copy()\n",
    ")\n",
    "pos_actions[\"time_seconds\"] = pos_actions[\"time_seconds\"].fillna(0.0)\n",
    "pos_actions[\"team_id\"] = pos_actions[\"team_id\"].fillna(\"unknown_team\")\n",
    "pos_actions[\"new_match\"] = pos_actions[\"match_id\"].ne(pos_actions[\"match_id\"].shift())\n",
    "pos_actions[\"same_team_prev\"] = pos_actions[\"team_id\"].eq(pos_actions[\"team_id\"].shift())\n",
    "pos_actions[\"prev_success\"] = pos_actions[\"result_name\"].shift().eq(\"success\")\n",
    "pos_actions[\"time_diff\"] = pos_actions.groupby(\"match_id\")[\"time_seconds\"].diff().fillna(0.0)\n",
    "pos_actions[\"new_possession\"] = (\n",
    "    pos_actions[\"new_match\"]\n",
    "    | (~pos_actions[\"same_team_prev\"].fillna(False))\n",
    "    | (~pos_actions[\"prev_success\"].fillna(True))\n",
    "    | (pos_actions[\"time_diff\"] > 15.0)\n",
    ")\n",
    "pos_actions.loc[pos_actions.index[0], \"new_possession\"] = True\n",
    "pos_actions[\"possession_id\"] = pos_actions[\"new_possession\"].cumsum().astype(int)\n",
    "pos_actions[\"possession_event_index\"] = pos_actions.groupby(\"possession_id\").cumcount() + 1\n",
    "\n",
    "pos_group = pos_actions.groupby(\"possession_id\").agg(\n",
    "    match_id=(\"match_id\", \"first\"),\n",
    "    team_id=(\"team_id\", \"first\"),\n",
    "    start_x=(\"start_x\", \"first\"),\n",
    "    start_y=(\"start_y\", \"first\"),\n",
    "    end_x=(\"end_x\", \"last\"),\n",
    "    end_y=(\"end_y\", \"last\"),\n",
    "    start_time=(\"time_seconds\", \"first\"),\n",
    "    end_time=(\"time_seconds\", \"last\"),\n",
    "    action_count=(\"player_id\", \"count\"),\n",
    "    unique_players=(\"player_id\", \"nunique\"),\n",
    "    xt_positive_sum=(\"xt_learned_positive_delta\", \"sum\"),\n",
    "    xt_delta_sum=(\"xt_learned_delta\", \"sum\"),\n",
    ").reset_index()\n",
    "\n",
    "pos_group[\"duration\"] = (pos_group[\"end_time\"] - pos_group[\"start_time\"]).clip(lower=1.0)\n",
    "pos_group[\"delta_x\"] = pos_group[\"end_x\"] - pos_group[\"start_x\"]\n",
    "pos_group[\"delta_y\"] = pos_group[\"end_y\"] - pos_group[\"start_y\"]\n",
    "pos_group[\"ground_distance\"] = np.sqrt(np.square(pos_group[\"delta_x\"]) + np.square(pos_group[\"delta_y\"]))\n",
    "pos_group[\"directness\"] = np.divide(\n",
    "    pos_group[\"delta_x\"],\n",
    "    pos_group[\"ground_distance\"],\n",
    "    out=np.zeros_like(pos_group[\"delta_x\"]),\n",
    "    where=pos_group[\"ground_distance\"] > 0,\n",
    ")\n",
    "pos_group[\"speed_x\"] = pos_group[\"delta_x\"] / pos_group[\"duration\"]\n",
    "pos_group[\"speed_ground\"] = pos_group[\"ground_distance\"] / pos_group[\"duration\"]\n",
    "pos_group[\"xt_positive_per_second\"] = np.divide(\n",
    "    pos_group[\"xt_positive_sum\"],\n",
    "    pos_group[\"duration\"],\n",
    "    out=np.zeros_like(pos_group[\"xt_positive_sum\"]),\n",
    "    where=pos_group[\"duration\"] > 0,\n",
    ")\n",
    "\n",
    "final_third_threshold = 70.0\n",
    "final_third_steps = (\n",
    "    pos_actions[pos_actions[\"end_x\"].ge(final_third_threshold)]\n",
    "    .groupby(\"possession_id\")[\"possession_event_index\"]\n",
    "    .min()\n",
    ")\n",
    "final_third_times = (\n",
    "    pos_actions[pos_actions[\"end_x\"].ge(final_third_threshold)]\n",
    "    .groupby(\"possession_id\")[\"time_seconds\"]\n",
    "    .min()\n",
    ")\n",
    "pos_group[\"final_third_entry_step\"] = pos_group[\"possession_id\"].map(final_third_steps)\n",
    "pos_group[\"final_third_entry_flag\"] = pos_group[\"final_third_entry_step\"].notna().astype(float)\n",
    "pos_group[\"final_third_entry_time\"] = pos_group[\"possession_id\"].map(final_third_times)\n",
    "pos_group[\"time_to_final_third\"] = (\n",
    "    pos_group[\"final_third_entry_time\"] - pos_group[\"start_time\"]\n",
    ").where(pos_group[\"final_third_entry_flag\"] > 0)\n",
    "\n",
    "pos_player = (\n",
    "    pos_actions[[\"match_id\", \"player_id\", \"possession_id\"]]\n",
    "    .drop_duplicates()\n",
    "    .merge(\n",
    "        pos_group[[\n",
    "            \"possession_id\",\n",
    "            \"duration\",\n",
    "            \"ground_distance\",\n",
    "            \"directness\",\n",
    "            \"speed_x\",\n",
    "            \"speed_ground\",\n",
    "            \"xt_positive_per_second\",\n",
    "            \"xt_positive_sum\",\n",
    "            \"xt_delta_sum\",\n",
    "            \"action_count\",\n",
    "            \"final_third_entry_flag\",\n",
    "            \"final_third_entry_step\",\n",
    "            \"time_to_final_third\",\n",
    "        ]],\n",
    "        on=\"possession_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n",
    "\n",
    "player_pos_features = pos_player.groupby([\"match_id\", \"player_id\"]).agg(\n",
    "    possession_count=(\"possession_id\", \"nunique\"),\n",
    "    possession_duration_mean=(\"duration\", \"mean\"),\n",
    "    possession_ground_distance_mean=(\"ground_distance\", \"mean\"),\n",
    "    possession_directness_mean=(\"directness\", \"mean\"),\n",
    "    possession_speed_x_mean=(\"speed_x\", \"mean\"),\n",
    "    possession_speed_ground_mean=(\"speed_ground\", \"mean\"),\n",
    "    possession_xt_positive_per_second_mean=(\"xt_positive_per_second\", \"mean\"),\n",
    "    possession_xt_positive_sum=(\"xt_positive_sum\", \"sum\"),\n",
    "    possession_xt_delta_sum=(\"xt_delta_sum\", \"sum\"),\n",
    "    possession_actions_per_pos_mean=(\"action_count\", \"mean\"),\n",
    "    possession_final_third_rate=(\"final_third_entry_flag\", \"mean\"),\n",
    "    possession_final_third_step_mean=(\"final_third_entry_step\", \"mean\"),\n",
    "    possession_time_to_final_third_mean=(\"time_to_final_third\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "possession_feature_cols = [\n",
    "    col for col in player_pos_features.columns if col not in {\"match_id\", \"player_id\"}\n",
    "]\n",
    "numeric_possession_cols = [col for col in possession_feature_cols if col != \"possession_count\"]\n",
    "\n",
    "train_df = train_df.merge(player_pos_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "test_df = test_df.merge(player_pos_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "\n",
    "train_df[\"possession_count\"] = train_df[\"possession_count\"].fillna(0).astype(int)\n",
    "test_df[\"possession_count\"] = test_df[\"possession_count\"].fillna(0).astype(int)\n",
    "\n",
    "if numeric_possession_cols:\n",
    "    train_df[numeric_possession_cols] = train_df[numeric_possession_cols].fillna(0.0)\n",
    "    test_df[numeric_possession_cols] = test_df[numeric_possession_cols].fillna(0.0)\n",
    "\n",
    "print(\"Possession progression features added:\", len(possession_feature_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1329ad",
   "metadata": {},
   "source": [
    "## Pass Network Features\n",
    "\n",
    "Network-centric statistics to capture player roles within possession flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5600a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Calculating pass network features...\")\n",
    "\n",
    "sorted_actions = (\n",
    "    relevant_actions\n",
    "    .reset_index(drop=False)\n",
    "    .sort_values([\"match_id\", \"period_id\", \"time_seconds\", \"index\"], kind=\"mergesort\")\n",
    "    .rename(columns={\"index\": \"action_index\"})\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "sorted_actions[\"next_player_id\"] = sorted_actions.groupby(\"match_id\")[\"player_id\"].shift(-1)\n",
    "sorted_actions[\"next_team_id\"] = sorted_actions.groupby(\"match_id\")[\"team_id\"].shift(-1)\n",
    "\n",
    "success_pass_mask = (\n",
    "    (sorted_actions[\"type_name\"] == \"pass\")\n",
    "    & sorted_actions[\"result_name\"].eq(\"success\")\n",
    "    & sorted_actions[\"next_team_id\"].notna()\n",
    "    & sorted_actions[\"next_team_id\"].eq(sorted_actions[\"team_id\"])\n",
    ")\n",
    "\n",
    "pass_edges = sorted_actions.loc[success_pass_mask, [\n",
    "    \"match_id\",\n",
    "    \"team_id\",\n",
    "    \"player_id\",\n",
    "    \"next_player_id\",\n",
    "    \"start_x\",\n",
    "    \"start_y\",\n",
    "    \"end_x\",\n",
    "    \"end_y\"\n",
    "]].copy()\n",
    "\n",
    "pass_edges = pass_edges.dropna(subset=[\"player_id\", \"next_player_id\"])\n",
    "pass_edges[\"player_id\"] = pass_edges[\"player_id\"].astype(str)\n",
    "pass_edges[\"next_player_id\"] = pass_edges[\"next_player_id\"].astype(str)\n",
    "\n",
    "pass_edges[\"pass_distance\"] = np.sqrt(\n",
    "    (pass_edges[\"end_x\"] - pass_edges[\"start_x\"]) ** 2 +\n",
    "    (pass_edges[\"end_y\"] - pass_edges[\"start_y\"]) ** 2\n",
    ")\n",
    "pass_edges[\"lateral_shift\"] = pass_edges[\"end_y\"] - pass_edges[\"start_y\"]\n",
    "pass_edges[\"switch_flag\"] = pass_edges[\"lateral_shift\"].abs() >= 20.0\n",
    "\n",
    "player_edge_stats = (\n",
    "    pass_edges.groupby([\"match_id\", \"player_id\"])\n",
    "    .agg(\n",
    "        pass_net_attempts=(\"next_player_id\", \"count\"),\n",
    "        pass_net_avg_distance=(\"pass_distance\", \"mean\"),\n",
    "        pass_net_switch_rate=(\"switch_flag\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "receiver_stats = (\n",
    "    pass_edges.groupby([\"match_id\", \"next_player_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"pass_net_receive_count\")\n",
    "    .rename(columns={\"next_player_id\": \"player_id\"})\n",
    ")\n",
    "\n",
    "centrality_records = []\n",
    "for (match_id, team_id), group in pass_edges.groupby([\"match_id\", \"team_id\"]):\n",
    "    players = set(group[\"player_id\"]) | set(group[\"next_player_id\"])\n",
    "    if not players:\n",
    "        continue\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    for src, tgt in group[[\"player_id\", \"next_player_id\"]].itertuples(index=False):\n",
    "        if G.has_edge(src, tgt):\n",
    "            G[src][tgt][\"weight\"] += 1.0\n",
    "        else:\n",
    "            G.add_edge(src, tgt, weight=1.0)\n",
    "\n",
    "    for node in players:\n",
    "        if node not in G:\n",
    "            G.add_node(node)\n",
    "\n",
    "    out_degree = dict(G.out_degree(weight=\"weight\"))\n",
    "    in_degree = dict(G.in_degree(weight=\"weight\"))\n",
    "    try:\n",
    "        betweenness = nx.betweenness_centrality(G, weight=\"weight\", normalized=True)\n",
    "    except Exception:\n",
    "        betweenness = {node: 0.0 for node in players}\n",
    "\n",
    "    undirected = G.to_undirected()\n",
    "    if undirected.number_of_edges() > 0:\n",
    "        clustering = nx.clustering(undirected, weight=\"weight\")\n",
    "    else:\n",
    "        clustering = {node: 0.0 for node in players}\n",
    "\n",
    "    for node in players:\n",
    "        centrality_records.append({\n",
    "            \"match_id\": match_id,\n",
    "            \"player_id\": node,\n",
    "            \"pass_net_out_degree\": out_degree.get(node, 0.0),\n",
    "            \"pass_net_in_degree\": in_degree.get(node, 0.0),\n",
    "            \"pass_net_betweenness\": betweenness.get(node, 0.0),\n",
    "            \"pass_net_clustering\": clustering.get(node, 0.0),\n",
    "        })\n",
    "\n",
    "centrality_df = pd.DataFrame(centrality_records)\n",
    "if centrality_df.empty:\n",
    "    centrality_df = pd.DataFrame(columns=[\n",
    "        \"match_id\",\n",
    "        \"player_id\",\n",
    "        \"pass_net_out_degree\",\n",
    "        \"pass_net_in_degree\",\n",
    "        \"pass_net_betweenness\",\n",
    "        \"pass_net_clustering\",\n",
    "    ])\n",
    "\n",
    "if player_edge_stats.empty:\n",
    "    player_edge_stats = pd.DataFrame(columns=[\n",
    "        \"match_id\",\n",
    "        \"player_id\",\n",
    "        \"pass_net_attempts\",\n",
    "        \"pass_net_avg_distance\",\n",
    "        \"pass_net_switch_rate\",\n",
    "    ])\n",
    "\n",
    "if receiver_stats.empty:\n",
    "    receiver_stats = pd.DataFrame(columns=[\n",
    "        \"match_id\",\n",
    "        \"player_id\",\n",
    "        \"pass_net_receive_count\",\n",
    "    ])\n",
    "\n",
    "pass_network_features = (\n",
    "    centrality_df\n",
    "    .merge(player_edge_stats, on=[\"match_id\", \"player_id\"], how=\"outer\")\n",
    "    .merge(receiver_stats, on=[\"match_id\", \"player_id\"], how=\"outer\")\n",
    ")\n",
    "\n",
    "if not pass_network_features.empty:\n",
    "    numeric_cols = [\n",
    "        col for col in pass_network_features.columns\n",
    "        if col not in {\"match_id\", \"player_id\"}\n",
    "    ]\n",
    "    pass_network_features[numeric_cols] = pass_network_features[numeric_cols].fillna(0.0)\n",
    "\n",
    "pass_network_feature_cols = [\n",
    "    col for col in pass_network_features.columns if col not in {\"match_id\", \"player_id\"}\n",
    "]\n",
    "\n",
    "train_df = train_df.merge(pass_network_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "test_df = test_df.merge(pass_network_features, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "\n",
    "if pass_network_feature_cols:\n",
    "    train_df[pass_network_feature_cols] = train_df[pass_network_feature_cols].fillna(0.0)\n",
    "    test_df[pass_network_feature_cols] = test_df[pass_network_feature_cols].fillna(0.0)\n",
    "\n",
    "print(\"Pass network features added:\", len(pass_network_feature_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767dd03",
   "metadata": {},
   "source": [
    "\n",
    "## 行為タイプ別 eΔxT 特徴量\n",
    "\n",
    "学習済みxTに基づく空間価値と行為タイプ別の成功確率モデルを組み合わせ、リスク調整された期待xT増分 (eΔxT) を算出します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0712a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"行為タイプ別 xPass モデルを構築しています...\")\n",
    "\n",
    "xpass_action_groups = {\n",
    "    \"pass\": [\"pass\"],\n",
    "    \"cross\": [\"cross\"],\n",
    "    \"carry\": [\"carry\"],\n",
    "    \"dribble\": [\"dribble\", \"take_on\"],\n",
    "    \"free_kick\": [\"freekick_crossed\"],\n",
    "    \"corner\": [\"corner_crossed\"],\n",
    "}\n",
    "\n",
    "train_match_ids = set(train_df[\"match_id\"])\n",
    "\n",
    "if \"action_index\" not in relevant_actions.columns:\n",
    "    relevant_actions = relevant_actions.copy()\n",
    "    relevant_actions[\"action_index\"] = np.arange(len(relevant_actions))\n",
    "\n",
    "if \"xpass_prob\" not in relevant_actions.columns:\n",
    "    relevant_actions[\"xpass_prob\"] = np.nan\n",
    "if \"xpass_action_group\" not in relevant_actions.columns:\n",
    "    relevant_actions[\"xpass_action_group\"] = pd.NA\n",
    "\n",
    "relevant_actions[\"is_train_action\"] = relevant_actions[\"match_id\"].isin(train_match_ids)\n",
    "\n",
    "relevant_actions[\"end_x_filled\"] = relevant_actions[\"end_x\"].fillna(relevant_actions[\"start_x\"])\n",
    "relevant_actions[\"end_y_filled\"] = relevant_actions[\"end_y\"].fillna(relevant_actions[\"start_y\"])\n",
    "relevant_actions[\"delta_x\"] = (relevant_actions[\"end_x_filled\"] - relevant_actions[\"start_x\"]).fillna(0.0)\n",
    "relevant_actions[\"delta_y\"] = (relevant_actions[\"end_y_filled\"] - relevant_actions[\"start_y\"]).fillna(0.0)\n",
    "relevant_actions[\"distance\"] = np.hypot(relevant_actions[\"delta_x\"], relevant_actions[\"delta_y\"])\n",
    "relevant_actions[\"abs_delta_y\"] = relevant_actions[\"delta_y\"].abs()\n",
    "\n",
    "for col in [\"xt_learned_start\", \"xt_learned_delta\", \"xt_learned_positive_delta\"]:\n",
    "    if col in relevant_actions.columns:\n",
    "        relevant_actions[col] = relevant_actions[col].fillna(0.0)\n",
    "\n",
    "xpass_predictions = []\n",
    "xpass_training_summary = []\n",
    "xpass_calibration_records = []\n",
    "\n",
    "xpass_numeric_candidates = [\n",
    "    \"start_x\",\n",
    "    \"start_y\",\n",
    "    \"end_x_filled\",\n",
    "    \"end_y_filled\",\n",
    "    \"delta_x\",\n",
    "    \"delta_y\",\n",
    "    \"distance\",\n",
    "    \"abs_delta_y\",\n",
    "    \"time_seconds\",\n",
    "    \"minutes_played\",\n",
    "    \"period_id\",\n",
    "    \"is_home\",\n",
    "    \"xt_learned_start\",\n",
    "    \"xt_learned_delta\",\n",
    "    \"xt_learned_positive_delta\",\n",
    "]\n",
    "\n",
    "xpass_categorical_candidates = [\n",
    "    \"team_name_short\",\n",
    "    \"bodypart_name\",\n",
    "    \"competition\",\n",
    "    \"match_venue\",\n",
    "]\n",
    "\n",
    "for action_group, action_names in xpass_action_groups.items():\n",
    "    subset_idx = relevant_actions[\"type_name\"].isin(action_names)\n",
    "    action_subset = relevant_actions.loc[subset_idx].copy()\n",
    "\n",
    "    if action_subset.empty:\n",
    "        continue\n",
    "\n",
    "    action_subset[\"is_success\"] = action_subset[\"result_name\"].eq(\"success\").astype(int)\n",
    "    action_subset[\"is_home\"] = action_subset[\"is_home\"].fillna(False).astype(int)\n",
    "\n",
    "    numeric_candidates_local = list(xpass_numeric_candidates)\n",
    "    if \"is_starter\" in action_subset.columns:\n",
    "        action_subset[\"is_starter\"] = action_subset[\"is_starter\"].fillna(False).astype(int)\n",
    "        numeric_candidates_local.append(\"is_starter\")\n",
    "\n",
    "    if \"minutes_played\" in action_subset.columns:\n",
    "        action_subset[\"minutes_played\"] = action_subset[\"minutes_played\"].fillna(0.0)\n",
    "\n",
    "    categorical_features = [col for col in xpass_categorical_candidates if col in action_subset.columns]\n",
    "    for col in categorical_features:\n",
    "        action_subset[col] = action_subset[col].fillna(\"missing\").astype(\"category\")\n",
    "\n",
    "    numeric_features = [col for col in numeric_candidates_local if col in action_subset.columns]\n",
    "    used_features = numeric_features + categorical_features\n",
    "\n",
    "    train_subset = action_subset[action_subset[\"is_train_action\"]].copy()\n",
    "    test_subset = action_subset[~action_subset[\"is_train_action\"]].copy()\n",
    "\n",
    "    if train_subset.empty or train_subset[\"match_id\"].nunique() < 2:\n",
    "        fallback = float(train_subset[\"is_success\"].mean()) if len(train_subset) else 0.5\n",
    "        fallback = float(np.clip(fallback, 1e-4, 1 - 1e-4))\n",
    "        action_subset.loc[train_subset.index, \"xpass_prob\"] = fallback\n",
    "        action_subset.loc[test_subset.index, \"xpass_prob\"] = fallback\n",
    "        action_subset[\"xpass_action_group\"] = action_group\n",
    "        relevant_actions.loc[action_subset.index, \"xpass_prob\"] = action_subset[\"xpass_prob\"]\n",
    "        relevant_actions.loc[action_subset.index, \"xpass_action_group\"] = action_subset[\"xpass_action_group\"]\n",
    "        xpass_predictions.append(\n",
    "            action_subset[\n",
    "                [\n",
    "                    \"match_id\",\n",
    "                    \"player_id\",\n",
    "                    \"action_index\",\n",
    "                    \"xpass_action_group\",\n",
    "                    \"xpass_prob\",\n",
    "                    \"xt_learned_delta\",\n",
    "                    \"xt_learned_start\",\n",
    "                    \"is_train_action\",\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "        xpass_training_summary.append(\n",
    "            {\n",
    "                \"action_type\": action_group,\n",
    "                \"train_actions\": len(train_subset),\n",
    "                \"test_actions\": len(test_subset),\n",
    "                \"success_rate\": float(train_subset[\"is_success\"].mean()) if len(train_subset) else np.nan,\n",
    "            }\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    n_splits = min(5, max(2, train_subset[\"match_id\"].nunique()))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"num_leaves\": 25,\n",
    "        \"feature_fraction\": 0.7,\n",
    "        \"bagging_fraction\": 0.7,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"min_data_in_leaf\": 64,\n",
    "        \"min_gain_to_split\": 0.01,\n",
    "        \"lambda_l1\": 0.1,\n",
    "        \"lambda_l2\": 0.1,\n",
    "        \"seed\": SEED,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    oof_preds = np.zeros(len(train_subset), dtype=float)\n",
    "    test_preds = np.zeros(len(test_subset), dtype=float) if len(test_subset) else None\n",
    "    models = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(gkf.split(train_subset, groups=train_subset[\"match_id\"])):\n",
    "        X_tr = train_subset.iloc[tr_idx][used_features]\n",
    "        y_tr = train_subset.iloc[tr_idx][\"is_success\"]\n",
    "        X_val = train_subset.iloc[val_idx][used_features]\n",
    "        y_val = train_subset.iloc[val_idx][\"is_success\"]\n",
    "\n",
    "        train_ds = lgb.Dataset(\n",
    "            X_tr,\n",
    "            label=y_tr,\n",
    "            categorical_feature=categorical_features or None,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "        val_ds = lgb.Dataset(\n",
    "            X_val,\n",
    "            label=y_val,\n",
    "            reference=train_ds,\n",
    "            categorical_feature=categorical_features or None,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_ds,\n",
    "            valid_sets=[val_ds],\n",
    "            num_boost_round=800,\n",
    "            callbacks=[lgb.early_stopping(80), lgb.log_evaluation(0)],\n",
    "        )\n",
    "        models.append(model)\n",
    "        fold_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        oof_preds[val_idx] = fold_pred\n",
    "        if len(test_subset):\n",
    "            test_preds += model.predict(test_subset[used_features], num_iteration=model.best_iteration)\n",
    "\n",
    "    if len(test_subset):\n",
    "        test_preds = test_preds / len(models)\n",
    "\n",
    "    # Plattスケーリングによるキャリブレーション（fold-aware to prevent leakage）\n",
    "    if len(np.unique(train_subset[\"is_success\"])) > 1:\n",
    "        try:\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "            # Fold-aware calibration for OOF predictions to prevent data leakage\n",
    "            calibrated_oof_preds = np.zeros(len(train_subset), dtype=float)\n",
    "            \n",
    "            for fold_idx, (tr_idx, val_idx) in enumerate(gkf.split(train_subset, groups=train_subset[\"match_id\"])):\n",
    "                # Fit calibration model on TRAINING fold only (exclude validation fold)\n",
    "                calib_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "                calib_model.fit(\n",
    "                    oof_preds[tr_idx].reshape(-1, 1),\n",
    "                    train_subset.iloc[tr_idx][\"is_success\"].to_numpy()\n",
    "                )\n",
    "                \n",
    "                # Apply calibration to VALIDATION fold\n",
    "                calibrated_oof_preds[val_idx] = calib_model.predict_proba(\n",
    "                    oof_preds[val_idx].reshape(-1, 1)\n",
    "                )[:, 1]\n",
    "            \n",
    "            oof_preds = calibrated_oof_preds\n",
    "            \n",
    "            # For test predictions: use ALL training data (this is correct)\n",
    "            if test_preds is not None:\n",
    "                final_calib = LogisticRegression(max_iter=1000, random_state=42)\n",
    "                final_calib.fit(oof_preds.reshape(-1, 1), train_subset[\"is_success\"].to_numpy())\n",
    "                test_preds = final_calib.predict_proba(test_preds.reshape(-1, 1))[:, 1]\n",
    "                \n",
    "        except Exception as exc:\n",
    "            print(f\"Calibration failed for {action_group}: {exc}\")\n",
    "\n",
    "    oof_preds = np.clip(oof_preds, 1e-4, 1 - 1e-4)\n",
    "    if len(test_subset):\n",
    "        test_preds = np.clip(test_preds, 1e-4, 1 - 1e-4)\n",
    "\n",
    "    train_mean = float(train_subset[\"is_success\"].mean()) if len(train_subset) else 0.5\n",
    "    fallback = float(np.clip(train_mean, 1e-4, 1 - 1e-4))\n",
    "\n",
    "    action_subset.loc[train_subset.index, \"xpass_prob\"] = oof_preds\n",
    "    if len(test_subset):\n",
    "        action_subset.loc[test_subset.index, \"xpass_prob\"] = test_preds\n",
    "    else:\n",
    "        action_subset.loc[test_subset.index, \"xpass_prob\"] = fallback\n",
    "\n",
    "    action_subset[\"xpass_action_group\"] = action_group\n",
    "\n",
    "    relevant_actions.loc[action_subset.index, \"xpass_prob\"] = action_subset[\"xpass_prob\"]\n",
    "    relevant_actions.loc[action_subset.index, \"xpass_action_group\"] = action_subset[\"xpass_action_group\"]\n",
    "\n",
    "    xpass_predictions.append(\n",
    "        action_subset[\n",
    "            [\n",
    "                \"match_id\",\n",
    "                \"player_id\",\n",
    "                \"action_index\",\n",
    "                \"xpass_action_group\",\n",
    "                \"xpass_prob\",\n",
    "                \"xt_learned_delta\",\n",
    "                \"xt_learned_start\",\n",
    "                \"is_train_action\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    xpass_training_summary.append(\n",
    "        {\n",
    "            \"action_type\": action_group,\n",
    "            \"train_actions\": len(train_subset),\n",
    "            \"test_actions\": len(test_subset),\n",
    "            \"success_rate\": float(train_subset[\"is_success\"].mean()) if len(train_subset) else np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    cal_df = train_subset[[\"is_success\"]].copy()\n",
    "    cal_df[\"pred\"] = oof_preds\n",
    "    cal_df[\"action_type\"] = action_group\n",
    "    try:\n",
    "        unique_pred = np.unique(np.round(cal_df[\"pred\"], 6))\n",
    "        n_bins = min(10, max(4, len(unique_pred)))\n",
    "        cal_df[\"bucket\"] = pd.qcut(cal_df[\"pred\"], q=n_bins, duplicates=\"drop\")\n",
    "        agg = cal_df.groupby([\"action_type\", \"bucket\"], observed=True).agg(\n",
    "            pred_mean=(\"pred\", \"mean\"),\n",
    "            success_rate=(\"is_success\", \"mean\"),\n",
    "            count=(\"is_success\", \"size\"),\n",
    "        ).reset_index()\n",
    "        xpass_calibration_records.append(agg)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "if xpass_predictions:\n",
    "    xpass_predictions_df = pd.concat(xpass_predictions, ignore_index=True)\n",
    "else:\n",
    "    xpass_predictions_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"match_id\",\n",
    "            \"player_id\",\n",
    "            \"action_index\",\n",
    "            \"xpass_action_group\",\n",
    "            \"xpass_prob\",\n",
    "            \"xt_learned_delta\",\n",
    "            \"xt_learned_start\",\n",
    "            \"is_train_action\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "xpass_training_summary_df = pd.DataFrame(xpass_training_summary)\n",
    "if not xpass_training_summary_df.empty:\n",
    "    display(xpass_training_summary_df.sort_values(\"action_type\"))\n",
    "\n",
    "if xpass_calibration_records:\n",
    "    calibration_df = pd.concat(xpass_calibration_records, ignore_index=True)\n",
    "    display(calibration_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122cff23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "nzaeWhMpbDlr",
    "outputId": "f99d35a4-fc96-4bcc-f176-50c7235075ef"
   },
   "outputs": [],
   "source": [
    "# 5分割のGroupKFoldを設定（match_idでグループ化）\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "train_df[\"fold\"] = 0  # 0で初期化\n",
    "\n",
    "# xAG軸のスケールは共通化して見やすくする\n",
    "x_min, x_max = train_df[\"xAG\"].min(), train_df[\"xAG\"].max()\n",
    "xAG_vals = np.arange(x_min, x_max + 0.1, 0.1).round(1)\n",
    "\n",
    "# 図: 各foldごとに 3カラム（Train分布, Val分布, match_idベン図）\n",
    "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(18, 18), sharey=False, sharex=False)\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=train_df[\"match_id\"])):\n",
    "    # fold列をセット\n",
    "    train_df.loc[val_idx, \"fold\"] = i + 1\n",
    "\n",
    "    # train/val の xAG 分布を取得（共通スケールにリインデックス）\n",
    "    trn_counts = (\n",
    "        train_df.iloc[trn_idx][\"xAG\"].value_counts().sort_index()\n",
    "        .reindex(xAG_vals, fill_value=0)\n",
    "    )\n",
    "    val_counts = (\n",
    "        train_df.iloc[val_idx][\"xAG\"].value_counts().sort_index()\n",
    "        .reindex(xAG_vals, fill_value=0)\n",
    "    )\n",
    "\n",
    "    # 左列: 各foldのtrainデータ分布\n",
    "    ax_train = axes[i, 0]\n",
    "    ax_train.bar(trn_counts.index, trn_counts.values, width=0.08, color=\"steelblue\")\n",
    "    ax_train.set_title(f\"Fold {i+1} - Train xAG 分布\")\n",
    "    ax_train.set_xlabel(\"xAG\")\n",
    "    ax_train.set_ylabel(\"頻度\")\n",
    "\n",
    "    # 中列: 各foldのvalidationデータ分布\n",
    "    ax_val = axes[i, 1]\n",
    "    ax_val.bar(val_counts.index, val_counts.values, width=0.08, color=\"orange\")\n",
    "    ax_val.set_title(f\"Fold {i+1} - Val xAG 分布\")\n",
    "    ax_val.set_xlabel(\"xAG\")\n",
    "    ax_val.set_ylabel(\"頻度\")\n",
    "\n",
    "    # 右列: match_idのベン図（Train vs Val）\n",
    "    ax_venn = axes[i, 2]\n",
    "    trn_match_ids = set(train_df.iloc[trn_idx][\"match_id\"])\n",
    "    val_match_ids = set(train_df.iloc[val_idx][\"match_id\"])\n",
    "    v = venn2(\n",
    "        [trn_match_ids, val_match_ids],\n",
    "        set_labels=(f\"Train match_id (n={len(trn_match_ids)})\",\n",
    "                    f\"Val match_id (n={len(val_match_ids)})\"),\n",
    "        ax=ax_venn\n",
    "    )\n",
    "    ax_venn.set_title(f\"Fold {i+1} - match_id の重なり\")\n",
    "\n",
    "# x軸を共通スケールに揃える（分布図の2カラムに適用）\n",
    "for i in range(5):\n",
    "    for j in [0, 1]:\n",
    "        ax = axes[i, j]\n",
    "        ax.set_xlim(x_min - 0.05, x_max + 0.05)  # 端を少し余裕持たせる\n",
    "        ax.set_xticks(xAG_vals[::2])  # ラベルの数を間引き\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27262c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"eΔxTのλ最適化と特徴量集約を実行中...\")\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "edxt_feature_cols = []\n",
    "\n",
    "if xpass_predictions_df.empty:\n",
    "    print(\"xPassの対象アクションが存在しないため、eΔxT特徴量は追加されません。\")\n",
    "else:\n",
    "    xpass_predictions_df = xpass_predictions_df.copy()\n",
    "    xpass_predictions_df[\"xt_learned_delta\"] = xpass_predictions_df[\"xt_learned_delta\"].fillna(0.0)\n",
    "    xpass_predictions_df[\"xt_learned_start\"] = xpass_predictions_df[\"xt_learned_start\"].fillna(0.0)\n",
    "    xpass_predictions_df[\"success_component\"] = xpass_predictions_df[\"xpass_prob\"] * xpass_predictions_df[\"xt_learned_delta\"]\n",
    "    xpass_predictions_df[\"fail_component_raw\"] = (1.0 - xpass_predictions_df[\"xpass_prob\"]) * xpass_predictions_df[\"xt_learned_start\"]\n",
    "    xpass_predictions_df[\"fail_weight\"] = (1.0 - xpass_predictions_df[\"xpass_prob\"]).fillna(0.0)\n",
    "    train_actions = xpass_predictions_df[xpass_predictions_df[\"is_train_action\"]].copy()\n",
    "    global_start_mean = float(train_actions[\"xt_learned_start\"].mean()) if not train_actions.empty else 0.0\n",
    "    global_start_std = float(train_actions[\"xt_learned_start\"].std(ddof=0)) if not train_actions.empty else 0.0\n",
    "    if global_start_std < 1e-6:\n",
    "        global_start_std = 1.0\n",
    "    global_start_median = float(train_actions[\"xt_learned_start\"].median()) if not train_actions.empty else 0.0\n",
    "    global_start_mad = float((train_actions[\"xt_learned_start\"] - global_start_median).abs().median()) if not train_actions.empty else 0.0\n",
    "    if global_start_mad < 1e-6:\n",
    "        global_start_mad = 1.0\n",
    "    # ============================================================\n",
    "    # FIX ISSUE 1: Fold-aware normalization to prevent data leakage\n",
    "    # Compute group statistics from OTHER folds only for each validation fold\n",
    "    # ============================================================\n",
    "    # Initialize columns for fold-aware statistics\n",
    "    xpass_predictions_df[\"fail_group_mean\"] = global_start_mean\n",
    "    xpass_predictions_df[\"fail_group_std\"] = global_start_std\n",
    "    xpass_predictions_df[\"fail_group_median\"] = global_start_median\n",
    "    xpass_predictions_df[\"fail_group_mad\"] = global_start_mad\n",
    "    # For training data: use fold-aware statistics (exclude current fold)\n",
    "    train_actions_with_fold = train_actions.merge(\n",
    "        train_df[[\"match_id\", \"player_id\", \"fold\"]],\n",
    "        on=[\"match_id\", \"player_id\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    for fold in train_actions_with_fold[\"fold\"].dropna().unique():\n",
    "        # Get actions from OTHER folds (not current fold)\n",
    "        other_folds_actions = train_actions_with_fold[train_actions_with_fold[\"fold\"] != fold]\n",
    "        if other_folds_actions.empty:\n",
    "            continue\n",
    "        # Compute statistics from other folds only\n",
    "        fold_group_mean = other_folds_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].mean()\n",
    "        fold_group_std = other_folds_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].std(ddof=0)\n",
    "        fold_group_median = other_folds_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].median()\n",
    "        fold_group_mad = other_folds_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].apply(\n",
    "            lambda s: (s - s.median()).abs().median()\n",
    "        )\n",
    "        # Apply to current fold's validation data\n",
    "        # Create the mask properly\n",
    "        fold_match_player = train_df[train_df[\"fold\"] == fold][[\"match_id\", \"player_id\"]].copy()\n",
    "        fold_match_player[\"_in_fold\"] = True\n",
    "        xpass_with_fold = xpass_predictions_df.merge(\n",
    "            fold_match_player,\n",
    "            on=[\"match_id\", \"player_id\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        current_fold_mask = (xpass_with_fold[\"is_train_action\"]) & (xpass_with_fold[\"_in_fold\"] == True)\n",
    "        if current_fold_mask.sum() > 0:\n",
    "            xpass_predictions_df.loc[current_fold_mask, \"fail_group_mean\"] = (\n",
    "                xpass_predictions_df.loc[current_fold_mask, \"xpass_action_group\"]\n",
    "                .map(fold_group_mean)\n",
    "                .fillna(global_start_mean)\n",
    "            )\n",
    "            xpass_predictions_df.loc[current_fold_mask, \"fail_group_std\"] = (\n",
    "                xpass_predictions_df.loc[current_fold_mask, \"xpass_action_group\"]\n",
    "                .map(fold_group_std)\n",
    "                .fillna(global_start_std)\n",
    "            )\n",
    "            xpass_predictions_df.loc[current_fold_mask, \"fail_group_median\"] = (\n",
    "                xpass_predictions_df.loc[current_fold_mask, \"xpass_action_group\"]\n",
    "                .map(fold_group_median)\n",
    "                .fillna(global_start_median)\n",
    "            )\n",
    "            xpass_predictions_df.loc[current_fold_mask, \"fail_group_mad\"] = (\n",
    "                xpass_predictions_df.loc[current_fold_mask, \"xpass_action_group\"]\n",
    "                .map(fold_group_mad)\n",
    "                .fillna(global_start_mad)\n",
    "            )\n",
    "    # For test data: use statistics from ALL training data\n",
    "    test_mask = ~xpass_predictions_df[\"is_train_action\"]\n",
    "    if test_mask.sum() > 0:\n",
    "        group_mean_all = train_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].mean()\n",
    "        group_std_all = train_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].std(ddof=0)\n",
    "        group_median_all = train_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].median()\n",
    "        group_mad_all = train_actions.groupby(\"xpass_action_group\")[\"xt_learned_start\"].apply(\n",
    "            lambda s: (s - s.median()).abs().median()\n",
    "        )\n",
    "        xpass_predictions_df.loc[test_mask, \"fail_group_mean\"] = (\n",
    "            xpass_predictions_df.loc[test_mask, \"xpass_action_group\"]\n",
    "            .map(group_mean_all)\n",
    "            .fillna(global_start_mean)\n",
    "        )\n",
    "        xpass_predictions_df.loc[test_mask, \"fail_group_std\"] = (\n",
    "            xpass_predictions_df.loc[test_mask, \"xpass_action_group\"]\n",
    "            .map(group_std_all)\n",
    "            .fillna(global_start_std)\n",
    "        )\n",
    "        xpass_predictions_df.loc[test_mask, \"fail_group_median\"] = (\n",
    "            xpass_predictions_df.loc[test_mask, \"xpass_action_group\"]\n",
    "            .map(group_median_all)\n",
    "            .fillna(global_start_median)\n",
    "        )\n",
    "        xpass_predictions_df.loc[test_mask, \"fail_group_mad\"] = (\n",
    "            xpass_predictions_df.loc[test_mask, \"xpass_action_group\"]\n",
    "            .map(group_mad_all)\n",
    "            .fillna(global_start_mad)\n",
    "        )\n",
    "    # Ensure minimum std and mad to avoid division by zero\n",
    "    xpass_predictions_df[\"fail_group_std\"] = xpass_predictions_df[\"fail_group_std\"].where(\n",
    "        xpass_predictions_df[\"fail_group_std\"] > 1e-6, global_start_std\n",
    "    )\n",
    "    xpass_predictions_df[\"fail_group_mad\"] = xpass_predictions_df[\"fail_group_mad\"].where(\n",
    "        xpass_predictions_df[\"fail_group_mad\"] > 1e-6, global_start_mad\n",
    "    )\n",
    "    # Validation: Ensure no NaN values remain\n",
    "    assert xpass_predictions_df[\"fail_group_mean\"].isna().sum() == 0, \"fail_group_mean has NaN values\"\n",
    "    assert xpass_predictions_df[\"fail_group_std\"].isna().sum() == 0, \"fail_group_std has NaN values\"\n",
    "    assert xpass_predictions_df[\"fail_group_median\"].isna().sum() == 0, \"fail_group_median has NaN values\"\n",
    "    assert xpass_predictions_df[\"fail_group_mad\"].isna().sum() == 0, \"fail_group_mad has NaN values\"\n",
    "    print(f\"✓ Fold-aware normalization applied: {len(train_actions_with_fold['fold'].dropna().unique())} folds processed\")\n",
    "    pass_train = train_actions[train_actions[\"xpass_action_group\"] == \"pass\"]\n",
    "    if not pass_train.empty:\n",
    "        pass_reference = np.sort(pass_train[\"xt_learned_start\"].to_numpy())\n",
    "    else:\n",
    "        pass_reference = None\n",
    "    def _quantile_center(values: np.ndarray, reference: np.ndarray) -> np.ndarray:\n",
    "        if reference is None or len(reference) == 0:\n",
    "            return np.zeros_like(values, dtype=float)\n",
    "        ranks = np.searchsorted(reference, values, side=\"left\")\n",
    "        quantiles = (ranks + 0.5) / len(reference)\n",
    "        quantiles = np.clip(quantiles, 1e-6, 1 - 1e-6)\n",
    "        return quantiles - 0.5\n",
    "    xpass_predictions_df[\"fail_component_scaled\"] = 0.0\n",
    "    pass_mask = xpass_predictions_df[\"xpass_action_group\"] == \"pass\"\n",
    "    if pass_mask.any():\n",
    "        if pass_reference is not None and len(pass_reference) > 10:\n",
    "            centered = _quantile_center(xpass_predictions_df.loc[pass_mask, \"xt_learned_start\"].to_numpy(), pass_reference)\n",
    "        else:\n",
    "            centered = (\n",
    "                (xpass_predictions_df.loc[pass_mask, \"xt_learned_start\"] - xpass_predictions_df.loc[pass_mask, \"fail_group_median\"]) / xpass_predictions_df.loc[pass_mask, \"fail_group_mad\"]\n",
    "            ).to_numpy()\n",
    "        xpass_predictions_df.loc[pass_mask, \"fail_component_scaled\"] = xpass_predictions_df.loc[pass_mask, \"fail_weight\"].to_numpy() * centered\n",
    "    non_pass_mask = ~pass_mask\n",
    "    if non_pass_mask.any():\n",
    "        centered = (\n",
    "            xpass_predictions_df.loc[non_pass_mask, \"xt_learned_start\"].to_numpy() - xpass_predictions_df.loc[non_pass_mask, \"fail_group_mean\"].to_numpy()\n",
    "        ) / xpass_predictions_df.loc[non_pass_mask, \"fail_group_std\"].to_numpy()\n",
    "        xpass_predictions_df.loc[non_pass_mask, \"fail_component_scaled\"] = xpass_predictions_df.loc[non_pass_mask, \"fail_weight\"].to_numpy() * centered\n",
    "    train_actions = xpass_predictions_df[xpass_predictions_df[\"is_train_action\"]].copy()\n",
    "    train_meta = train_df[[\"match_id\", \"player_id\", \"fold\", \"xAG\"]].copy()\n",
    "    fold_labels = sorted(train_df[\"fold\"].unique())\n",
    "    def _weighted_rmse_local(y_true, y_pred):\n",
    "        weights = make_sample_weight(y_true)\n",
    "        return float(np.sqrt(np.mean(weights * (y_true - y_pred) ** 2) + 1e-9))\n",
    "    aggregated_components = (\n",
    "        train_actions.groupby([\"match_id\", \"player_id\", \"xpass_action_group\"])\n",
    "        .agg(\n",
    "            success_sum=(\"success_component\", \"sum\"),\n",
    "            fail_sum_scaled=(\"fail_component_scaled\", \"sum\"),\n",
    "            fail_sum_raw=(\"fail_component_raw\", \"sum\"),\n",
    "            fail_weight_sum=(\"fail_weight\", \"sum\"),\n",
    "            action_count=(\"success_component\", \"count\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    lambda_per_type = {}\n",
    "    lambda_meta = []\n",
    "    lambda_bounds = {\n",
    "        \"pass\": (-0.3, 0.6),\n",
    "        \"cross\": (-0.6, 2.0),\n",
    "        \"dribble\": (-0.6, 2.0),\n",
    "        \"carry\": (-0.6, 2.0),\n",
    "        \"corner\": (-1.5, 3.0),\n",
    "        \"free_kick\": (-1.5, 3.0),\n",
    "    }\n",
    "    for action_group in sorted(xpass_predictions_df[\"xpass_action_group\"].dropna().unique()):\n",
    "        type_df = aggregated_components[aggregated_components[\"xpass_action_group\"] == action_group].copy()\n",
    "        type_df = type_df.merge(train_meta, on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "        type_df = type_df.dropna(subset=[\"xAG\", \"fold\"])\n",
    "        if type_df.empty:\n",
    "            lambda_per_type[action_group] = 0.0\n",
    "            continue\n",
    "        lam_low, lam_high = lambda_bounds.get(action_group, (-1.0, 2.0))\n",
    "        def objective(trial):\n",
    "            lam = trial.suggest_float(\"lambda\", lam_low, lam_high)\n",
    "            preds = type_df[\"success_sum\"] - lam * type_df[\"fail_sum_scaled\"]\n",
    "            scores = []\n",
    "            for fold in fold_labels:\n",
    "                fold_mask = type_df[\"fold\"] == fold\n",
    "                if not fold_mask.any():\n",
    "                    continue\n",
    "                scores.append(\n",
    "                    _weighted_rmse_local(\n",
    "                        type_df.loc[fold_mask, \"xAG\"].to_numpy(),\n",
    "                        preds.loc[fold_mask].to_numpy(),\n",
    "                    )\n",
    "                )\n",
    "            return float(np.mean(scores)) if scores else 1.0\n",
    "        study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=SEED))\n",
    "        study.optimize(objective, n_trials=35, show_progress_bar=False)\n",
    "        best_lambda = float(study.best_params[\"lambda\"])\n",
    "        lambda_per_type[action_group] = best_lambda\n",
    "        lambda_meta.append(\n",
    "            {\n",
    "                \"action_type\": action_group,\n",
    "                \"lambda\": best_lambda,\n",
    "                \"lambda_min\": lam_low,\n",
    "                \"lambda_max\": lam_high,\n",
    "                \"train_rows\": int(type_df.shape[0]),\n",
    "                \"actions_per_player_mean\": float(type_df[\"action_count\"].mean()),\n",
    "                \"fail_scaled_mean\": float(type_df[\"fail_sum_scaled\"].mean()),\n",
    "            }\n",
    "        )\n",
    "    lambda_meta_df = pd.DataFrame(lambda_meta)\n",
    "    if not lambda_meta_df.empty:\n",
    "        display(lambda_meta_df.sort_values(\"lambda\"))\n",
    "        print(\"λ分布統計:\")\n",
    "        display(lambda_meta_df[\"lambda\"].describe())\n",
    "    for action_group, lam_value in lambda_per_type.items():\n",
    "        type_actions = xpass_predictions_df[xpass_predictions_df[\"xpass_action_group\"] == action_group].copy()\n",
    "        if type_actions.empty:\n",
    "            continue\n",
    "        type_actions[\"edxt_value_scaled\"] = type_actions[\"success_component\"] - lam_value * type_actions[\"fail_component_scaled\"]\n",
    "        type_actions[\"edxt_positive_scaled\"] = np.clip(type_actions[\"edxt_value_scaled\"], 0.0, None)\n",
    "        type_actions[\"edxt_value\"] = type_actions[\"success_component\"] - lam_value * type_actions[\"fail_component_raw\"]\n",
    "        type_actions[\"edxt_positive\"] = np.clip(type_actions[\"edxt_value\"], 0.0, None)\n",
    "        agg_train = (\n",
    "            type_actions[type_actions[\"is_train_action\"]]\n",
    "            .groupby([\"match_id\", \"player_id\"])\n",
    "            .agg(\n",
    "                edxt_sum=(\"edxt_value\", \"sum\"),\n",
    "                edxt_mean=(\"edxt_value\", \"mean\"),\n",
    "                edxt_max=(\"edxt_value\", \"max\"),\n",
    "                edxt_positive_sum=(\"edxt_positive\", \"sum\"),\n",
    "                edxt_positive_mean=(\"edxt_positive\", \"mean\"),\n",
    "                edxt_scaled_sum=(\"edxt_value_scaled\", \"sum\"),\n",
    "                edxt_scaled_mean=(\"edxt_value_scaled\", \"mean\"),\n",
    "                edxt_scaled_max=(\"edxt_value_scaled\", \"max\"),\n",
    "                edxt_scaled_positive_sum=(\"edxt_positive_scaled\", \"sum\"),\n",
    "                edxt_scaled_positive_mean=(\"edxt_positive_scaled\", \"mean\"),\n",
    "                edxt_count=(\"edxt_value\", \"count\"),\n",
    "                success_sum=(\"success_component\", \"sum\"),\n",
    "                fail_sum_raw=(\"fail_component_raw\", \"sum\"),\n",
    "                fail_sum_scaled=(\"fail_component_scaled\", \"sum\"),\n",
    "                fail_weight_sum=(\"fail_weight\", \"sum\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "        agg_test = (\n",
    "            type_actions[~type_actions[\"is_train_action\"]]\n",
    "            .groupby([\"match_id\", \"player_id\"])\n",
    "            .agg(\n",
    "                edxt_sum=(\"edxt_value\", \"sum\"),\n",
    "                edxt_mean=(\"edxt_value\", \"mean\"),\n",
    "                edxt_max=(\"edxt_value\", \"max\"),\n",
    "                edxt_positive_sum=(\"edxt_positive\", \"sum\"),\n",
    "                edxt_positive_mean=(\"edxt_positive\", \"mean\"),\n",
    "                edxt_scaled_sum=(\"edxt_value_scaled\", \"sum\"),\n",
    "                edxt_scaled_mean=(\"edxt_value_scaled\", \"mean\"),\n",
    "                edxt_scaled_max=(\"edxt_value_scaled\", \"max\"),\n",
    "                edxt_scaled_positive_sum=(\"edxt_positive_scaled\", \"sum\"),\n",
    "                edxt_scaled_positive_mean=(\"edxt_positive_scaled\", \"mean\"),\n",
    "                edxt_count=(\"edxt_value\", \"count\"),\n",
    "                success_sum=(\"success_component\", \"sum\"),\n",
    "                fail_sum_raw=(\"fail_component_raw\", \"sum\"),\n",
    "                fail_sum_scaled=(\"fail_component_scaled\", \"sum\"),\n",
    "                fail_weight_sum=(\"fail_weight\", \"sum\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "        col_map = {\n",
    "            \"edxt_sum\": f\"{action_group}_edxt_sum\",\n",
    "            \"edxt_mean\": f\"{action_group}_edxt_mean\",\n",
    "            \"edxt_max\": f\"{action_group}_edxt_max\",\n",
    "            \"edxt_positive_sum\": f\"{action_group}_edxt_positive_sum\",\n",
    "            \"edxt_positive_mean\": f\"{action_group}_edxt_positive_mean\",\n",
    "            \"edxt_scaled_sum\": f\"{action_group}_edxt_scaled_sum\",\n",
    "            \"edxt_scaled_mean\": f\"{action_group}_edxt_scaled_mean\",\n",
    "            \"edxt_scaled_max\": f\"{action_group}_edxt_scaled_max\",\n",
    "            \"edxt_scaled_positive_sum\": f\"{action_group}_edxt_scaled_positive_sum\",\n",
    "            \"edxt_scaled_positive_mean\": f\"{action_group}_edxt_scaled_positive_mean\",\n",
    "            \"edxt_count\": f\"{action_group}_edxt_count\",\n",
    "            \"success_sum\": f\"{action_group}_edxt_success_sum\",\n",
    "            \"fail_sum_raw\": f\"{action_group}_edxt_fail_sum\",\n",
    "            \"fail_sum_scaled\": f\"{action_group}_edxt_fail_scaled_sum\",\n",
    "            \"fail_weight_sum\": f\"{action_group}_fail_weight_sum\",\n",
    "        }\n",
    "        train_df = train_df.merge(agg_train.rename(columns=col_map), on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "        test_df = test_df.merge(agg_test.rename(columns=col_map), on=[\"match_id\", \"player_id\"], how=\"left\")\n",
    "        for new_col in col_map.values():\n",
    "            if new_col not in train_df.columns:\n",
    "                train_df[new_col] = 0.0\n",
    "            if new_col not in test_df.columns:\n",
    "                test_df[new_col] = 0.0\n",
    "            train_df[new_col] = train_df[new_col].fillna(0.0)\n",
    "            test_df[new_col] = test_df[new_col].fillna(0.0)\n",
    "        edxt_feature_cols.extend(col_map.values())\n",
    "    openplay_groups = {\"pass\", \"cross\", \"dribble\", \"carry\"}\n",
    "    setpiece_groups = {\"corner\", \"free_kick\"}\n",
    "    def _sum_columns(df, cols, new_col):\n",
    "        found = [col for col in cols if col in df.columns]\n",
    "        if found:\n",
    "            df[new_col] = df[found].sum(axis=1)\n",
    "        else:\n",
    "            df[new_col] = 0.0\n",
    "    setpiece_scaled_cols = [f\"{g}_edxt_scaled_positive_sum\" for g in setpiece_groups]\n",
    "    openplay_scaled_cols = [f\"{g}_edxt_scaled_positive_sum\" for g in openplay_groups]\n",
    "    setpiece_raw_cols = [f\"{g}_edxt_positive_sum\" for g in setpiece_groups]\n",
    "    openplay_raw_cols = [f\"{g}_edxt_positive_sum\" for g in openplay_groups]\n",
    "    for df in (train_df, test_df):\n",
    "        _sum_columns(df, setpiece_scaled_cols, \"setpiece_edxt_scaled_positive_sum\")\n",
    "        _sum_columns(df, openplay_scaled_cols, \"openplay_edxt_scaled_positive_sum\")\n",
    "        _sum_columns(df, setpiece_raw_cols, \"setpiece_edxt_positive_sum\")\n",
    "        _sum_columns(df, openplay_raw_cols, \"openplay_edxt_positive_sum\")\n",
    "        scaled_denom = df[\"setpiece_edxt_scaled_positive_sum\"] + df[\"openplay_edxt_scaled_positive_sum\"]\n",
    "        raw_denom = df[\"setpiece_edxt_positive_sum\"] + df[\"openplay_edxt_positive_sum\"]\n",
    "        df[\"setpiece_edxt_scaled_ratio\"] = np.where(scaled_denom > 0, df[\"setpiece_edxt_scaled_positive_sum\"] / scaled_denom, 0.0)\n",
    "        df[\"setpiece_edxt_raw_ratio\"] = np.where(raw_denom > 0, df[\"setpiece_edxt_positive_sum\"] / raw_denom, 0.0)\n",
    "    edxt_feature_cols.extend([\n",
    "        \"setpiece_edxt_scaled_positive_sum\",\n",
    "        \"openplay_edxt_scaled_positive_sum\",\n",
    "        \"setpiece_edxt_positive_sum\",\n",
    "        \"openplay_edxt_positive_sum\",\n",
    "        \"setpiece_edxt_scaled_ratio\",\n",
    "        \"setpiece_edxt_raw_ratio\",\n",
    "    ])\n",
    "    edxt_feature_cols = sorted(dict.fromkeys(edxt_feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a69637",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"チーム文脈特徴量を追加しています...\")\n",
    "\n",
    "team_context_feature_cols = []\n",
    "team_base_candidates = [\n",
    "    col\n",
    "    for col in train_df.columns\n",
    "    if col.startswith(\"xt_learned_\") or col.startswith(\"possession_xt_\") or col.endswith(\"_edxt_sum\")\n",
    "]\n",
    "team_base_columns = [col for col in team_base_candidates if np.issubdtype(train_df[col].dtype, np.number)]\n",
    "\n",
    "if team_base_columns:\n",
    "    for df in (train_df, test_df):\n",
    "        for col in team_base_columns:\n",
    "            team_sum = df.groupby([\"match_id\", \"Squad\"])[col].transform(\"sum\")\n",
    "            sum_col = f\"{col}_team_sum\"\n",
    "            share_col = f\"{col}_team_share\"\n",
    "            lopo_col = f\"{col}_team_lopo\"\n",
    "            df[sum_col] = team_sum\n",
    "            df[share_col] = np.where(team_sum != 0, df[col] / team_sum, 0.0)\n",
    "            df[lopo_col] = team_sum - df[col]\n",
    "            df[sum_col] = df[sum_col].fillna(0.0)\n",
    "            df[share_col] = df[share_col].fillna(0.0)\n",
    "            df[lopo_col] = df[lopo_col].fillna(0.0)\n",
    "            if df is train_df:\n",
    "                team_context_feature_cols.extend([sum_col, share_col, lopo_col])\n",
    "\n",
    "    team_context_feature_cols = sorted(dict.fromkeys(team_context_feature_cols))\n",
    "else:\n",
    "    team_context_feature_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c9f3d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"リーグ別ゲーティング特徴を作成しています...\")\n",
    "\n",
    "comp_interaction_feature_cols = []\n",
    "comp_cross_base_features = [\n",
    "    col\n",
    "    for col in [\n",
    "        \"xt_learned_delta_sum\",\n",
    "        \"xt_learned_positive_delta_sum\",\n",
    "        \"possession_xt_positive_sum\",\n",
    "        \"possession_xt_delta_sum\",\n",
    "        \"possession_speed_ground_mean\",\n",
    "    ]\n",
    "    if col in train_df.columns\n",
    "]\n",
    "\n",
    "if comp_cross_base_features:\n",
    "    comp_dummy_train = pd.get_dummies(train_df[\"Comp\"].astype(str), prefix=\"comp_gate\", dtype=float)\n",
    "    comp_dummy_test = pd.get_dummies(test_df[\"Comp\"].astype(str), prefix=\"comp_gate\", dtype=float)\n",
    "    comp_dummy_train, comp_dummy_test = comp_dummy_train.align(comp_dummy_test, join=\"outer\", axis=1, fill_value=0.0)\n",
    "    comp_dummy_test = comp_dummy_test[comp_dummy_train.columns]\n",
    "\n",
    "    train_base = train_df[comp_cross_base_features].fillna(0.0)\n",
    "    test_base = test_df[comp_cross_base_features].fillna(0.0)\n",
    "\n",
    "    for base_col in comp_cross_base_features:\n",
    "        train_values = train_base[base_col].to_numpy()\n",
    "        test_values = test_base[base_col].to_numpy()\n",
    "        for comp_col in comp_dummy_train.columns:\n",
    "            feat_name = f\"{base_col}__{comp_col}\"\n",
    "            train_df[feat_name] = train_values * comp_dummy_train[comp_col].to_numpy()\n",
    "            test_df[feat_name] = test_values * comp_dummy_test[comp_col].to_numpy()\n",
    "            comp_interaction_feature_cols.append(feat_name)\n",
    "\n",
    "    comp_interaction_feature_cols = sorted(dict.fromkeys(comp_interaction_feature_cols))\n",
    "else:\n",
    "    comp_interaction_feature_cols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66d81c",
   "metadata": {
    "id": "A7xHPcUziuhW"
   },
   "source": [
    "## 特徴量の統合\n",
    "\n",
    "作成した全ての特徴量を統合し、train/testデータにマージします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a9eca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiPaa-Dz6Gvj",
    "lines_to_next_cell": 2,
    "outputId": "cc523b94-b8ff-47fd-b87c-8ced83eb52a0"
   },
   "outputs": [],
   "source": [
    "# 応用特徴量をtrain/testへマージ\n",
    "train_df = (\n",
    "    train_df\n",
    "    .merge(success_rates, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(zone_actions, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(per_minute_features, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(offense_defense_balance, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(pass_leads_to_shot, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(progressive_features, on=['match_id', 'player_id'], how='left')\n",
    ")\n",
    "\n",
    "train_df['pass_leads_to_shot'] = train_df['pass_leads_to_shot'].fillna(0)\n",
    "\n",
    "progressive_cols = [col for col in progressive_features.columns if col not in ['match_id', 'player_id']]\n",
    "for col in progressive_cols:\n",
    "    train_df[col] = train_df[col].fillna(0.0)\n",
    "\n",
    "\n",
    "test_df = (\n",
    "    test_df\n",
    "    .merge(success_rates, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(zone_actions, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(per_minute_features, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(offense_defense_balance, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(pass_leads_to_shot, on=['match_id', 'player_id'], how='left')\n",
    "    .merge(progressive_features, on=['match_id', 'player_id'], how='left')\n",
    ")\n",
    "\n",
    "test_df['pass_leads_to_shot'] = test_df['pass_leads_to_shot'].fillna(0)\n",
    "for col in progressive_cols:\n",
    "    test_df[col] = test_df[col].fillna(0.0)\n",
    "\n",
    "print(f\"マージ後のtrainデータshape: {train_df.shape}\")\n",
    "print(f\"マージ後のtestデータshape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311c1ec",
   "metadata": {
    "id": "FHzc1BjgZYRR"
   },
   "source": [
    "## クロスバリデーション分割\n",
    "\n",
    "初回のbaselineでは、全データをランダムに分割するKFoldを用いましたが、今回はデータ特性に合わせた別の分割方法を行います。\n",
    "\n",
    "EDAで確認したように、今回はtrainデータとtestデータについては、match_idの重なりはありません。\n",
    "すなわち、testデータを予測するときには、これまで見たことのない試合のデータに対して予測をする必要があります。\n",
    "この状況をtrainデータ内部でのCross Validationでもなるべく再現することによって、実際のタスクに近い状況で正しい評価が可能になります。\n",
    "\n",
    "ここでは、GroupKFoldを用いて、trainデータをmatch_idが被らないように5分割します。こうすることで、各foldでのtrainデータとvalidデータのmatch_idが重ならなくなります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b372196",
   "metadata": {
    "id": "EqDZiepKaIf3"
   },
   "source": [
    "## モデル学習用データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ターゲットエンコーディング特徴量の作成\n",
    "print(\"ターゲットエンコーディング特徴量を作成中...\")\n",
    "\n",
    "# Squad×Opponentの交互作用特徴を作成\n",
    "train_df[\"Squad_x_Opponent\"] = train_df[\"Squad\"].astype(str) + \"_vs_\" + train_df[\"Opponent\"].astype(str)\n",
    "test_df[\"Squad_x_Opponent\"] = test_df[\"Squad\"].astype(str) + \"_vs_\" + test_df[\"Opponent\"].astype(str)\n",
    "\n",
    "target_encoding_cols = [\"player_id\", \"Squad\", \"Opponent\", \"Squad_x_Opponent\"]\n",
    "global_mean = train_df[\"xAG\"].mean()\n",
    "smoothing = 10.0\n",
    "fold_labels = sorted(train_df[\"fold\"].unique())\n",
    "\n",
    "for col in target_encoding_cols:\n",
    "    enc_col = f\"{col}_target_enc\"\n",
    "    train_df[enc_col] = np.nan\n",
    "\n",
    "    for fold in fold_labels:\n",
    "        trn = train_df[train_df[\"fold\"] != fold]\n",
    "        val_mask = train_df[\"fold\"] == fold\n",
    "\n",
    "        stats = trn.groupby(col)[\"xAG\"].agg([\"sum\", \"count\"])\n",
    "        stats[\"encoding\"] = (stats[\"sum\"] + global_mean * smoothing) / (stats[\"count\"] + smoothing)\n",
    "\n",
    "        train_df.loc[val_mask, enc_col] = train_df.loc[val_mask, col].map(stats[\"encoding\"]).fillna(global_mean)\n",
    "\n",
    "    overall_stats = train_df.groupby(col)[\"xAG\"].agg([\"sum\", \"count\"])\n",
    "    overall_stats[\"encoding\"] = (overall_stats[\"sum\"] + global_mean * smoothing) / (overall_stats[\"count\"] + smoothing)\n",
    "\n",
    "    test_df[enc_col] = test_df[col].map(overall_stats[\"encoding\"]).fillna(global_mean)\n",
    "\n",
    "    missing_train = train_df[enc_col].isna().sum()\n",
    "    missing_test = test_df[enc_col].isna().sum()\n",
    "\n",
    "    if missing_train > 0:\n",
    "        train_df.loc[train_df[enc_col].isna(), enc_col] = global_mean\n",
    "    if missing_test > 0:\n",
    "        test_df.loc[test_df[enc_col].isna(), enc_col] = global_mean\n",
    "\n",
    "    print(f\"  {col}: train missing {int(missing_train)}, test missing {int(missing_test)}\")\n",
    "\n",
    "print(\"リーグ/チームバイアス調整特徴を計算中...\")\n",
    "\n",
    "train_df[\"Comp_target_enc\"] = np.nan\n",
    "comp_smoothing = 5.0\n",
    "\n",
    "for fold in fold_labels:\n",
    "    trn = train_df[train_df[\"fold\"] != fold]\n",
    "    val_mask = train_df[\"fold\"] == fold\n",
    "\n",
    "    comp_stats = trn.groupby(\"Comp\")[\"xAG\"].agg([\"sum\", \"count\"])\n",
    "    comp_stats[\"encoding\"] = (comp_stats[\"sum\"] + global_mean * comp_smoothing) / (comp_stats[\"count\"] + comp_smoothing)\n",
    "\n",
    "    train_df.loc[val_mask, \"Comp_target_enc\"] = train_df.loc[val_mask, \"Comp\"].map(comp_stats[\"encoding\"]).fillna(global_mean)\n",
    "\n",
    "comp_overall_stats = train_df.groupby(\"Comp\")[\"xAG\"].agg([\"sum\", \"count\"])\n",
    "comp_overall_stats[\"encoding\"] = (comp_overall_stats[\"sum\"] + global_mean * comp_smoothing) / (comp_overall_stats[\"count\"] + comp_smoothing)\n",
    "\n",
    "test_df[\"Comp_target_enc\"] = test_df[\"Comp\"].map(comp_overall_stats[\"encoding\"]).fillna(global_mean)\n",
    "\n",
    "train_df[\"Comp_target_enc\"] = train_df[\"Comp_target_enc\"].fillna(global_mean)\n",
    "\n",
    "test_df[\"Comp_target_enc\"] = test_df[\"Comp_target_enc\"].fillna(global_mean)\n",
    "\n",
    "train_df[\"Squad_comp_residual\"] = train_df[\"Squad_target_enc\"] - train_df[\"Comp_target_enc\"]\n",
    "test_df[\"Squad_comp_residual\"] = test_df[\"Squad_target_enc\"] - test_df[\"Comp_target_enc\"]\n",
    "\n",
    "train_df[\"Squad_global_residual\"] = train_df[\"Squad_target_enc\"] - global_mean\n",
    "test_df[\"Squad_global_residual\"] = test_df[\"Squad_target_enc\"] - global_mean\n",
    "\n",
    "# diff between Squad and Opponent TE for matchup effect\n",
    "train_df[\"Squad_vs_opponent_gap\"] = train_df[\"Squad_target_enc\"] - train_df[\"Opponent_target_enc\"]\n",
    "test_df[\"Squad_vs_opponent_gap\"] = test_df[\"Squad_target_enc\"] - test_df[\"Opponent_target_enc\"]\n",
    "\n",
    "print(\"  Squad_comp_residual などの新特徴を追加しました。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb98842",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "507qeMbXaIf3",
    "lines_to_next_cell": 2,
    "outputId": "bc0b39f4-fe13-4491-8f88-71c960669942"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 各特徴量グループの定義\n",
    "base_features = [\"age\", \"action_count\", \"avg_x\", \"avg_y\", \"minutes_played\", \"goal_count\"]\n",
    "categorical_features = [\"Comp\", \"Squad\", \"Venue\"]\n",
    "action_type_features = [col for col in train_df.columns if (col.startswith('type_')) and (col.endswith('_count'))]\n",
    "success_rate_features = [\n",
    "    col for col in train_df.columns\n",
    "    if col.endswith('_success_rate') and not col.startswith('progressive_')\n",
    "]\n",
    "zone_features = [col for col in train_df.columns if col.startswith('zone_')]\n",
    "per_minute_features = [col for col in train_df.columns if col.endswith('_per_minute')]\n",
    "ad_balance_features = ['type_offensive_actions', 'type_defensive_actions', 'type_offensive_action_ratio']\n",
    "sequencial_features = ['pass_leads_to_shot']\n",
    "progressive_feature_cols = [\n",
    "    col for col in train_df.columns\n",
    "    if col.startswith('progressive_')\n",
    "    or col in ['deep_completion_count', 'final_third_entry_count', 'penalty_area_entry_count']\n",
    "]\n",
    "xt_cols = [col for col in train_df.columns if col.startswith('xt_')]\n",
    "target_encoding_features = [f\"{col}_target_enc\" for col in [\"player_id\", \"Squad\", \"Opponent\", \"Squad_x_Opponent\"]]\n",
    "extra_bias_features = [\"Comp_target_enc\", \"Squad_comp_residual\", \"Squad_global_residual\", \"Squad_vs_opponent_gap\"]\n",
    "possession_features = [col for col in train_df.columns if col.startswith('possession_')]\n",
    "pass_network_features = [col for col in train_df.columns if col.startswith('pass_net_')]\n",
    "edxt_features = sorted(globals().get('edxt_feature_cols', []))\n",
    "team_context_features = sorted(globals().get('team_context_feature_cols', []))\n",
    "comp_interaction_features = sorted(globals().get('comp_interaction_feature_cols', []))\n",
    "\n",
    "all_features = (\n",
    "    base_features\n",
    "    + categorical_features\n",
    "    + action_type_features\n",
    "    + success_rate_features\n",
    "    + zone_features\n",
    "    + per_minute_features\n",
    "    + ad_balance_features\n",
    "    + sequencial_features\n",
    "    + progressive_feature_cols\n",
    "    + xt_cols\n",
    "    + target_encoding_features\n",
    "    + extra_bias_features\n",
    "    + possession_features\n",
    "    + pass_network_features\n",
    "    + edxt_features\n",
    "    + team_context_features\n",
    "    + comp_interaction_features\n",
    ")\n",
    "\n",
    "all_features = list(dict.fromkeys(all_features))\n",
    "\n",
    "# 追加: 高度特徴量を all_features に含める（学習用データ作成の前に実施）\n",
    "advanced_candidates = [\n",
    "    \"second_assist_count\",\n",
    "    \"SCA_1\",\n",
    "    \"SCA_2\",\n",
    "    \"GCA_1\",\n",
    "    \"GCA_2\",\n",
    "    \"nstep_to_shot\",\n",
    "    \"nstep_xt_delta\",\n",
    "    \"pass_dist_mean\",\n",
    "    \"pass_dist_max\",\n",
    "    \"to_goal_angle_abs_mean\",\n",
    "    \"to_goal_dist_mean\",\n",
    "    \"pass_to_shot_latency_mean\",\n",
    "    \"pass_to_shot_latency_min\",\n",
    "    \"risk_creativity_sum\",\n",
    "    \"xpass_mean\",\n",
    "    \"xpass_min\",\n",
    "    \"pass_success_minus_xpass\",\n",
    "    \"xpass_deep_mean\",\n",
    "    \"xpass_box_mean\",\n",
    "    # 時系列トレンド\n",
    "    \"xAG_expanding_mean\",\n",
    "    \"xAG_rolling3_mean\",\n",
    "    \"xAG_diff_prev\",\n",
    "    # 🆕 新特徴量（EXP0025）\n",
    "    \"first_half_actions\", \"second_half_actions\", \"final_15min_actions\",\n",
    "    \"early_10min_actions\", \"time_weighted_intensity\",\n",
    "    \"defensive_zone_actions\", \"middle_zone_actions\", \"attacking_zone_actions\",\n",
    "    \"halfspace_left_actions\", \"halfspace_right_actions\", \"central_corridor_actions\",\n",
    "    \"final_third_penetrations\", \"box_entries\",\n",
    "    \"betweenness_centrality\", \"closeness_centrality\", \"degree_centrality\",\n",
    "    \"pass_receiver_diversity\", \"unique_pass_partners\",\n",
    "    \"longchain_to_shot\", \"longchain_xt_delta\",\n",
    "    \"position_variance_x\", \"position_variance_y\", \"position_range_x\",\n",
    "    \"position_range_y\", \"avg_action_distance\",\n",
    "]\n",
    "advanced_features = [c for c in advanced_candidates if c in train_df.columns]\n",
    "if advanced_features:\n",
    "    all_features = list(dict.fromkeys(all_features + advanced_features))\n",
    "    print(f\"追加された高度特徴量（学習前反映）: {len(advanced_features)}個 (🆕新特徴量25個含む)\")\n",
    "\n",
    "# カテゴリカル変数については、列の型を「category」に変更しておく\n",
    "for col in categorical_features:\n",
    "    train_df[col] = train_df[col].astype(\"category\")\n",
    "    test_df[col] = test_df[col].astype(\"category\")\n",
    "\n",
    "print(f\"  - 使用する特徴量数: {len(all_features)}個\")\n",
    "print(f\"  - 基本特徴量: {len(base_features)}個\")\n",
    "print(f\"  - カテゴリカル特徴量: {len(categorical_features)}個\")\n",
    "print(f\"  - アクション特徴量(type_*_count): {len(action_type_features)}個\")\n",
    "print(f\"  - 成功率系: {len(success_rate_features)}個\")\n",
    "print(f\"  - ゾーン系: {len(zone_features)}個\")\n",
    "print(f\"  - per_minute系: {len(per_minute_features)}個\")\n",
    "print(f\"  - 攻守バランス系: {len(ad_balance_features)}個\")\n",
    "print(f\"  - 時系列系: {len(sequencial_features)}個\")\n",
    "print(f\"  - プログレッシブ系: {len(progressive_feature_cols)}個\")\n",
    "print(f\"  - xT系: {len(xt_cols)}個\")\n",
    "print(f\"  - ターゲットエンコーディング系: {len(target_encoding_features)}個\")\n",
    "print(f\"  - ポゼッション進攻系: {len(possession_features)}個\")\n",
    "print(f\"  - パスネットワーク系: {len(pass_network_features)}個\")\n",
    "print(f\"  - eΔxT系: {len(edxt_features)}個\")\n",
    "print(f\"  - チーム文脈系: {len(team_context_features)}個\")\n",
    "print(f\"  - リーグ相互作用系: {len(comp_interaction_features)}個\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc2649",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUaVQAMtR2wk",
    "outputId": "a5af6982-d1c3-4d7d-f5aa-a51963962df1"
   },
   "outputs": [],
   "source": [
    "# モデル学習用データの作成\n",
    "X_train = train_df[all_features + [\"fold\"]]\n",
    "y_train = train_df[\"xAG\"]\n",
    "X_test = test_df[all_features]\n",
    "\n",
    "print(f\"\\nモデル学習用データ形状: X_train {X_train.shape}, y_train {y_train.shape}, X_test {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db8d55",
   "metadata": {
    "id": "cCk52KvKaIf3"
   },
   "source": [
    "## モデル学習（LightGBM）\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc463b",
   "metadata": {
    "id": "fBFkOqtLhraM",
    "lines_to_next_cell": 2
   },
   "source": [
    "特徴量の数も増えており、ハイパーパラメータは探索してみないと分かりません。\n",
    "\n",
    "ここでは、より効率的に良さそうなパラメータを見つけられるOptunaを用いて最適化を行います。\n",
    "Optunaは探索空間から試行回数ごとに候補を提案し、良かった試行の情報を活かしながら次の探索に反映させるベイズ的最適化アルゴリズム（TPEサンプラー）を利用できるため、総当たりのGridSearchよりも少ない試行で良い結果に辿り着きやすいのがメリットです。\n",
    "（参考: https://zenn.dev/robes/articles/d53ff6d665650f ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a8dd6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngpAJwwnaIf3",
    "outputId": "321e83a6-aee6-4b0a-88c6-199be978c2c2"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Optunaで最適化しないベースパラメータ\n",
    "base_params = {\n",
    "    \"objective\": \"regression_l2\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"random_state\": SEED,\n",
    "    \"verbosity\": -1,\n",
    "    \"force_col_wise\": True,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"feature_fraction\": 0.8,\n",
    "}\n",
    "\n",
    "# Optunaで探索するハイパーパラメータの概要\n",
    "optuna_search_space = {\n",
    "    \"num_leaves\": (10, 64),\n",
    "    \"learning_rate\": (0.01, 0.1),\n",
    "    \"min_child_samples\": (10, 50),\n",
    "}\n",
    "\n",
    "print(\"Optuna用ハイパーパラメータ設定完了\")\n",
    "print(f\"探索対象パラメータ: {list(optuna_search_space.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e53304",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hkjQJvTvhMO",
    "outputId": "61949fbb-9b97-43cd-9bfc-e704053383ba"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    base_dir = Path(__file__).resolve().parent\n",
    "except NameError:  # __file__ はノートブック実行時には定義されない\n",
    "    base_dir = Path.cwd()\n",
    "\n",
    "log_dir = base_dir / \"logs\"\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_training_run(\n",
    "    cv_scores,\n",
    "    oof_score,\n",
    "    optuna_summary,\n",
    "    best_params,\n",
    "    log_directory: Path,\n",
    "    log_prefix: str = \"host_baseline_002\",\n",
    "):\n",
    "    \"\"\"Persist CV metrics to reusable JSON/text logs.\"\"\"\n",
    "\n",
    "    timestamp = datetime.now().astimezone().isoformat(timespec=\"seconds\")\n",
    "\n",
    "    metrics_payload = {\n",
    "        \"run_timestamp\": timestamp,\n",
    "        \"cv\": {\n",
    "            \"scores\": [float(score) for score in cv_scores],\n",
    "            \"mean\": float(np.mean(cv_scores)),\n",
    "            \"std\": float(np.std(cv_scores)),\n",
    "        },\n",
    "        \"per_fold\": {f\"fold_{idx + 1}\": float(score) for idx, score in enumerate(cv_scores)},\n",
    "        \"oof_rmse\": float(oof_score),\n",
    "        \"optuna\": optuna_summary,\n",
    "        \"best_params\": {key: (float(val) if isinstance(val, (np.floating, np.integer)) else val)\n",
    "                         for key, val in best_params.items()},\n",
    "    }\n",
    "\n",
    "    metrics_path = log_directory / f\"{log_prefix}_metrics.json\"\n",
    "    metrics_path.write_text(json.dumps(metrics_payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    log_lines = [\n",
    "        f\"[{timestamp}] {log_prefix}\",\n",
    "        f\"  CV mean: {metrics_payload['cv']['mean']:.4f}\",\n",
    "        f\"  CV std: {metrics_payload['cv']['std']:.4f}\",\n",
    "        f\"  OOF RMSE: {metrics_payload['oof_rmse']:.4f}\",\n",
    "    ]\n",
    "    for idx, score in enumerate(cv_scores, start=1):\n",
    "        log_lines.append(f\"  Fold {idx}: {score:.4f}\")\n",
    "\n",
    "    log_lines.append(\n",
    "        \"  Optuna best trial: \"\n",
    "        f\"{optuna_summary['best_trial_number']} (CV mean {optuna_summary['best_cv_value']:.6f}, \"\n",
    "        f\"fold1 RMSE {optuna_summary['fold1_val_rmse']:.6f})\"\n",
    "    )\n",
    "\n",
    "    log_path = log_directory / f\"{log_prefix}_training.log\"\n",
    "    with log_path.open(\"a\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(\"\\n\".join(log_lines) + \"\\n\")\n",
    "\n",
    "\n",
    "# Optunaによるハイパーパラメータチューニング\n",
    "print(\"Optunaによるチューニングを開始します...\")\n",
    "\n",
    "# Fold 1を検証用に確保（後でスコア確認に利用）\n",
    "trn_mask = train_df[\"fold\"] != 1\n",
    "val_mask = train_df[\"fold\"] == 1\n",
    "\n",
    "X_tr = train_df.loc[trn_mask, all_features].copy()\n",
    "X_val = train_df.loc[val_mask, all_features].copy()\n",
    "y_tr = y_train.loc[trn_mask].copy()\n",
    "y_val = y_train.loc[val_mask].copy()\n",
    "\n",
    "def objective(trial):\n",
    "    params = base_params.copy()\n",
    "    params.update({\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", *optuna_search_space[\"num_leaves\"]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", *optuna_search_space[\"learning_rate\"], log=True),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", *optuna_search_space[\"min_child_samples\"]),\n",
    "    })\n",
    "\n",
    "    cv_scores = []\n",
    "    for fold in range(1, 4):  # 計算量を抑えるためFold1~3でCV\n",
    "        trn_mask_cv = train_df[\"fold\"] != fold\n",
    "        val_mask_cv = train_df[\"fold\"] == fold\n",
    "\n",
    "        X_tr_cv = train_df.loc[trn_mask_cv, all_features].copy()\n",
    "        X_val_cv = train_df.loc[val_mask_cv, all_features].copy()\n",
    "        y_tr_cv = y_train.loc[trn_mask_cv].copy()\n",
    "        y_val_cv = y_train.loc[val_mask_cv].copy()\n",
    "\n",
    "        train_weights_cv = make_sample_weight(y_tr_cv)\n",
    "        val_weights_cv = make_sample_weight(y_val_cv)\n",
    "        train_data = lgb.Dataset(X_tr_cv, label=y_tr_cv, weight=train_weights_cv)\n",
    "        val_data = lgb.Dataset(X_val_cv, label=y_val_cv, weight=val_weights_cv)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[val_data],\n",
    "            feval=weighted_rmse_feval,\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)],\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_val_cv, num_iteration=model.best_iteration)\n",
    "        cv_scores.append(weighted_rmse(y_val_cv, preds))\n",
    "\n",
    "    return float(np.mean(cv_scores))\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=SEED))\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "best_params = study.best_trial.params.copy()\n",
    "best_lgbm_params = base_params.copy()\n",
    "best_lgbm_params.update(best_params)\n",
    "\n",
    "# Fold1でのスコアを再確認\n",
    "train_weights = make_sample_weight(y_tr)\n",
    "val_weights = make_sample_weight(y_val)\n",
    "train_data = lgb.Dataset(X_tr, label=y_tr, weight=train_weights)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, weight=val_weights)\n",
    "best_model = lgb.train(\n",
    "    best_lgbm_params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    feval=weighted_rmse_feval,\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)],\n",
    ")\n",
    "\n",
    "val_pred = best_model.predict(X_val, num_iteration=best_model.best_iteration)\n",
    "val_score = weighted_rmse(y_val, val_pred)\n",
    "\n",
    "print(\"=== Optunaチューニング結果 ===\")\n",
    "print(f\"最良Trial番号: {study.best_trial.number}\")\n",
    "print(f\"平均CV RMSE: {study.best_value:.6f}\")\n",
    "print(f\"Fold1 Validation RMSE: {val_score:.6f}\")\n",
    "print(\"最適化されたパラメータ:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f10f28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1o2kC3wsi0n",
    "lines_to_next_cell": 2,
    "outputId": "2e156a42-4637-433a-f6db-76205a1e3b21"
   },
   "outputs": [],
   "source": [
    "# 最適化されたパラメータでの5-Fold Cross Validation\n",
    "print(\"最適化されたパラメータでの5-Fold Cross Validationを開始...\")\n",
    "\n",
    "# 単調性制約の設定\n",
    "# xAGと単調増加関係にある特徴量を選定\n",
    "monotone_increase_features = [\n",
    "    # プログレッシブ系（攻撃的な前進プレー → xAG増加）\n",
    "    'progressive_pass_count',\n",
    "    'progressive_pass_success',\n",
    "    'progressive_pass_distance_total',\n",
    "    'progressive_pass_distance_mean',\n",
    "    'progressive_carry_count',\n",
    "    'progressive_carry_success',\n",
    "    'progressive_carry_distance_total',\n",
    "    'progressive_carry_distance_mean',\n",
    "    'deep_completion_count',  # ディープゾーン到達数\n",
    "    'final_third_entry_count',  # ファイナルサード進入数\n",
    "    'penalty_area_entry_count',  # ペナルティエリア進入数\n",
    "\n",
    "    # シュート・ゴール系（創造性の指標）\n",
    "    'goal_count',  # ゴール数\n",
    "    'pass_leads_to_shot',  # パス→ショットの連鎖\n",
    "\n",
    "    # 攻撃的ゾーン活動（前線でのプレー → xAG増加）\n",
    "    'zone_attacking_actions',  # 攻撃ゾーンでのアクション数\n",
    "    'zone_attacking_actions_ratio',  # 攻撃ゾーン比率\n",
    "\n",
    "    # 攻撃的バランス\n",
    "    'type_offensive_actions',  # 攻撃アクション数\n",
    "    'type_offensive_action_ratio',  # 攻撃アクション比率\n",
    "]\n",
    "\n",
    "missing_monotone_features = [feat for feat in monotone_increase_features if feat not in all_features]\n",
    "if missing_monotone_features:\n",
    "    print(\"単調性制約対象として指定したものの、特徴量一覧に存在しない列があります:\")\n",
    "    for feat in missing_monotone_features:\n",
    "        print(f\"  - {feat}\")\n",
    "\n",
    "applied_monotone_features = [feat for feat in monotone_increase_features if feat in all_features]\n",
    "\n",
    "# all_features内での各特徴量のインデックスを取得し、単調性ベクトルを構築\n",
    "monotone_constraints = [0] * len(all_features)  # デフォルトは制約なし(0)\n",
    "for feat in applied_monotone_features:\n",
    "    idx = all_features.index(feat)\n",
    "    monotone_constraints[idx] = 1  # 単調増加制約\n",
    "\n",
    "print(f\"\\n単調性制約を適用: {len(applied_monotone_features)}個の特徴量\")\n",
    "print(\"単調増加制約を適用した特徴量:\")\n",
    "for feat in applied_monotone_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "# LightGBM学習のパラメータを設定（Optunaで最適化されたパラメータを使用）\n",
    "lgbm_params = {\n",
    "    \"objective\": \"regression_l2\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"random_state\": SEED,\n",
    "    \"verbosity\": -1,\n",
    "    \"force_col_wise\": True,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"monotone_constraints\": monotone_constraints,  # 単調性制約を追加\n",
    "    \"monotone_constraints_method\": \"advanced\",  # advanced methodを使用\n",
    "}\n",
    "\n",
    "# Optunaの最適パラメータをマージ\n",
    "lgbm_params.update(best_params)\n",
    "\n",
    "print(f\"\\n使用するパラメータ: {lgbm_params}\")\n",
    "\n",
    "# 5-Foldでのモデル学習（最適化されたパラメータ使用）\n",
    "oof_preds = np.zeros(len(X_train))\n",
    "cv_scores = []\n",
    "models = []\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "# Training the models on the entire training data\n",
    "for fold in range(5):\n",
    "    print(f\"=== Fold {fold + 1} ===\")\n",
    "\n",
    "    # データ分割\n",
    "    trn_mask = train_df[\"fold\"] != fold+1\n",
    "    val_mask = train_df[\"fold\"] == fold+1\n",
    "\n",
    "    X_tr = train_df.loc[trn_mask, all_features].copy()\n",
    "    X_val = train_df.loc[val_mask, all_features].copy()\n",
    "    y_tr = y_train.loc[trn_mask].copy()\n",
    "    y_val = y_train.loc[val_mask].copy()\n",
    "\n",
    "    # LightGBMデータセット作成\n",
    "    train_weights = make_sample_weight(y_tr)\n",
    "    val_weights = make_sample_weight(y_val)\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr, weight=train_weights)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, weight=val_weights, reference=train_data)\n",
    "\n",
    "    # モデル学習（最適パラメータ使用）\n",
    "    model = lgb.train(\n",
    "        lgbm_params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=[\"train\", \"val\"],\n",
    "        feval=weighted_rmse_feval,\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "    )\n",
    "\n",
    "    # validationデータに対する予測、スコア算出\n",
    "    y_pred_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    oof_preds[val_mask] = y_pred_val\n",
    "    score = weighted_rmse(y_val, y_pred_val)\n",
    "    cv_scores.append(score)\n",
    "    models.append(model)  # このfoldのモデルをmodelsに格納\n",
    "\n",
    "    print(f\"Fold {fold + 1} RMSE: {score:.4f}\")\n",
    "\n",
    "    # 特徴量重要度算出\n",
    "    fold_importance = pd.DataFrame({\n",
    "        \"feature\": all_features,\n",
    "        \"importance\": model.feature_importance(importance_type=\"gain\"),\n",
    "        \"fold\": fold + 1\n",
    "    })\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "cv_mean = float(np.mean(cv_scores))\n",
    "cv_std = float(np.std(cv_scores))\n",
    "\n",
    "print(\"=== Cross Validation Results (Optimized Parameters) ===\")\n",
    "print(f\"CV RMSE: {cv_mean:.4f} (+/- {cv_std * 2:.4f})\")\n",
    "for i, score in enumerate(cv_scores):\n",
    "    print(f\"Fold {i + 1}: {score:.4f}\")\n",
    "\n",
    "# OOF予測のスコア算出\n",
    "oof_score = weighted_rmse(y_train, oof_preds)\n",
    "print(f\"OOF RMSE: {oof_score:.4f}\")\n",
    "\n",
    "optuna_summary = {\n",
    "    \"best_trial_number\": int(study.best_trial.number),\n",
    "    \"best_cv_value\": float(study.best_value),\n",
    "    \"fold1_val_rmse\": float(val_score),\n",
    "}\n",
    "\n",
    "save_training_run(\n",
    "    cv_scores=cv_scores,\n",
    "    oof_score=oof_score,\n",
    "    optuna_summary=optuna_summary,\n",
    "    best_params=best_params,\n",
    "    log_directory=log_dir,\n",
    ")\n",
    "\n",
    "print(f\"メトリクスを保存しました: {log_dir / 'host_baseline_002_metrics.json'}\")\n",
    "print(f\"ログを追記しました: {log_dir / 'host_baseline_002_training.log'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d339c",
   "metadata": {},
   "source": [
    "## CatBoost モデル学習\n",
    "\n",
    "CatBoostを使用して、LGBMと相補的なモデルを構築します。\n",
    "\n",
    "**CatBoostの特徴:**\n",
    "- **Ordered Target Statistics**: リークを回避しながらカテゴリ変数を効果的に処理\n",
    "- **高次交互作用**: カテゴリ変数間の複雑な交互作用を自動的に学習\n",
    "- **対称木構造**: より安定した予測を実現\n",
    "\n",
    "**実装方針:**\n",
    "- カテゴリカル特徴量を明示的に指定\n",
    "- LGBMと異なるseed/列サブセットで多様性を確保\n",
    "- 単調性制約は必要最小限に抑制\n",
    "- 重み付きRMSEに対応したサンプル重みを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ebff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost用のカテゴリカル特徴量を明示的に定義\n",
    "catboost_categorical_features = ['Comp', 'Squad', 'Venue']\n",
    "\n",
    "# CatBoostで使用する特徴量（LGBMと同じ特徴量を使用）\n",
    "catboost_features = all_features.copy()\n",
    "\n",
    "print(f\"CatBoostで使用する特徴量数: {len(catboost_features)}個\")\n",
    "print(f\"カテゴリカル特徴量: {catboost_categorical_features}\")\n",
    "\n",
    "# カテゴリカル特徴量のインデックスを取得\n",
    "cat_features_idx = [catboost_features.index(col) for col in catboost_categorical_features if col in catboost_features]\n",
    "print(f\"カテゴリカル特徴量インデックス: {cat_features_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost用のOptunaハイパーパラメータ最適化\n",
    "print(\"CatBoost ハイパーパラメータ最適化を開始...\")\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    \"\"\"\n",
    "    CatBoost用のOptuna目的関数\n",
    "    LGBMと相補性を持たせるため、異なる探索空間を設定\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'iterations': 1000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.1, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': 'RMSE',\n",
    "        'random_seed': SEED + 100,  # LGBMと異なるseedで多様性確保\n",
    "        'verbose': False,\n",
    "        'early_stopping_rounds': 100,\n",
    "        'cat_features': cat_features_idx,\n",
    "    }\n",
    "    \n",
    "    # Fold 1のみで評価（高速化のため）\n",
    "    fold = 0\n",
    "    trn_mask = train_df['fold'] != fold + 1\n",
    "    val_mask = train_df['fold'] == fold + 1\n",
    "    \n",
    "    X_tr = train_df.loc[trn_mask, catboost_features].copy()\n",
    "    X_val = train_df.loc[val_mask, catboost_features].copy()\n",
    "    y_tr = y_train.loc[trn_mask].copy()\n",
    "    y_val = y_train.loc[val_mask].copy()\n",
    "    \n",
    "    # サンプル重みを計算\n",
    "    train_weights = make_sample_weight(y_tr)\n",
    "    \n",
    "    # CatBoost Pool作成\n",
    "    train_pool = cb.Pool(\n",
    "        data=X_tr,\n",
    "        label=y_tr,\n",
    "        weight=train_weights,\n",
    "        cat_features=cat_features_idx\n",
    "    )\n",
    "    val_pool = cb.Pool(\n",
    "        data=X_val,\n",
    "        label=y_val,\n",
    "        cat_features=cat_features_idx\n",
    "    )\n",
    "    \n",
    "    # モデル学習\n",
    "    model = cb.CatBoostRegressor(**params)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        verbose=False,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    # 予測とスコア計算\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    val_score = weighted_rmse(y_val, y_pred_val)\n",
    "    \n",
    "    return val_score\n",
    "\n",
    "# Optuna最適化実行\n",
    "catboost_study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=SEED)\n",
    ")\n",
    "\n",
    "catboost_study.optimize(\n",
    "    objective_catboost,\n",
    "    n_trials=30,  # LGBMと同様に30試行\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "catboost_best_params = catboost_study.best_params\n",
    "print(f\"\\nCatBoost最適化完了\")\n",
    "print(f\"Best trial: {catboost_study.best_trial.number}\")\n",
    "print(f\"Best validation RMSE: {catboost_study.best_value:.4f}\")\n",
    "print(f\"Best parameters: {catboost_best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost用の単調性制約設定\n",
    "# LGBMよりも制約を緩めて、モデルの多様性を確保\n",
    "print(\"CatBoost単調性制約を設定中...\")\n",
    "\n",
    "# 最も重要な特徴量のみに単調性制約を適用（LGBMより少なめ）\n",
    "catboost_monotone_increase_features = [\n",
    "    'goal_count',  # ゴール数\n",
    "    'pass_leads_to_shot',  # パス→ショット\n",
    "    'progressive_pass_count',  # プログレッシブパス数\n",
    "    'deep_completion_count',  # ディープゾーン到達\n",
    "    'penalty_area_entry_count',  # ペナルティエリア進入\n",
    "    'zone_attacking_actions',  # 攻撃ゾーンアクション\n",
    "]\n",
    "\n",
    "# 特徴量が存在するもののみをフィルタリング\n",
    "applied_catboost_monotone_features = [\n",
    "    feat for feat in catboost_monotone_increase_features \n",
    "    if feat in catboost_features\n",
    "]\n",
    "\n",
    "# CatBoostの単調性制約形式: 文字列のカンマ区切り\n",
    "# 形式: \"feature_idx1,feature_idx2,...\" で方向を指定\n",
    "# または各特徴量に対して (idx, direction) のタプルのリスト\n",
    "# ここでは、特徴量名ベースで辞書形式を使用\n",
    "\n",
    "# CatBoostの単調性制約: 全特徴量に対する制約リスト（0=制約なし, 1=増加, -1=減少）\n",
    "catboost_monotone_constraints = [0] * len(catboost_features)\n",
    "\n",
    "for feat in applied_catboost_monotone_features:\n",
    "    if feat in catboost_features:\n",
    "        idx = catboost_features.index(feat)\n",
    "        catboost_monotone_constraints[idx] = 1  # 単調増加制約\n",
    "\n",
    "print(f\"単調性制約を適用: {len(applied_catboost_monotone_features)}個の特徴量\")\n",
    "print(f\"  (LGBMの{len(applied_monotone_features)}個から削減し、モデルの多様性を確保)\")\n",
    "for feat in applied_catboost_monotone_features:\n",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe199d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostでの5-Fold Cross Validation\n",
    "print(\"\\nCatBoostでの5-Fold Cross Validationを開始...\")\n",
    "\n",
    "# 最適化されたパラメータをベースに設定\n",
    "catboost_params = {\n",
    "    'iterations': 1000,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': SEED + 100,  # LGBMと異なるseed\n",
    "    'verbose': False,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'cat_features': cat_features_idx,\n",
    "    'monotone_constraints': catboost_monotone_constraints,  # 単調性制約\n",
    "}\n",
    "\n",
    "# Optunaの最適パラメータをマージ\n",
    "catboost_params.update(catboost_best_params)\n",
    "\n",
    "print(f\"使用するパラメータ: {catboost_params}\")\n",
    "\n",
    "# CV結果を格納\n",
    "catboost_oof_preds = np.zeros(len(X_train))\n",
    "catboost_cv_scores = []\n",
    "catboost_models = []\n",
    "catboost_feature_importance = pd.DataFrame()\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"\\n=== CatBoost Fold {fold + 1} ===\")\n",
    "    \n",
    "    # データ分割\n",
    "    trn_mask = train_df['fold'] != fold + 1\n",
    "    val_mask = train_df['fold'] == fold + 1\n",
    "    \n",
    "    X_tr = train_df.loc[trn_mask, catboost_features].copy()\n",
    "    X_val = train_df.loc[val_mask, catboost_features].copy()\n",
    "    y_tr = y_train.loc[trn_mask].copy()\n",
    "    y_val = y_train.loc[val_mask].copy()\n",
    "    \n",
    "    # サンプル重みを計算\n",
    "    train_weights = make_sample_weight(y_tr)\n",
    "    \n",
    "    # CatBoost Pool作成\n",
    "    train_pool = cb.Pool(\n",
    "        data=X_tr,\n",
    "        label=y_tr,\n",
    "        weight=train_weights,  # 重み付きRMSE対応\n",
    "        cat_features=cat_features_idx\n",
    "    )\n",
    "    val_pool = cb.Pool(\n",
    "        data=X_val,\n",
    "        label=y_val,\n",
    "        cat_features=cat_features_idx\n",
    "    )\n",
    "    \n",
    "    # モデル学習\n",
    "    model = cb.CatBoostRegressor(**catboost_params)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        verbose=100,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    # 予測とスコア計算\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    catboost_oof_preds[val_mask] = y_pred_val\n",
    "    score = weighted_rmse(y_val, y_pred_val)\n",
    "    catboost_cv_scores.append(score)\n",
    "    catboost_models.append(model)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Weighted RMSE: {score:.4f}\")\n",
    "    \n",
    "    # 特徴量重要度を取得\n",
    "    fold_importance = pd.DataFrame({\n",
    "        'feature': catboost_features,\n",
    "        'importance': model.get_feature_importance(),\n",
    "        'fold': fold + 1\n",
    "    })\n",
    "    catboost_feature_importance = pd.concat(\n",
    "        [catboost_feature_importance, fold_importance], \n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "# CV結果のサマリー\n",
    "catboost_cv_mean = float(np.mean(catboost_cv_scores))\n",
    "catboost_cv_std = float(np.std(catboost_cv_scores))\n",
    "\n",
    "print(\"\\n=== CatBoost Cross Validation Results ===\")\n",
    "print(f\"CV Weighted RMSE: {catboost_cv_mean:.4f} (+/- {catboost_cv_std * 2:.4f})\")\n",
    "for i, score in enumerate(catboost_cv_scores):\n",
    "    print(f\"Fold {i + 1}: {score:.4f}\")\n",
    "\n",
    "# OOF予測のスコア\n",
    "catboost_oof_score = weighted_rmse(y_train, catboost_oof_preds)\n",
    "print(f\"\\nCatBoost OOF Weighted RMSE: {catboost_oof_score:.4f}\")\n",
    "\n",
    "# LGBMとの比較\n",
    "print(f\"\\n--- モデル比較 ---\")\n",
    "print(f\"LightGBM OOF RMSE: {oof_score:.4f}\")\n",
    "print(f\"CatBoost OOF RMSE: {catboost_oof_score:.4f}\")\n",
    "print(f\"差分: {catboost_oof_score - oof_score:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225234a7",
   "metadata": {},
   "source": [
    "## モデルブレンディング（LightGBM + CatBoost）\n",
    "\n",
    "LightGBMとCatBoostの予測を加重平均でブレンドします。\n",
    "\n",
    "**ブレンディング戦略:**\n",
    "- OOF予測でブレンド比率を最適化\n",
    "- グリッドサーチで最適な重みを探索\n",
    "- LGBMとCatBoostの相補性を活用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOF予測を使ってブレンディング比率を最適化\n",
    "print(\"ブレンディング比率を最適化中...\")\n",
    "\n",
    "best_blend_weight = 0.5\n",
    "best_blend_score = float('inf')\n",
    "\n",
    "# グリッドサーチで最適な重みを探索\n",
    "for lgb_weight in np.arange(0.0, 1.01, 0.05):\n",
    "    catboost_weight = 1.0 - lgb_weight\n",
    "    \n",
    "    # ブレンド予測\n",
    "    blended_oof = lgb_weight * oof_preds + catboost_weight * catboost_oof_preds\n",
    "    \n",
    "    # スコア計算\n",
    "    blend_score = weighted_rmse(y_train, blended_oof)\n",
    "    \n",
    "    if blend_score < best_blend_score:\n",
    "        best_blend_score = blend_score\n",
    "        best_blend_weight = lgb_weight\n",
    "\n",
    "best_catboost_weight = 1.0 - best_blend_weight\n",
    "\n",
    "print(f\"\\n=== 最適ブレンディング比率 ===\")\n",
    "print(f\"LightGBM重み: {best_blend_weight:.2f}\")\n",
    "print(f\"CatBoost重み: {best_catboost_weight:.2f}\")\n",
    "print(f\"\\n--- スコア比較 ---\")\n",
    "print(f\"LightGBM OOF: {oof_score:.4f}\")\n",
    "print(f\"CatBoost OOF: {catboost_oof_score:.4f}\")\n",
    "print(f\"ブレンドOOF: {best_blend_score:.4f}\")\n",
    "print(f\"\\nLGBMからの改善: {best_blend_score - oof_score:+.4f}\")\n",
    "print(f\"CatBoostからの改善: {best_blend_score - catboost_oof_score:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68552b49",
   "metadata": {},
   "source": [
    "## テストデータに対する推論（ブレンドモデル）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f3511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostでテストデータに対する推論\n",
    "print(\"CatBoostでテストデータに対する推論を実行中...\")\n",
    "\n",
    "catboost_test_preds = np.zeros(len(X_test))\n",
    "\n",
    "for fold, model in enumerate(catboost_models):\n",
    "    fold_preds = model.predict(test_df[catboost_features])\n",
    "    catboost_test_preds += fold_preds / 5\n",
    "    print(f\"Fold {fold + 1}: 予測完了\")\n",
    "\n",
    "print(f\"\\nCatBoost予測統計:\")\n",
    "print(f\"  Mean: {catboost_test_preds.mean():.4f}\")\n",
    "print(f\"  Std: {catboost_test_preds.std():.4f}\")\n",
    "print(f\"  Min: {catboost_test_preds.min():.4f}\")\n",
    "print(f\"  Max: {catboost_test_preds.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMでテストデータに対する推論（既存のmodelsを使用）\n",
    "print(\"LightGBMでテストデータに対する推論を実行中...\")\n",
    "\n",
    "lgbm_test_preds = np.zeros(len(X_test))\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    fold_preds = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    lgbm_test_preds += fold_preds / 5\n",
    "    print(f\"Fold {fold + 1}: 予測完了\")\n",
    "\n",
    "print(f\"\\nLightGBM予測統計:\")\n",
    "print(f\"  Mean: {lgbm_test_preds.mean():.4f}\")\n",
    "print(f\"  Std: {lgbm_test_preds.std():.4f}\")\n",
    "print(f\"  Min: {lgbm_test_preds.min():.4f}\")\n",
    "print(f\"  Max: {lgbm_test_preds.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適な重みでブレンド予測を作成\n",
    "print(\"\\nブレンド予測を作成中...\")\n",
    "\n",
    "blended_test_preds = (\n",
    "    best_blend_weight * lgbm_test_preds + \n",
    "    best_catboost_weight * catboost_test_preds\n",
    ")\n",
    "\n",
    "print(f\"\\nブレンド予測統計:\")\n",
    "print(f\"  Mean: {blended_test_preds.mean():.4f}\")\n",
    "print(f\"  Std: {blended_test_preds.std():.4f}\")\n",
    "print(f\"  Min: {blended_test_preds.min():.4f}\")\n",
    "print(f\"  Max: {blended_test_preds.max():.4f}\")\n",
    "\n",
    "# 予測値の分布を可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].hist(lgbm_test_preds, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].set_title('LightGBM予測分布', fontsize=14)\n",
    "axes[0].set_xlabel('xAG予測値')\n",
    "axes[0].set_ylabel('頻度')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].hist(catboost_test_preds, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1].set_title('CatBoost予測分布', fontsize=14)\n",
    "axes[1].set_xlabel('xAG予測値')\n",
    "axes[1].set_ylabel('頻度')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "axes[2].hist(blended_test_preds, bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[2].set_title('ブレンド予測分布', fontsize=14)\n",
    "axes[2].set_xlabel('xAG予測値')\n",
    "axes[2].set_ylabel('頻度')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# モデル間の相関を確認\n",
    "correlation = np.corrcoef(lgbm_test_preds, catboost_test_preds)[0, 1]\n",
    "print(f\"\\nLGBMとCatBoostの予測相関: {correlation:.4f}\")\n",
    "print(f\"(相関が低いほど、ブレンディングによる改善効果が大きい)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e55003",
   "metadata": {
    "id": "Sap_9i9DaIf3"
   },
   "source": [
    "## テストデータに対する推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a3a3b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Xs1lGqfaIf4",
    "outputId": "47eceb84-34b8-480a-dfd5-85eebb203bc7"
   },
   "outputs": [],
   "source": [
    "# アンサンブル予測（5モデルの平均） on Test Data\n",
    "test_preds = np.zeros(len(X_test))\n",
    "\n",
    "for model in models:\n",
    "    pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    test_preds += pred\n",
    "\n",
    "test_preds /= len(models)\n",
    "\n",
    "\n",
    "print(f\"\\n=== Test Set Predictions ===\")\n",
    "print(f\"予測xAG範囲: {test_preds.min():.3f} 〜 {test_preds.max():.3f}\")\n",
    "\n",
    "# test_dfに予測結果を追加\n",
    "test_df['predicted_xAG'] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a2d48",
   "metadata": {
    "id": "yL_4w1qWaIf4"
   },
   "source": [
    "## 予測結果の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7b95c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 998
    },
    "id": "KLKnE3KajdZp",
    "outputId": "d9b9cad3-dedc-458d-aad3-e23986d7e5a3"
   },
   "outputs": [],
   "source": [
    "# 特徴量重要度の平均計算\n",
    "feature_importance_mean = feature_importance.groupby('feature')['importance'].agg(['mean', 'std']).reset_index()\n",
    "feature_importance_mean = feature_importance_mean.sort_values('mean', ascending=False)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance_mean.head(15), x='mean', y='feature')\n",
    "plt.title('Top 15 Feature Importance (Weighted RMSE Baseline xAG Model)')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"特徴量重要度 Top 10:\")\n",
    "print(feature_importance_mean.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517699b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "kGIeBEIPaIf4",
    "outputId": "92e7fb77-a19e-45f3-c778-c010f56a2adf"
   },
   "outputs": [],
   "source": [
    "# train, test予測値の分布を可視化\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(oof_preds, stat='density', kde=True, alpha=0.2, label='OOF予測', linewidth=0)\n",
    "sns.histplot(test_preds, stat='density', kde=True, alpha=0.2, label='Test予測', linewidth=0)\n",
    "\n",
    "# train正解値の分布を可視化\n",
    "vc = y_train.value_counts().sort_index()\n",
    "heights = vc / vc.sum() / 0.1 # 棒グラフの高さをdensity に合わせる\n",
    "plt.bar(vc.index, heights, width=0.03, alpha=0.6, label='OOF正解', align='center')\n",
    "\n",
    "plt.xlabel('xAG')\n",
    "plt.ylabel('密度')\n",
    "plt.xlim(0, 1)\n",
    "plt.title('xAG予測値の分布（OOF予測 vs Test予測 vs OOF正解）')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c4b9d8",
   "metadata": {
    "id": "61-ufcOruCGb"
   },
   "source": [
    "正解が0.0のデータの重み付けが小さいため、全体的に正の値を予想する傾向が見られる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add31d1",
   "metadata": {
    "id": "u4I2O1ntaIf4"
   },
   "source": [
    "## 提出ファイル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf7400",
   "metadata": {
    "id": "cbhq5ARAaIf4",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ブレンドモデルの予測で提出ファイルを作成\n",
    "submission_df['xAG'] = blended_test_preds\n",
    "\n",
    "# 提出ファイル保存\n",
    "submission_path = log_dir / 'submission_blend_lgbm_catboost.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"提出ファイルを保存しました: {submission_path}\")\n",
    "print(f\"\\n提出ファイルの統計:\")\n",
    "print(submission_df['xAG'].describe())\n",
    "\n",
    "# 個別モデルの提出ファイルも保存\n",
    "submission_lgbm = submission_df.copy()\n",
    "submission_lgbm['xAG'] = lgbm_test_preds\n",
    "submission_lgbm.to_csv(log_dir / 'submission_lgbm_only.csv', index=False)\n",
    "print(f\"\\nLightGBM単独の提出ファイルも保存: {log_dir / 'submission_lgbm_only.csv'}\")\n",
    "\n",
    "submission_catboost = submission_df.copy()\n",
    "submission_catboost['xAG'] = catboost_test_preds\n",
    "submission_catboost.to_csv(log_dir / 'submission_catboost_only.csv', index=False)\n",
    "print(f\"CatBoost単独の提出ファイルも保存: {log_dir / 'submission_catboost_only.csv'}\")\n",
    "\n",
    "# サマリー表示\n",
    "print(\"\\n=== 最終結果サマリー ===\")\n",
    "print(f\"LightGBM OOF RMSE: {oof_score:.4f}\")\n",
    "print(f\"CatBoost OOF RMSE: {catboost_oof_score:.4f}\")\n",
    "print(f\"ブレンドOOF RMSE: {best_blend_score:.4f}\")\n",
    "print(f\"\\nブレンディング比率:\")\n",
    "print(f\"  LightGBM: {best_blend_weight:.2f}\")\n",
    "print(f\"  CatBoost: {best_catboost_weight:.2f}\")\n",
    "print(f\"\\n提出ファイル:\")\n",
    "print(f\"  1. submission_blend_lgbm_catboost.csv (推奨)\")\n",
    "print(f\"  2. submission_lgbm_only.csv\")\n",
    "print(f\"  3. submission_catboost_only.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "all",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "all,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09a43976bef243599b2e9b64cffb91b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3e34a9bb0d24577acc83d7ae4b2486d",
       "IPY_MODEL_dcffd72448ea44bf9ec8aec5b31762f6",
       "IPY_MODEL_3a83f4956d7d41938ef54f146a5cc541"
      ],
      "layout": "IPY_MODEL_69216dc0f0f4422e8166c4a8f8abe666"
     }
    },
    "09a7b0f32ef942afb2963f355e80a8bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a83f4956d7d41938ef54f146a5cc541": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b6ef11c003d4a79b3924bc396c0ff56",
      "placeholder": "​",
      "style": "IPY_MODEL_78773c5f4ebc47fea4077d687ab0ea0c",
      "value": " 40041/40041 [03:10&lt;00:00, 234.12it/s]"
     }
    },
    "5b6ef11c003d4a79b3924bc396c0ff56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e50717143ae4771b600c2a5f73488e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69216dc0f0f4422e8166c4a8f8abe666": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78773c5f4ebc47fea4077d687ab0ea0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79fcd266aa524e9b9d656b2eab1a8cd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3e34a9bb0d24577acc83d7ae4b2486d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79fcd266aa524e9b9d656b2eab1a8cd3",
      "placeholder": "​",
      "style": "IPY_MODEL_09a7b0f32ef942afb2963f355e80a8bc",
      "value": "Calculating success rates: 100%"
     }
    },
    "dc043a4a5ed74b1c9b6cc8e027e5b2b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcffd72448ea44bf9ec8aec5b31762f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc043a4a5ed74b1c9b6cc8e027e5b2b6",
      "max": 40041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e50717143ae4771b600c2a5f73488e2",
      "value": 40041
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
