{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Evaluation Notebook - exp0001\n",
    "\n",
    "**OOF分析・CV品質チェック・リーク監査**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import json\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 設定とデータ読み込み\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "with open(\"metrics.json\", \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "oof_df = pd.read_parquet(\"oof.parquet\")\n",
    "cv_folds_df = pd.read_parquet(\"cv_folds.parquet\")\n",
    "\n",
    "print(f\"実験ID: {cfg['experiment']['id']}\")\n",
    "print(f\"OOF形状: {oof_df.shape}\")\n",
    "print(f\"CV分割形状: {cv_folds_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本統計\n",
    "print(\"=== CV Results ===\")\n",
    "print(f\"CV AUC: {metrics['cv']['mean']:.6f} ± {metrics['cv']['std']:.6f}\")\n",
    "print(f\"Per-fold AUC: {metrics['cv']['per_fold']}\")\n",
    "print(f\"学習時間: {metrics['train_time_sec']:.1f}秒\")\n",
    "\n",
    "# OOF全体スコア\n",
    "oof_auc = roc_auc_score(oof_df[\"y_true\"], oof_df[\"y_pred\"])\n",
    "oof_acc = accuracy_score(oof_df[\"y_true\"], (oof_df[\"y_pred\"] > 0.5).astype(int))\n",
    "\n",
    "print(f\"\\n=== OOF Scores ===\")\n",
    "print(f\"OOF AUC: {oof_auc:.6f}\")\n",
    "print(f\"OOF Accuracy: {oof_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold別スコア分析\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Fold別AUC\n",
    "fold_aucs = []\n",
    "for fold in range(cfg[\"cv\"][\"n_splits\"]):\n",
    "    fold_data = oof_df[oof_df[\"fold\"] == fold]\n",
    "    if len(fold_data) > 0:\n",
    "        fold_auc = roc_auc_score(fold_data[\"y_true\"], fold_data[\"y_pred\"])\n",
    "        fold_aucs.append(fold_auc)\n",
    "\n",
    "axes[0, 0].bar(range(len(fold_aucs)), fold_aucs)\n",
    "axes[0, 0].axhline(y=np.mean(fold_aucs), color=\"r\", linestyle=\"--\", label=f\"Mean: {np.mean(fold_aucs):.4f}\")\n",
    "axes[0, 0].set_title(\"Fold別AUC\")\n",
    "axes[0, 0].set_xlabel(\"Fold\")\n",
    "axes[0, 0].set_ylabel(\"AUC\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 予測値の分布\n",
    "axes[0, 1].hist(oof_df[oof_df[\"y_true\"] == 0][\"y_pred\"], bins=30, alpha=0.7, label=\"Survived=0\", density=True)\n",
    "axes[0, 1].hist(oof_df[oof_df[\"y_true\"] == 1][\"y_pred\"], bins=30, alpha=0.7, label=\"Survived=1\", density=True)\n",
    "axes[0, 1].set_title(\"予測値分布（クラス別）\")\n",
    "axes[0, 1].set_xlabel(\"予測確率\")\n",
    "axes[0, 1].set_ylabel(\"密度\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Calibration curve\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(oof_df[\"y_true\"], oof_df[\"y_pred\"], n_bins=10)\n",
    "axes[1, 0].plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Model\")\n",
    "axes[1, 0].plot([0, 1], [0, 1], \"k:\", label=\"Perfect calibration\")\n",
    "axes[1, 0].set_title(\"Calibration Curve\")\n",
    "axes[1, 0].set_xlabel(\"Mean predicted probability\")\n",
    "axes[1, 0].set_ylabel(\"Fraction of positives\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Confusion Matrix\n",
    "cm = confusion_matrix(oof_df[\"y_true\"], (oof_df[\"y_pred\"] > 0.5).astype(int))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", ax=axes[1, 1], cmap=\"Blues\")\n",
    "axes[1, 1].set_title(\"Confusion Matrix (threshold=0.5)\")\n",
    "axes[1, 1].set_xlabel(\"Predicted\")\n",
    "axes[1, 1].set_ylabel(\"True\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 閾値最適化\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# PR曲線から最適閾値を求める\n",
    "precision, recall, thresholds = precision_recall_curve(oof_df[\"y_true\"], oof_df[\"y_pred\"])\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "best_threshold_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "best_f1 = f1_scores[best_threshold_idx]\n",
    "\n",
    "print(f\"最適閾値 (F1-score): {best_threshold:.4f}\")\n",
    "print(f\"最適F1-score: {best_f1:.4f}\")\n",
    "\n",
    "# 閾値別の性能\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# PR曲線\n",
    "axes[0].plot(recall, precision, label=f\"PR Curve (AUC={roc_auc_score(oof_df['y_true'], oof_df['y_pred']):.3f})\")\n",
    "axes[0].scatter(\n",
    "    recall[best_threshold_idx],\n",
    "    precision[best_threshold_idx],\n",
    "    color=\"red\",\n",
    "    s=100,\n",
    "    label=f\"Best threshold: {best_threshold:.3f}\",\n",
    ")\n",
    "axes[0].set_xlabel(\"Recall\")\n",
    "axes[0].set_ylabel(\"Precision\")\n",
    "axes[0].set_title(\"Precision-Recall Curve\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1-score vs Threshold\n",
    "axes[1].plot(thresholds, f1_scores[:-1])\n",
    "axes[1].axvline(x=best_threshold, color=\"red\", linestyle=\"--\", label=f\"Best: {best_threshold:.3f} (F1={best_f1:.3f})\")\n",
    "axes[1].set_xlabel(\"Threshold\")\n",
    "axes[1].set_ylabel(\"F1-score\")\n",
    "axes[1].set_title(\"F1-score vs Threshold\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV品質チェック（リーク監査）\n",
    "print(\"=== CV品質チェック ===\")\n",
    "\n",
    "# 1. Fold間のスコア分散\n",
    "fold_auc_std = np.std(fold_aucs)\n",
    "print(f\"Fold間AUC標準偏差: {fold_auc_std:.6f}\")\n",
    "\n",
    "if fold_auc_std > 0.02:\n",
    "    print(\"⚠️  WARNING: Fold間のスコア分散が大きい（リーク疑い）\")\n",
    "else:\n",
    "    print(\"✅ Fold間のスコア分散は正常範囲\")\n",
    "\n",
    "# 2. 各Foldのサンプル数とtarget分布\n",
    "fold_stats = []\n",
    "for fold in range(cfg[\"cv\"][\"n_splits\"]):\n",
    "    fold_data = oof_df[oof_df[\"fold\"] == fold]\n",
    "    if len(fold_data) > 0:\n",
    "        fold_stats.append(\n",
    "            {\n",
    "                \"fold\": fold,\n",
    "                \"size\": len(fold_data),\n",
    "                \"positive_rate\": fold_data[\"y_true\"].mean(),\n",
    "                \"auc\": roc_auc_score(fold_data[\"y_true\"], fold_data[\"y_pred\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "fold_stats_df = pd.DataFrame(fold_stats)\n",
    "print(\"\\nFold別統計:\")\n",
    "print(fold_stats_df)\n",
    "\n",
    "# 3. Target分布の一様性チェック\n",
    "target_std = fold_stats_df[\"positive_rate\"].std()\n",
    "print(f\"\\nFold間target分布標準偏差: {target_std:.6f}\")\n",
    "\n",
    "if target_std > 0.05:\n",
    "    print(\"⚠️  WARNING: Fold間のtarget分布が不均一\")\n",
    "else:\n",
    "    print(\"✅ Fold間のtarget分布は均一\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 外れ値・異常値分析\n",
    "print(\"=== 外れ値分析 ===\")\n",
    "\n",
    "# 予測確率の外れ値\n",
    "q1, q3 = oof_df[\"y_pred\"].quantile([0.25, 0.75])\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "outliers = oof_df[(oof_df[\"y_pred\"] < lower_bound) | (oof_df[\"y_pred\"] > upper_bound)]\n",
    "print(f\"予測確率外れ値: {len(outliers)}件 ({len(outliers) / len(oof_df) * 100:.2f}%)\")\n",
    "\n",
    "# 大きな予測誤差のサンプル\n",
    "oof_df[\"abs_error\"] = np.abs(oof_df[\"y_true\"] - oof_df[\"y_pred\"])\n",
    "top_errors = oof_df.nlargest(10, \"abs_error\")[[\"index\", \"fold\", \"y_true\", \"y_pred\", \"abs_error\"]]\n",
    "print(\"\\n最大予測誤差サンプル（上位10件）:\")\n",
    "print(top_errors)\n",
    "\n",
    "# 予測誤差の分布\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(oof_df[\"abs_error\"], bins=50, alpha=0.7, edgecolor=\"black\")\n",
    "plt.axvline(oof_df[\"abs_error\"].mean(), color=\"red\", linestyle=\"--\", label=f\"Mean: {oof_df['abs_error'].mean():.3f}\")\n",
    "plt.xlabel(\"絶対誤差\")\n",
    "plt.ylabel(\"頻度\")\n",
    "plt.title(\"予測誤差分布\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(oof_df[\"y_pred\"], oof_df[\"abs_error\"], alpha=0.6)\n",
    "plt.xlabel(\"予測確率\")\n",
    "plt.ylabel(\"絶対誤差\")\n",
    "plt.title(\"予測確率 vs 絶対誤差\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV vs LB相関分析（実際のLBスコアがあれば）\n",
    "print(\"=== CV vs LB相関監視 ===\")\n",
    "print(\"※ 実際のLBスコア取得後に更新\")\n",
    "\n",
    "# 実験台帳があれば読み込んで相関を可視化\n",
    "experiments_file = \"../../experiments.csv\"\n",
    "try:\n",
    "    experiments_df = pd.read_csv(experiments_file)\n",
    "    if len(experiments_df) > 1:  # 複数実験がある場合\n",
    "        # CV vs LB散布図\n",
    "        valid_experiments = experiments_df.dropna(subset=[\"cv_mean\", \"lb_public\"])\n",
    "        if len(valid_experiments) > 0:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(valid_experiments[\"cv_mean\"], valid_experiments[\"lb_public\"], s=100, alpha=0.7)\n",
    "\n",
    "            # 相関係数\n",
    "            corr = valid_experiments[[\"cv_mean\", \"lb_public\"]].corr().iloc[0, 1]\n",
    "\n",
    "            # 回帰直線\n",
    "            z = np.polyfit(valid_experiments[\"cv_mean\"], valid_experiments[\"lb_public\"], 1)\n",
    "            p = np.poly1d(z)\n",
    "            plt.plot(valid_experiments[\"cv_mean\"], p(valid_experiments[\"cv_mean\"]), \"r--\", alpha=0.8)\n",
    "\n",
    "            plt.xlabel(\"CV AUC\")\n",
    "            plt.ylabel(\"LB Public Score\")\n",
    "            plt.title(f\"CV vs LB相関 (r={corr:.3f})\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            # 実験IDをラベル\n",
    "            for idx, row in valid_experiments.iterrows():\n",
    "                plt.annotate(\n",
    "                    row[\"exp_id\"], (row[\"cv_mean\"], row[\"lb_public\"]), xytext=(5, 5), textcoords=\"offset points\", fontsize=8\n",
    "                )\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            if abs(corr) < 0.7:\n",
    "                print(f\"⚠️  WARNING: CV-LB相関が低い (r={corr:.3f})\")\n",
    "                print(\"CVスキームの見直しを検討してください\")\n",
    "            else:\n",
    "                print(f\"✅ CV-LB相関は良好 (r={corr:.3f})\")\n",
    "        else:\n",
    "            print(\"LBスコアがある実験がまだありません\")\n",
    "    else:\n",
    "        print(\"比較可能な実験がまだありません\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"実験台帳がまだありません\")\n",
    "except Exception as e:\n",
    "    print(f\"実験台帳読み込みエラー: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レポートサマリー\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"実験ID: {cfg['experiment']['id']}\")\n",
    "print(f\"CV AUC: {metrics['cv']['mean']:.6f} ± {metrics['cv']['std']:.6f}\")\n",
    "print(f\"OOF AUC: {oof_auc:.6f}\")\n",
    "print(f\"最適閾値 (F1): {best_threshold:.4f}\")\n",
    "print(f\"最適F1スコア: {best_f1:.4f}\")\n",
    "\n",
    "print(\"\\n品質チェック結果:\")\n",
    "print(f\"- Fold間スコア分散: {fold_auc_std:.6f} {'⚠️' if fold_auc_std > 0.02 else '✅'}\")\n",
    "print(f\"- Target分布均一性: {target_std:.6f} {'⚠️' if target_std > 0.05 else '✅'}\")\n",
    "print(f\"- 予測外れ値: {len(outliers)}件 ({len(outliers) / len(oof_df) * 100:.1f}%)\")\n",
    "\n",
    "print(\"\\n次のアクション:\")\n",
    "if fold_auc_std > 0.02:\n",
    "    print(\"- Fold間スコア分散が大きい → リーク調査・CVスキーム見直し\")\n",
    "if target_std > 0.05:\n",
    "    print(\"- Target分布が不均一 → 分割方法の改善\")\n",
    "if len(outliers) > len(oof_df) * 0.1:\n",
    "    print(\"- 外れ値が多い → 前処理・特徴量見直し\")\n",
    "if fold_auc_std <= 0.02 and target_std <= 0.05:\n",
    "    print(\"- CV品質は良好 → ハイパーパラメータ調整・特徴量追加\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}