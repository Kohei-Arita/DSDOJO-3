{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Inference Notebook - exp0001\n",
    "\n",
    "**テストデータ予測・提出・台帳更新**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import yaml\n",
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 設定読み込み\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "print(f\"実験ID: {cfg['experiment']['id']}\")\n",
    "print(f\"推論開始時刻: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み・前処理（training.ipynbと同じ処理）\n",
    "def load_and_preprocess_data(cfg):\n",
    "    \"\"\"データの読み込みと前処理\"\"\"\n",
    "\n",
    "    # 生データ読み込み\n",
    "    train_df = pd.read_csv(f\"{cfg['paths']['raw_dir']}/train.csv\")\n",
    "    test_df = pd.read_csv(f\"{cfg['paths']['raw_dir']}/test.csv\")\n",
    "\n",
    "    # データ結合\n",
    "    all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "    # 欠損値処理\n",
    "    all_data[\"Age\"].fillna(all_data[\"Age\"].median(), inplace=True)\n",
    "    all_data[\"Fare\"].fillna(all_data[\"Fare\"].median(), inplace=True)\n",
    "    all_data[\"Embarked\"].fillna(all_data[\"Embarked\"].mode()[0], inplace=True)\n",
    "\n",
    "    # 特徴量エンジニアリング\n",
    "    # Title抽出\n",
    "    all_data[\"Title\"] = all_data[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\")\n",
    "    title_mapping = {\n",
    "        \"Mr\": \"Mr\",\n",
    "        \"Mrs\": \"Mrs\",\n",
    "        \"Miss\": \"Miss\",\n",
    "        \"Master\": \"Master\",\n",
    "        \"Dr\": \"Rare\",\n",
    "        \"Rev\": \"Rare\",\n",
    "        \"Col\": \"Rare\",\n",
    "        \"Major\": \"Rare\",\n",
    "        \"Mlle\": \"Miss\",\n",
    "        \"Countess\": \"Rare\",\n",
    "        \"Ms\": \"Mrs\",\n",
    "        \"Lady\": \"Rare\",\n",
    "        \"Jonkheer\": \"Rare\",\n",
    "        \"Don\": \"Rare\",\n",
    "        \"Dona\": \"Rare\",\n",
    "        \"Mme\": \"Mrs\",\n",
    "        \"Capt\": \"Rare\",\n",
    "        \"Sir\": \"Rare\",\n",
    "    }\n",
    "    all_data[\"Title\"] = all_data[\"Title\"].map(title_mapping).fillna(\"Rare\")\n",
    "\n",
    "    # Family features\n",
    "    all_data[\"FamilySize\"] = all_data[\"SibSp\"] + all_data[\"Parch\"] + 1\n",
    "    all_data[\"IsAlone\"] = (all_data[\"FamilySize\"] == 1).astype(int)\n",
    "\n",
    "    # Age bands\n",
    "    all_data[\"AgeBand\"] = pd.cut(\n",
    "        all_data[\"Age\"], bins=[0, 12, 18, 35, 60, 100], labels=[\"Child\", \"Teen\", \"Adult\", \"Middle\", \"Senior\"]\n",
    "    )\n",
    "\n",
    "    # Fare bands\n",
    "    all_data[\"FareBand\"] = pd.qcut(all_data[\"Fare\"], q=4, labels=[\"Low\", \"Medium\", \"High\", \"VeryHigh\"])\n",
    "\n",
    "    # 学習・テストに分離\n",
    "    train_data = all_data[: len(train_df)].copy()\n",
    "    test_data = all_data[len(train_df) :].copy()\n",
    "\n",
    "    # 特徴量とターゲットを分離\n",
    "    feature_cols = cfg[\"features\"][\"use\"]\n",
    "\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data[cfg[\"data\"][\"target\"]]\n",
    "    X_test = test_data[feature_cols]\n",
    "\n",
    "    return X_train, y_train, X_test, test_data\n",
    "\n",
    "\n",
    "# データ読み込み\n",
    "X_train, y_train, X_test, test_data = load_and_preprocess_data(cfg)\n",
    "\n",
    "print(f\"テストデータ形状: {X_test.shape}\")\n",
    "print(f\"特徴量: {list(X_test.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルの読み込み\n",
    "models = []\n",
    "model_paths = []\n",
    "\n",
    "for fold in range(cfg[\"cv\"][\"n_splits\"]):\n",
    "    model_path = f\"model/fold{fold}.lgb\"\n",
    "    if Path(model_path).exists():\n",
    "        model = lgb.Booster(model_file=model_path)\n",
    "        models.append(model)\n",
    "        model_paths.append(model_path)\n",
    "        print(f\"Fold {fold} モデル読み込み: {model_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"モデルファイルが見つかりません: {model_path}\")\n",
    "\n",
    "print(f\"\\n読み込み完了: {len(models)}個のモデル\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータ予測\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "fold_predictions = []\n",
    "\n",
    "print(\"テストデータ予測開始...\")\n",
    "for i, model in enumerate(models):\n",
    "    pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    test_predictions += pred / len(models)\n",
    "    fold_predictions.append(pred)\n",
    "    print(f\"Fold {i}: 予測完了 (平均: {pred.mean():.4f})\")\n",
    "\n",
    "print(f\"\\nアンサンブル予測完了\")\n",
    "print(f\"予測値統計: min={test_predictions.min():.4f}, max={test_predictions.max():.4f}, mean={test_predictions.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 閾値の決定（OOF分析から）\n",
    "# evaluation.ipynbで求めた最適閾値を使用するか、デフォルト0.5を使用\n",
    "threshold = 0.5  # 後でevaluation結果から更新\n",
    "\n",
    "try:\n",
    "    # OOFデータから最適閾値を計算\n",
    "    oof_df = pd.read_parquet(\"oof.parquet\")\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(oof_df[\"y_true\"], oof_df[\"y_pred\"])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    best_threshold_idx = np.argmax(f1_scores)\n",
    "    threshold = thresholds[best_threshold_idx]\n",
    "\n",
    "    print(f\"OOFから最適閾値を計算: {threshold:.4f}\")\n",
    "except:\n",
    "    print(f\"デフォルト閾値を使用: {threshold}\")\n",
    "\n",
    "# 提出用予測（バイナリ）\n",
    "binary_predictions = (test_predictions > threshold).astype(int)\n",
    "\n",
    "print(f\"予測分布: {np.bincount(binary_predictions)}\")\n",
    "print(f\"生存率: {binary_predictions.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイル作成\n",
    "submission = pd.DataFrame({cfg[\"data\"][\"id\"]: test_data[cfg[\"data\"][\"id\"]], cfg[\"data\"][\"target\"]: binary_predictions})\n",
    "\n",
    "submission_path = f\"submissions/submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"提出ファイル作成: {submission_path}\")\n",
    "print(\"\\n提出データサンプル:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\n提出データ形状: {submission.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API提出\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Git SHAを取得\n",
    "try:\n",
    "    with open(\"git_sha.txt\", \"r\") as f:\n",
    "        git_sha = f.read().strip()\n",
    "except:\n",
    "    try:\n",
    "        git_sha = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).decode(\"ascii\").strip()[:8]\n",
    "    except:\n",
    "        git_sha = \"unknown\"\n",
    "\n",
    "# 提出メッセージ\n",
    "message = cfg[\"kaggle\"][\"message_template\"].format(exp_id=cfg[\"experiment\"][\"id\"], git_sha=git_sha)\n",
    "\n",
    "print(f\"Kaggle提出開始...\")\n",
    "print(f\"Competition: {cfg['kaggle']['competition']}\")\n",
    "print(f\"Message: {message}\")\n",
    "\n",
    "# 提出コマンド実行\n",
    "cmd = f\"kaggle competitions submit -c {cfg['kaggle']['competition']} -f {submission_path} -m '{message}'\"\n",
    "result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"✅ 提出成功!\")\n",
    "    print(result.stdout)\n",
    "\n",
    "    # 提出IDを抽出\n",
    "    submission_match = re.search(r\"Successfully submitted to (.+)\", result.stdout)\n",
    "    if submission_match:\n",
    "        competition_name = submission_match.group(1)\n",
    "        print(f\"Competition: {competition_name}\")\n",
    "else:\n",
    "    print(\"❌ 提出失敗\")\n",
    "    print(f\"Error: {result.stderr}\")\n",
    "\n",
    "# 提出履歴を取得してSubmission IDを取得\n",
    "print(\"\\n提出履歴を取得中...\")\n",
    "submissions_cmd = f\"kaggle competitions submissions -c {cfg['kaggle']['competition']} -v\"\n",
    "submissions_result = subprocess.run(submissions_cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "submission_info = {}\n",
    "if submissions_result.returncode == 0:\n",
    "    # 最新の提出情報をパース\n",
    "    lines = submissions_result.stdout.strip().split(\"\\n\")\n",
    "    if len(lines) > 1:  # ヘッダー行を除く\n",
    "        latest_submission = lines[1].split(\",\")\n",
    "        if len(latest_submission) >= 6:\n",
    "            submission_info = {\n",
    "                \"id\": latest_submission[0],\n",
    "                \"description\": latest_submission[1],\n",
    "                \"submitted_at\": latest_submission[2],\n",
    "                \"public_score\": latest_submission[4] if latest_submission[4] != \"\" else None,\n",
    "            }\n",
    "            print(f\"Submission ID: {submission_info['id']}\")\n",
    "            print(f\"Public Score: {submission_info['public_score']}\")\n",
    "else:\n",
    "    print(f\"提出履歴取得エラー: {submissions_result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission manifest作成\n",
    "manifest = {\n",
    "    \"exp_id\": cfg[\"experiment\"][\"id\"],\n",
    "    \"generated_at\": datetime.now().isoformat(),\n",
    "    \"models\": model_paths,\n",
    "    \"threshold\": float(threshold),\n",
    "    \"postprocess\": None,\n",
    "    \"oof_path\": \"oof.parquet\",\n",
    "    \"config_path\": \"config.yaml\",\n",
    "    \"git_sha\": git_sha,\n",
    "    \"wandb_run\": None,  # training.ipynbで生成されたW&B URLを後で追加\n",
    "    \"prediction_stats\": {\n",
    "        \"mean\": float(test_predictions.mean()),\n",
    "        \"std\": float(test_predictions.std()),\n",
    "        \"min\": float(test_predictions.min()),\n",
    "        \"max\": float(test_predictions.max()),\n",
    "        \"survival_rate\": float(binary_predictions.mean()),\n",
    "    },\n",
    "    \"kaggle_submission\": submission_info,\n",
    "    \"notes\": cfg[\"experiment\"][\"description\"],\n",
    "}\n",
    "\n",
    "# W&B Run URLを追加\n",
    "try:\n",
    "    with open(\"wandb_run.txt\", \"r\") as f:\n",
    "        wandb_info = f.read().strip().split(\"\\n\")\n",
    "        manifest[\"wandb_run\"] = wandb_info[0] if len(wandb_info) > 0 else None\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Manifest保存\n",
    "manifest_path = \"submissions/submission.manifest.json\"\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSubmission manifest保存: {manifest_path}\")\n",
    "print(json.dumps(manifest, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験台帳を更新\n",
    "def append_experiments_csv(row_data, path=\"../../experiments.csv\"):\n",
    "    \"\"\"実験台帳にエントリを追加\"\"\"\n",
    "    import csv\n",
    "    import os\n",
    "\n",
    "    header = [\n",
    "        \"exp_id\",\n",
    "        \"date\",\n",
    "        \"git_sha\",\n",
    "        \"wandb_url\",\n",
    "        \"cv_metric\",\n",
    "        \"cv_mean\",\n",
    "        \"cv_std\",\n",
    "        \"lb_public\",\n",
    "        \"lb_private\",\n",
    "        \"data_rev\",\n",
    "        \"seed\",\n",
    "        \"n_splits\",\n",
    "        \"cv_method\",\n",
    "        \"split_id\",\n",
    "        \"notes\",\n",
    "        \"submission_id\",\n",
    "        \"submitted_at\",\n",
    "    ]\n",
    "\n",
    "    exists = os.path.exists(path)\n",
    "    with open(path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header)\n",
    "        if not exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row_data)\n",
    "\n",
    "\n",
    "# メトリクス読み込み\n",
    "try:\n",
    "    with open(\"metrics.json\", \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    metrics = {\"cv\": {\"mean\": None, \"std\": None}}\n",
    "\n",
    "# CV分割情報読み込み\n",
    "try:\n",
    "    cv_folds_df = pd.read_parquet(\"cv_folds.parquet\")\n",
    "    split_id = cv_folds_df[\"split_id\"].iloc[0]\n",
    "except:\n",
    "    split_id = \"unknown\"\n",
    "\n",
    "# 実験台帳エントリ作成\n",
    "experiment_row = {\n",
    "    \"exp_id\": cfg[\"experiment\"][\"id\"],\n",
    "    \"date\": cfg[\"experiment\"][\"date\"],\n",
    "    \"git_sha\": git_sha,\n",
    "    \"wandb_url\": manifest.get(\"wandb_run\"),\n",
    "    \"cv_metric\": \"auc\",\n",
    "    \"cv_mean\": metrics[\"cv\"][\"mean\"],\n",
    "    \"cv_std\": metrics[\"cv\"][\"std\"],\n",
    "    \"lb_public\": submission_info.get(\"public_score\"),\n",
    "    \"lb_private\": None,  # コンペ終了後に更新\n",
    "    \"data_rev\": \"v1\",\n",
    "    \"seed\": cfg[\"cv\"][\"seed\"],\n",
    "    \"n_splits\": cfg[\"cv\"][\"n_splits\"],\n",
    "    \"cv_method\": cfg[\"cv\"][\"method\"],\n",
    "    \"split_id\": split_id,\n",
    "    \"notes\": cfg[\"experiment\"][\"description\"],\n",
    "    \"submission_id\": submission_info.get(\"id\"),\n",
    "    \"submitted_at\": submission_info.get(\"submitted_at\"),\n",
    "}\n",
    "\n",
    "# 台帳に追加\n",
    "append_experiments_csv(experiment_row)\n",
    "print(\"\\n✅ 実験台帳を更新しました\")\n",
    "print(f\"実験ID: {experiment_row['exp_id']}\")\n",
    "print(f\"CV AUC: {experiment_row['cv_mean']} ± {experiment_row['cv_std']}\")\n",
    "print(f\"Submission ID: {experiment_row['submission_id']}\")\n",
    "print(f\"Public Score: {experiment_row['lb_public']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論サマリー\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"INFERENCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"実験ID: {cfg['experiment']['id']}\")\n",
    "print(f\"使用モデル: {len(models)}個のfoldアンサンブル\")\n",
    "print(f\"予測閾値: {threshold:.4f}\")\n",
    "print(f\"予測生存率: {binary_predictions.mean():.3f}\")\n",
    "print(f\"提出ファイル: {submission_path}\")\n",
    "print(f\"Submission ID: {submission_info.get('id', 'N/A')}\")\n",
    "print(f\"Public Score: {submission_info.get('public_score', 'N/A')}\")\n",
    "\n",
    "print(\"\\n成果物:\")\n",
    "print(f\"- 提出CSV: {submission_path}\")\n",
    "print(f\"- Manifest: {manifest_path}\")\n",
    "print(f\"- 実験台帳: ../../experiments.csv (更新済み)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"推論完了時刻: {datetime.now()}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}